{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-attention-visualize-all.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNRdqf86o3Lu",
        "colab_type": "code",
        "outputId": "afbf4630-be74-4327-97dc-9e7c3697bb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "#https://github.com/likejazz/jupyter-notebooks/tree/master/deep-learning/keras-attention\n",
        "#>> https://github.com/datalogue/keras-attention.git\n",
        "\n",
        "!git clone https://github.com/jukyellow/keras-attention.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-attention'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 154 (delta 4), reused 0 (delta 0), pack-reused 143\u001b[K\n",
            "Receiving objects: 100% (154/154), 15.63 MiB | 7.43 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gqGpVZdJLyg",
        "colab_type": "code",
        "outputId": "b2dba0a1-a577-45fa-9ee2-a5272e05c4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install Faker"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ed/2fd5337ed405c4258dde1254e60f4e8ef9f1787576c0a2cd0d750b1716a6/Faker-2.0.3-py2.py3-none-any.whl (892kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from Faker) (2.6.1)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from Faker) (1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from Faker) (1.12.0)\n",
            "Installing collected packages: Faker\n",
            "Successfully installed Faker-2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otcMjkDfIFf8",
        "colab_type": "code",
        "outputId": "4fd34767-9b0c-493b-d7fb-88f370b4b1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import random\n",
        "import json\n",
        "import os\n",
        "\n",
        "#DATA_FOLDER = os.path.realpath(os.path.join(os.path.realpath(__file__), '..'))\n",
        "DATA_FOLDER = os.path.realpath(os.path.join(os.path.abspath(''), '..'))\n",
        "print('DATA_FOLDER:', DATA_FOLDER)\n",
        "DATA_FOLDER = '/content/keras-attention/data'\n",
        "print('DATA_FOLDER:', DATA_FOLDER)\n",
        "\n",
        "\n",
        "from faker import Faker\n",
        "import babel\n",
        "from babel.dates import format_date\n",
        "\n",
        "fake = Faker()\n",
        "fake.seed(230517)\n",
        "random.seed(230517)\n",
        "\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'd MMM YYY',\n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY',\n",
        "           ]\n",
        "\n",
        "# change this if you want it to work with only a single language\n",
        "# LOCALES = ['en_US']\n",
        "LOCALES = babel.localedata.locale_identifiers()\n",
        "\n",
        "\n",
        "def create_date():\n",
        "    \"\"\"\n",
        "        Creates some fake dates \n",
        "        :returns: tuple containing \n",
        "                  1. human formatted string\n",
        "                  2. machine formatted string\n",
        "                  3. date object.\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    # wrapping this in a try catch because\n",
        "    # the locale 'vo' and format 'full' will fail\n",
        "    try:\n",
        "        human = format_date(dt,\n",
        "                            format=random.choice(FORMATS),\n",
        "                            locale=random.choice(LOCALES))\n",
        "\n",
        "        case_change = random.randint(0,3) # 1/2 chance of case change\n",
        "        if case_change == 1:\n",
        "            human = human.upper()\n",
        "        elif case_change == 2:\n",
        "            human = human.lower()\n",
        "\n",
        "        machine = dt.isoformat()\n",
        "    except AttributeError as e:\n",
        "        # print(e)\n",
        "        return None, None, None\n",
        "\n",
        "    return human, machine, dt\n",
        "\n",
        "\n",
        "def create_dataset(dataset_name, n_examples, vocabulary=False):\n",
        "    \"\"\"\n",
        "        Creates a csv dataset with n_examples and optional vocabulary\n",
        "        :param dataset_name: name of the file to save as\n",
        "        :n_examples: the number of examples to generate\n",
        "        :vocabulary: if true, will also save the vocabulary\n",
        "    \"\"\"\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "\n",
        "    with open(dataset_name, 'w') as f:\n",
        "        for i in range(n_examples):\n",
        "            h, m, _ = create_date()\n",
        "            if h is not None:\n",
        "                f.write('\"'+h + '\",\"' + m + '\"\\n')\n",
        "                human_vocab.update(tuple(h))\n",
        "                machine_vocab.update(tuple(m))\n",
        "            if(i==0):\n",
        "                print('create_dataset h:',h,',m:',m,',_:',_)\n",
        "\n",
        "    if vocabulary:\n",
        "        int2human = dict(enumerate(human_vocab))\n",
        "        int2human.update({len(int2human): '<unk>',\n",
        "                          len(int2human)+1: '<eot>'})\n",
        "        int2machine = dict(enumerate(machine_vocab))\n",
        "        int2machine.update({len(int2machine):'<unk>',\n",
        "                            len(int2machine)+1:'<eot>'})\n",
        "\n",
        "        human2int = {v: k for k, v in int2human.items()}\n",
        "        machine2int = {v: k for k, v in int2machine.items()}\n",
        "\n",
        "        with open(os.path.join(DATA_FOLDER, 'human_vocab.json'), 'w') as f:\n",
        "            json.dump(human2int, f)\n",
        "        with open(os.path.join(DATA_FOLDER, 'machine_vocab.json'), 'w') as f:\n",
        "            json.dump(machine2int, f)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA_FOLDER: /\n",
            "DATA_FOLDER: /content/keras-attention/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYptL7ouK9Vc",
        "colab_type": "code",
        "outputId": "12d07a3b-f074-4d30-a4c1-abe02f774d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print('creating dataset')\n",
        "    create_dataset(os.path.join(DATA_FOLDER, 'training.csv'), 50000,\n",
        "                   vocabulary=True)\n",
        "    create_dataset(os.path.join(DATA_FOLDER, 'validation.csv'), 100)\n",
        "    print('dataset created.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating dataset\n",
            "create_dataset h: 12, sept. 2010 ,m: 2010-09-12 ,_: 2010-09-12\n",
            "create_dataset h: 18 mar. 1990 ,m: 1990-03-18 ,_: 1990-03-18\n",
            "dataset created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0s2_luBBycQ",
        "colab_type": "code",
        "outputId": "b1c132ea-2bad-4850-f923-0d0b0322d4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "\"\"\"\n",
        "    Runs a simple Neural Machine Translation model\n",
        "    Type `python run.py -h` for help with arguments.\n",
        "\"\"\"\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#from models.NMT import simpleNMT\n",
        "#from data.reader import Data, Vocabulary\n",
        "#from utils.metrics import all_acc\n",
        "#from utils.examples import run_examples\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEWoyh5a2aS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def all_acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "        All Accuracy\n",
        "        https://github.com/rasmusbergpalm/normalization/blob/master/train.py#L10\n",
        "    \"\"\"\n",
        "    return K.mean(\n",
        "        K.all(\n",
        "            K.equal(\n",
        "                K.max(y_true, axis=-1),\n",
        "                K.cast(K.argmax(y_pred, axis=-1), K.floatx())\n",
        "            ),\n",
        "            axis=1)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afVnYsBd3CPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "random.seed(1984)\n",
        "\n",
        "INPUT_PADDING = 50\n",
        "OUTPUT_PADDING = 100\n",
        "\n",
        "\n",
        "class Vocabulary(object):\n",
        "\n",
        "    def __init__(self, vocabulary_file, padding=None):\n",
        "        \"\"\"\n",
        "            Creates a vocabulary from a file\n",
        "            :param vocabulary_file: the path to the vocabulary\n",
        "        \"\"\"\n",
        "        print('vocabulary_file:', vocabulary_file)\n",
        "        self.vocabulary_file = vocabulary_file\n",
        "        with open(vocabulary_file, 'r') as f:\n",
        "            self.vocabulary = json.load(f)\n",
        "\n",
        "        self.padding = padding\n",
        "        self.reverse_vocabulary = {v: k for k, v in self.vocabulary.items()}\n",
        "\n",
        "    def size(self):\n",
        "        \"\"\"\n",
        "            Gets the size of the vocabulary\n",
        "        \"\"\"\n",
        "        #print('Vocabulary.size: ', self.vocabulary.keys())\n",
        "        return len(self.vocabulary.keys())\n",
        "\n",
        "    def string_to_int(self, text):\n",
        "        \"\"\"\n",
        "            Converts a string into it's character integer \n",
        "            representation\n",
        "            :param text: text to convert\n",
        "        \"\"\"\n",
        "        characters = list(text)\n",
        "\n",
        "        integers = []\n",
        "\n",
        "        if self.padding and len(characters) >= self.padding:\n",
        "            # truncate if too long\n",
        "            characters = characters[:self.padding - 1]\n",
        "\n",
        "        characters.append('<eot>')\n",
        "\n",
        "        for c in characters:\n",
        "            if c in self.vocabulary:\n",
        "                integers.append(self.vocabulary[c])\n",
        "            else:\n",
        "                integers.append(self.vocabulary['<unk>'])\n",
        "\n",
        "\n",
        "        # pad:\n",
        "        if self.padding and len(integers) < self.padding:\n",
        "            integers.extend([self.vocabulary['<unk>']]\n",
        "                            * (self.padding - len(integers)))\n",
        "\n",
        "        if len(integers) != self.padding:\n",
        "            print(text)\n",
        "            raise AttributeError('Length of text was not padding.')\n",
        "        #print('Vocabulary.string_to_int: ', len(integers))\n",
        "        return integers\n",
        "\n",
        "    def int_to_string(self, integers):\n",
        "        \"\"\"\n",
        "            Decodes a list of integers\n",
        "            into it's string representation\n",
        "        \"\"\"\n",
        "        characters = []\n",
        "        for i in integers:\n",
        "            characters.append(self.reverse_vocabulary[i])\n",
        "        #print('Vocabulary.int_to_string: ', len(characters))\n",
        "        return characters\n",
        "\n",
        "\n",
        "class Data(object):\n",
        "\n",
        "    def __init__(self, file_name, input_vocabulary, output_vocabulary):\n",
        "        \"\"\"\n",
        "            Creates an object that gets data from a file\n",
        "            :param file_name: name of the file to read from\n",
        "            :param vocabulary: the Vocabulary object to use\n",
        "            :param batch_size: the number of datapoints to return\n",
        "            :param padding: the amount of padding to apply to \n",
        "                            a short string\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_vocabulary = input_vocabulary\n",
        "        self.output_vocabulary = output_vocabulary\n",
        "        self.file_name = file_name\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"\n",
        "            Loads data from a file\n",
        "        \"\"\"\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        with open(self.file_name, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                self.inputs.append(row[0])\n",
        "                self.targets.append(row[1])\n",
        "\n",
        "        print('Data.load len(inputs): ', len(self.inputs))\n",
        "        print('Data.load len(targets): ', len(self.targets))\n",
        "        print('Data.load (inputs[0]): ', self.inputs[0])\n",
        "        print('Data.load (targets[0]): ', self.targets[0])\n",
        "\n",
        "    def transform(self):\n",
        "        \"\"\"\n",
        "            Transforms the data as necessary\n",
        "        \"\"\"\n",
        "        # @TODO: use `pool.map_async` here?\n",
        "        self.inputs = np.array(list(\n",
        "            map(self.input_vocabulary.string_to_int, self.inputs)))\n",
        "        self.targets = map(self.output_vocabulary.string_to_int, self.targets)\n",
        "        self.targets = np.array(\n",
        "            list(map(\n",
        "                lambda x: to_categorical(\n",
        "                    x,\n",
        "                    num_classes=self.output_vocabulary.size()),\n",
        "                self.targets)))\n",
        "        print('Data.transform len(inputs): ', len(self.inputs))\n",
        "        print('Data.transform len(targets): ', len(self.targets))\n",
        "        print('Data.transform np.array(inputs): ', np.array(self.inputs))\n",
        "        print('Data.transform np.array(targets): ', np.array(self.targets))\n",
        "        print('Data.transform np.array(inputs)shape: ', np.array(self.inputs).shape)\n",
        "        print('Data.transform np.array(targets)shape: ', np.array(self.targets).shape)\n",
        "        print('Data.transform (inputs[0]): ', self.inputs[0])\n",
        "        print('Data.transform (targets[0]): ', self.targets[0])\n",
        "        assert len(self.inputs.shape) == 2, 'Inputs could not properly be encoded'\n",
        "        assert len(self.targets.shape) == 3, 'Targets could not properly be encoded'\n",
        "\n",
        "    def generator(self, batch_size):\n",
        "        \"\"\"\n",
        "            Creates a generator that can be used in `model.fit_generator()`\n",
        "            Batches are generated randomly.\n",
        "            :param batch_size: the number of instances to include per batch\n",
        "        \"\"\"\n",
        "        instance_id = range(len(self.inputs))\n",
        "        while True:\n",
        "            try:\n",
        "                batch_ids = random.sample(instance_id, batch_size)\n",
        "                #print('Data.generator: batch_ids:', batch_ids+',instance_id:', instance_id+ ',batch_size:', batch_size)\n",
        "                yield (np.array(self.inputs[batch_ids], dtype=int),\n",
        "                       np.array(self.targets[batch_ids]))\n",
        "            except Exception as e:\n",
        "                print('EXCEPTION OMG')\n",
        "                print(e)\n",
        "                yield None, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD6vt_bLEvxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "EXAMPLES = ['26th January 2016', '3 April 1989', '5 Dec 09', 'Sat 8 Jun 2017']\n",
        "\n",
        "def run_example(model, input_vocabulary, output_vocabulary, text, idx):\n",
        "    encoded = input_vocabulary.string_to_int(text)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)    \n",
        "\n",
        "    decoded = output_vocabulary.int_to_string(prediction)\n",
        "    if(idx==0):\n",
        "        print('text: ', text, ',encoded:', encoded)\n",
        "        print('run_example.prediction:', prediction)\n",
        "        print('run_example.decoded:', decoded , ',prediction:', prediction)\n",
        "    return decoded\n",
        "\n",
        "def run_examples(model, input_vocabulary, output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    idx = 0\n",
        "    for example in examples:\n",
        "        print('~~~~~')\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, output_vocabulary, example, idx)))\n",
        "        print('input:',example)\n",
        "        print('output:',predicted[-1])\n",
        "        idx = idx + 1\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWDDxe6p1Zu5",
        "colab_type": "code",
        "outputId": "b9d11778-3ab2-4b09-ce89-50095c501df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "ls -alrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Oct 25 16:58 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Nov  4 16:14 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Nov  6 22:24 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Nov  6 22:25 \u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 7 root root 4096 Nov  6 22:25 \u001b[01;34mkeras-attention\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLsxZ_fh1cuu",
        "colab_type": "code",
        "outputId": "e3866a31-1bb4-4cc2-eb44-988c1a6416c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd keras-attention"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spnc32GD2sSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Activation, Permute\n",
        "from keras.layers import Input, Flatten, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
        "from models.custom_recurrents import AttentionDecoder\n",
        "\n",
        "\n",
        "def simpleNMT(pad_length=100,\n",
        "              n_chars=105,\n",
        "              n_labels=6,\n",
        "              embedding_learnable=False,\n",
        "              encoder_units=256,\n",
        "              decoder_units=256,\n",
        "              trainable=True,\n",
        "              return_probabilities=False):\n",
        "    \"\"\"\n",
        "    Builds a Neural Machine Translator that has alignment attention\n",
        "    :param pad_length: the size of the input sequence\n",
        "    :param n_chars: the number of characters in the vocabulary\n",
        "    :param n_labels: the number of possible labelings for each character\n",
        "    :param embedding_learnable: decides if the one hot embedding should be refinable.\n",
        "    :return: keras.models.Model that can be compiled and fit'ed\n",
        "    *** REFERENCES ***\n",
        "    Lee, Jason, Kyunghyun Cho, and Thomas Hofmann. \n",
        "    \"Neural Machine Translation By Jointly Learning To Align and Translate\" \n",
        "    \"\"\"\n",
        "    input_ = Input(shape=(pad_length,), dtype='float32')\n",
        "    print('input_.shape: ', input_.shape)\n",
        "\n",
        "    input_embed = Embedding(n_chars, n_chars,\n",
        "                            input_length=pad_length,\n",
        "                            trainable=embedding_learnable,\n",
        "                            weights=[np.eye(n_chars)],\n",
        "                            name='OneHot')(input_)\n",
        "    print('simpleNMT n_chars:', n_chars,',pad_length:',pad_length,',embedding_learnable:',embedding_learnable,',weights:',[np.eye(n_chars)])\n",
        "\n",
        "    rnn_encoded = Bidirectional(LSTM(encoder_units, return_sequences=True),\n",
        "                                name='bidirectional_1',\n",
        "                                merge_mode='concat',\n",
        "                                trainable=trainable)(input_embed)\n",
        "    print('simpleNMT rnn_encoded:', rnn_encoded)\n",
        "\n",
        "    y_hat = AttentionDecoder(decoder_units,\n",
        "                             name='attention_decoder_1',\n",
        "                             output_dim=n_labels,\n",
        "                             return_probabilities=return_probabilities,\n",
        "                             trainable=trainable)(rnn_encoded)\n",
        "    print('simpleNMT decoder_units:', decoder_units, 'n_labels:', n_labels, ',return_probabilities:',return_probabilities, ',trainable:',trainable)\n",
        "    print('simpleNMT y_hat:', y_hat)\n",
        "\n",
        "    model = Model(inputs=input_, outputs=y_hat)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHu0QkevDpIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cp = ModelCheckpoint(\"./weights/NMT.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
        "                     monitor='val_loss',\n",
        "                     verbose=0,\n",
        "                     save_best_only=True,\n",
        "                     save_weights_only=True,\n",
        "                     mode='auto')\n",
        "\n",
        "# create a directory if it doesn't already exist\n",
        "if not os.path.exists('./weights'):\n",
        "    os.makedirs('./weights/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP1R2hLpFYWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main():\n",
        "    print('main!')\n",
        "\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "    # Dataset functions\n",
        "    #input_vocab = Vocabulary('./data/human_vocab.json', padding=50)\n",
        "    #output_vocab = Vocabulary('./data/machine_vocab.json',padding=50)\n",
        "    input_vocab = Vocabulary('/content/keras-attention/data/human_vocab.json', padding=50)\n",
        "    output_vocab = Vocabulary('/content/keras-attention/data/machine_vocab.json',padding=50)\n",
        "    print('Loading datasets.')\n",
        "\n",
        "    #training = Data('./data/training.csv', input_vocab, output_vocab)\n",
        "    #validation = Data('./data/validation.csv', input_vocab, output_vocab)\n",
        "    training = Data('/content/keras-attention/data/training.csv', input_vocab, output_vocab)\n",
        "    validation = Data('/content/keras-attention/data/validation.csv', input_vocab, output_vocab)\n",
        "    \n",
        "    training.load()\n",
        "    validation.load()\n",
        "    training.transform()\n",
        "    validation.transform()\n",
        "\n",
        "    print('Datasets Loaded.')\n",
        "    print('Compiling Model.')\n",
        "    model = simpleNMT(pad_length=50,\n",
        "                      n_chars=input_vocab.size(),\n",
        "                      n_labels=output_vocab.size(),\n",
        "                      embedding_learnable=False,\n",
        "                      encoder_units=256,\n",
        "                      decoder_units=256,\n",
        "                      trainable=True,\n",
        "                      return_probabilities=False)\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', all_acc])\n",
        "    print('Model Compiled.')\n",
        "    print('Training. Ctrl+C to end early.')\n",
        "\n",
        "    try:\n",
        "        model.fit_generator(generator=training.generator(32),\n",
        "                            steps_per_epoch=100,\n",
        "                            validation_data=validation.generator(32),\n",
        "                            validation_steps=100,\n",
        "                            callbacks=[cp],\n",
        "                            workers=1,\n",
        "                            verbose=1,\n",
        "                            epochs=1) #100?\n",
        "\n",
        "    except KeyboardInterrupt as e:\n",
        "        print('Model training stopped early.')\n",
        "\n",
        "    print('Model training complete.')\n",
        "\n",
        "    predicted = run_examples(model, input_vocab, output_vocab)\n",
        "    print('len(predicted): ', len(predicted))\n",
        "    print('np.array(predicted).shape: ', np.array(predicted).shape)\n",
        "    print('predicted[0]: ', predicted[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJvPDxN9DpNS",
        "colab_type": "code",
        "outputId": "f901cdd5-ff32-439e-e1ae-8388c56be91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # named_args = parser.add_argument_group('named arguments')\n",
        "    \n",
        "    # DEF_EPOCHS = 5 #50\n",
        "\n",
        "    # named_args.add_argument('-e', '--epochs', metavar='|',\n",
        "    #                         help=\"\"\"Number of Epochs to Run\"\"\",\n",
        "    #                         required=False, default=DEF_EPOCHS, type=int)\n",
        "\n",
        "    # named_args.add_argument('-g', '--gpu', metavar='|',\n",
        "    #                         help=\"\"\"GPU to use\"\"\",\n",
        "    #                         required=False, default='0', type=str)\n",
        "\n",
        "    # named_args.add_argument('-p', '--padding', metavar='|',\n",
        "    #                         help=\"\"\"Amount of padding to use\"\"\",\n",
        "    #                         required=False, default=DEF_EPOCHS, type=int)\n",
        "\n",
        "    # named_args.add_argument('-t', '--training-data', metavar='|',\n",
        "    #                         help=\"\"\"Location of training data\"\"\",\n",
        "    #                         required=False, default='./data/training.csv')\n",
        "\n",
        "    # named_args.add_argument('-v', '--validation-data', metavar='|',\n",
        "    #                         help=\"\"\"Location of validation data\"\"\",\n",
        "    #                         required=False, default='./data/validation.csv')\n",
        "\n",
        "    # named_args.add_argument('-b', '--batch-size', metavar='|',\n",
        "    #                         help=\"\"\"Location of validation data\"\"\",\n",
        "    #                         required=False, default=32, type=int)\n",
        "    # args = parser.parse_args()\n",
        "    # print(args)\n",
        "    \n",
        "    #main(args)\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main!\n",
            "vocabulary_file: /content/keras-attention/data/human_vocab.json\n",
            "vocabulary_file: /content/keras-attention/data/machine_vocab.json\n",
            "Loading datasets.\n",
            "Data.load len(inputs):  50000\n",
            "Data.load len(targets):  50000\n",
            "Data.load (inputs[0]):  12, sept. 2010\n",
            "Data.load (targets[0]):  2010-09-12\n",
            "Data.load len(inputs):  100\n",
            "Data.load len(targets):  100\n",
            "Data.load (inputs[0]):  18 mar. 1990\n",
            "Data.load (targets[0]):  1990-03-18\n",
            "Data.transform len(inputs):  50000\n",
            "Data.transform len(targets):  50000\n",
            "Data.transform np.array(inputs):  [[1027 1305  165 ... 1333 1333 1333]\n",
            " [ 372 1141  827 ... 1333 1333 1333]\n",
            " [ 580  493  372 ... 1333 1333 1333]\n",
            " ...\n",
            " [1027  295  493 ... 1333 1333 1333]\n",
            " [1043 1184  355 ... 1333 1333 1333]\n",
            " [1027  493 1304 ... 1333 1333 1333]]\n",
            "Data.transform np.array(targets):  [[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]]\n",
            "Data.transform np.array(inputs)shape:  (50000, 50)\n",
            "Data.transform np.array(targets)shape:  (50000, 50, 13)\n",
            "Data.transform (inputs[0]):  [1027 1305  165  493  426  293   58  263  889  493 1305 1304 1027 1304\n",
            " 1334 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333\n",
            " 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333\n",
            " 1333 1333 1333 1333 1333 1333 1333 1333]\n",
            "Data.transform (targets[0]):  [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "Data.transform len(inputs):  100\n",
            "Data.transform len(targets):  100\n",
            "Data.transform np.array(inputs):  [[1027  580  493 ... 1333 1333 1333]\n",
            " [1027 1305  493 ... 1333 1333 1333]\n",
            " [1027  318  493 ... 1333 1333 1333]\n",
            " ...\n",
            " [1027  944  493 ... 1333 1333 1333]\n",
            " [ 990  493  418 ... 1333 1333 1333]\n",
            " [1305  318  493 ... 1333 1333 1333]]\n",
            "Data.transform np.array(targets):  [[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]]\n",
            "Data.transform np.array(inputs)shape:  (100, 50)\n",
            "Data.transform np.array(targets)shape:  (100, 50, 13)\n",
            "Data.transform (inputs[0]):  [1027  580  493  565 1187    5  889  493 1027  295  295 1304 1334 1333\n",
            " 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333\n",
            " 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333 1333\n",
            " 1333 1333 1333 1333 1333 1333 1333 1333]\n",
            "Data.transform (targets[0]):  [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "Datasets Loaded.\n",
            "Compiling Model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "input_.shape:  (?, 50)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "simpleNMT n_chars: 1335 ,pad_length: 50 ,embedding_learnable: False ,weights: [array([[1., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 1., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 1., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 1., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 1.]])]\n",
            "simpleNMT rnn_encoded: Tensor(\"bidirectional_1/concat:0\", shape=(?, ?, 512), dtype=float32)\n",
            "AttentionDecoder init\n",
            "AttentionDecoder build:\n",
            "AttentionDecoder call:\n",
            "AttentionDecoder get_initial_state:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder compute_output_shape:\n",
            "simpleNMT decoder_units: 256 n_labels: 13 ,return_probabilities: False ,trainable: True\n",
            "simpleNMT y_hat: Tensor(\"attention_decoder_1/transpose_4:0\", shape=(?, ?, 13), dtype=float32)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "OneHot (Embedding)           (None, 50, 1335)          1782225   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 512)           3260416   \n",
            "_________________________________________________________________\n",
            "attention_decoder_1 (Attenti (None, 50, 13)            938934    \n",
            "=================================================================\n",
            "Total params: 5,981,575\n",
            "Trainable params: 4,199,350\n",
            "Non-trainable params: 1,782,225\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model Compiled.\n",
            "Training. Ctrl+C to end early.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 61s 607ms/step - loss: 0.5544 - acc: 0.8308 - all_acc: 0.0000e+00 - val_loss: 0.3430 - val_acc: 0.8754 - val_all_acc: 0.0000e+00\n",
            "Model training complete.\n",
            "~~~~~\n",
            "text:  26th January 2016 ,encoded: [1305, 416, 263, 1094, 493, 1242, 1187, 841, 1184, 1187, 5, 119, 493, 1305, 1304, 1027, 416, 1334, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333, 1333]\n",
            "run_example.prediction: [ 0  4  4  9  9  9  9  9  0  7 12 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11]\n",
            "run_example.decoded: ['1', '9', '9', '-', '-', '-', '-', '-', '1', '2', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>'] ,prediction: [ 0  4  4  9  9  9  9  9  0  7 12 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11]\n",
            "input: 26th January 2016\n",
            "output: 199-----12<eot><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
            "~~~~~\n",
            "input: 3 April 1989\n",
            "output: 199-----12<eot><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
            "~~~~~\n",
            "input: 5 Dec 09\n",
            "output: 199-----12<eot><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
            "~~~~~\n",
            "input: Sat 8 Jun 2017\n",
            "output: 199-----12<eot><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
            "len(predicted):  4\n",
            "np.array(predicted).shape:  (4,)\n",
            "predicted[0]:  199-----12<eot><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKrY4Hi22CE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import argparse\n",
        "#import os\n",
        "#import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "#from models.NMT import simpleNMT\n",
        "#from utils.examples import run_example\n",
        "#from data.reader import Vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2AHsWfi2Efn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1c6cc8b1-2d92-45b7-84ba-86b70088aea0"
      },
      "source": [
        "\n",
        "#HERE = os.path.realpath(os.path.join(os.path.realpath(__file__), '..'))\n",
        "HERE = os.path.realpath(os.path.join(os.path.abspath(''), '..'))\n",
        "print('HERE:', HERE)\n",
        "HERE = '/content/keras-attention'\n",
        "print('HERE:', HERE)\n",
        "\n",
        "def load_examples(file_name):\n",
        "    with open(file_name) as f:\n",
        "        return [s.replace('\\n', '') for s in f.readlines()]\n",
        "\n",
        "# create a directory if it doesn't already exist\n",
        "if not os.path.exists(os.path.join(HERE, 'attention_maps')):\n",
        "    os.makedirs(os.path.join(HERE, 'attention_maps'))\n",
        "\n",
        "SAMPLE_HUMAN_VOCAB = os.path.join(HERE, 'data', 'sample_human_vocab.json')\n",
        "SAMPLE_MACHINE_VOCAB = os.path.join(HERE, 'data', 'sample_machine_vocab.json')\n",
        "SAMPLE_WEIGHTS = os.path.join(HERE, 'weights', 'sample_NMT.49.0.01.hdf5')\n",
        "\n",
        "class Visualizer(object):\n",
        "\n",
        "    def __init__(self,\n",
        "                 padding=None,\n",
        "                 input_vocab=SAMPLE_HUMAN_VOCAB,\n",
        "                 output_vocab=SAMPLE_MACHINE_VOCAB):\n",
        "        \"\"\"\n",
        "            Visualizes attention maps\n",
        "            :param padding: the padding to use for the sequences.\n",
        "            :param input_vocab: the location of the input human\n",
        "                                vocabulary file\n",
        "            :param output_vocab: the location of the output \n",
        "                                 machine vocabulary file\n",
        "        \"\"\"\n",
        "        self.padding = padding\n",
        "        self.input_vocab = Vocabulary(\n",
        "            input_vocab, padding=padding)\n",
        "        self.output_vocab = Vocabulary(\n",
        "            output_vocab, padding=padding)\n",
        "\n",
        "    def set_models(self, pred_model, proba_model):\n",
        "        \"\"\"\n",
        "            Sets the models to use\n",
        "            :param pred_model: the prediction model\n",
        "            :param proba_model: the model that outputs the activation maps\n",
        "        \"\"\"\n",
        "        self.pred_model = pred_model\n",
        "        self.proba_model = proba_model\n",
        "\n",
        "    def attention_map(self, text, idx):\n",
        "        \"\"\"\n",
        "            Text to visualze attention map for.\n",
        "        \"\"\"\n",
        "        # encode the string\n",
        "        d = self.input_vocab.string_to_int(text)\n",
        "\n",
        "        # get the output sequence\n",
        "        predicted_text = run_example(\n",
        "            self.pred_model, self.input_vocab, self.output_vocab, text, idx)\n",
        "\n",
        "        text_ = list(text) + ['<eot>'] + ['<unk>'] * self.input_vocab.padding\n",
        "        # get the lengths of the string\n",
        "        input_length = len(text)+1\n",
        "        output_length = predicted_text.index('<eot>')+1\n",
        "        # get the activation map\n",
        "        activation_map = np.squeeze(self.proba_model.predict(np.array([d])))[\n",
        "            0:output_length, 0:input_length]\n",
        "\n",
        "        # import seaborn as sns\n",
        "        plt.clf()\n",
        "        f = plt.figure(figsize=(8, 8.5))\n",
        "        ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "        # add image\n",
        "        i = ax.imshow(activation_map, interpolation='nearest', cmap='gray')\n",
        "        \n",
        "        # add colorbar\n",
        "        cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "        cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
        "        cbar.ax.set_xlabel('Probability', labelpad=2)\n",
        "\n",
        "        # add labels\n",
        "        ax.set_yticks(range(output_length))\n",
        "        ax.set_yticklabels(predicted_text[:output_length])\n",
        "        \n",
        "        ax.set_xticks(range(input_length))\n",
        "        ax.set_xticklabels(text_[:input_length], rotation=45)\n",
        "        \n",
        "        ax.set_xlabel('Input Sequence')\n",
        "        ax.set_ylabel('Output Sequence')\n",
        "\n",
        "        # add grid and legend\n",
        "        ax.grid()\n",
        "        # ax.legend(loc='best')\n",
        "\n",
        "        f.savefig(os.path.join(HERE, 'attention_maps', text.replace('/', '')+'.pdf'), bbox_inches='tight')\n",
        "        f.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HERE: /content\n",
            "HERE: /content/keras-attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TXhicNT2wdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(examples, args):\n",
        "    print('Total Number of Examples:', len(examples))\n",
        "    weights_file = os.path.expanduser(SAMPLE_WEIGHTS)\n",
        "    print('Weights loading from:', weights_file)\n",
        "    viz = Visualizer(padding=50,\n",
        "                     input_vocab=SAMPLE_HUMAN_VOCAB,\n",
        "                     output_vocab=SAMPLE_MACHINE_VOCAB)\n",
        "    print('Loading models')\n",
        "    pred_model = simpleNMT(trainable=False,\n",
        "                           pad_length=50,\n",
        "                           n_chars=viz.input_vocab.size(),\n",
        "                           n_labels=viz.output_vocab.size())\n",
        "\n",
        "    pred_model.load_weights(weights_file, by_name=True)\n",
        "    pred_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    proba_model = simpleNMT(trainable=False,\n",
        "                            pad_length=50,\n",
        "                            n_chars=viz.input_vocab.size(),\n",
        "                            n_labels=viz.output_vocab.size(),\n",
        "                            return_probabilities=True)\n",
        "\n",
        "    proba_model.load_weights(weights_file, by_name=True)\n",
        "    proba_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    viz.set_models(pred_model, proba_model)\n",
        "\n",
        "    print('Models loaded')\n",
        "\n",
        "    idx = 0\n",
        "    for example in examples:\n",
        "        viz.attention_map(example, idx)\n",
        "        idx = idx + 1\n",
        "\n",
        "    print('Completed visualizations')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61MDCJ7p2CM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3339bf6f-ec76-4c22-a2e3-feeca8d332e8"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    args = ''\n",
        "    args_exam = 'examples.txt';\n",
        "    if args_exam.find('.txt') > 0:\n",
        "        examples = load_examples(args_exam)\n",
        "    else:\n",
        "        examples = [args_exam]\n",
        "\n",
        "    main(examples, args)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Examples: 10\n",
            "Weights loading from: /content/keras-attention/weights/sample_NMT.49.0.01.hdf5\n",
            "vocabulary_file: /content/keras-attention/data/sample_human_vocab.json\n",
            "vocabulary_file: /content/keras-attention/data/sample_machine_vocab.json\n",
            "Loading models\n",
            "input_.shape:  (?, 50)\n",
            "simpleNMT n_chars: 1426 ,pad_length: 50 ,embedding_learnable: False ,weights: [array([[1., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 1., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 1., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 1., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 1.]])]\n",
            "simpleNMT rnn_encoded: Tensor(\"bidirectional_1_3/concat:0\", shape=(?, ?, 512), dtype=float32)\n",
            "AttentionDecoder init\n",
            "AttentionDecoder build:\n",
            "AttentionDecoder call:\n",
            "AttentionDecoder get_initial_state:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder compute_output_shape:\n",
            "simpleNMT decoder_units: 256 n_labels: 13 ,return_probabilities: False ,trainable: False\n",
            "simpleNMT y_hat: Tensor(\"attention_decoder_1_3/transpose_4:0\", shape=(?, ?, 13), dtype=float32)\n",
            "input_.shape:  (?, 50)\n",
            "simpleNMT n_chars: 1426 ,pad_length: 50 ,embedding_learnable: False ,weights: [array([[1., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 1., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 1., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 1., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 1.]])]\n",
            "simpleNMT rnn_encoded: Tensor(\"bidirectional_1_4/concat:0\", shape=(?, ?, 512), dtype=float32)\n",
            "AttentionDecoder init\n",
            "AttentionDecoder build:\n",
            "AttentionDecoder call:\n",
            "AttentionDecoder get_initial_state:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder compute_output_shape:\n",
            "simpleNMT decoder_units: 256 n_labels: 13 ,return_probabilities: True ,trainable: False\n",
            "simpleNMT y_hat: Tensor(\"attention_decoder_1_4/transpose_4:0\", shape=(?, ?, 50, 1), dtype=float32)\n",
            "Models loaded\n",
            "text:  January 5 2016 ,encoded: [635, 919, 657, 739, 919, 970, 640, 880, 1100, 880, 593, 1345, 251, 363, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "run_example.prediction: [ 8  5 10  0  1  5 10  1  5  7 12 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11]\n",
            "run_example.decoded: ['2', '0', '1', '6', '-', '0', '1', '-', '0', '5', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>'] ,prediction: [ 8  5 10  0  1  5 10  1  5  7 12 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11]\n",
            "Completed visualizations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAHSCAYAAACXeAMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkjoGA0mS1DEYSJKkzv8DRj/tCaSFTQkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x612 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}