{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-attention-visualize.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNRdqf86o3Lu",
        "colab_type": "code",
        "outputId": "9f021bb3-790e-4de3-95fd-4c4a66088905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "#https://github.com/likejazz/jupyter-notebooks/tree/master/deep-learning/keras-attention\n",
        "#>> https://github.com/datalogue/keras-attention.git\n",
        "\n",
        "!git clone https://github.com/jukyellow/keras-attention.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-attention'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 154 (delta 4), reused 0 (delta 0), pack-reused 143\n",
            "Receiving objects: 100% (154/154), 15.63 MiB | 7.76 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpf4FCHspulb",
        "colab_type": "code",
        "outputId": "dd1f5ca0-51b0-4c16-c66e-c2e4664859ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "ls -alrt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Oct 25 16:58 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Oct 30 15:14 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Nov  3 08:42 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Nov  3 08:44 \u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 7 root root 4096 Nov  3 08:44 \u001b[01;34mkeras-attention\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0iMOqCLpxAc",
        "colab_type": "code",
        "outputId": "e854b7ec-0495-4847-e457-62d500c864f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd keras-attention"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I2ykBDmo4I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -r requirements-gpu.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUC-UxSo4P2",
        "colab_type": "code",
        "outputId": "1a41e818-fe88-4acd-b9a3-297b7efd1c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.17.3)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: tensorflow>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: keras>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.8.0)\n",
            "Collecting Faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ed/2fd5337ed405c4258dde1254e60f4e8ef9f1787576c0a2cd0d750b1716a6/Faker-2.0.3-py2.py3-none-any.whl (892kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel>=1.3->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.4->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.4->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from Faker->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from Faker->-r requirements.txt (line 6)) (1.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 7)) (2.4.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.1.0->-r requirements.txt (line 3)) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.1.0->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.1.0->-r requirements.txt (line 3)) (0.16.0)\n",
            "Installing collected packages: Faker\n",
            "Successfully installed Faker-2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v7xlzOOqKv2",
        "colab_type": "code",
        "outputId": "bee7a124-25ea-40f3-dd28-76e4f9022b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "ls -alrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 100\n",
            "drwxr-xr-x 1 root root  4096 Oct 31 16:45 \u001b[0m\u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 34520 Oct 31 16:45 LICENSE\n",
            "-rw-r--r-- 1 root root  1157 Oct 31 16:45 .gitignore\n",
            "-rw-r--r-- 1 root root  3968 Oct 31 16:45 run.py\n",
            "-rw-r--r-- 1 root root    76 Oct 31 16:45 requirements.txt\n",
            "-rw-r--r-- 1 root root    80 Oct 31 16:45 requirements-gpu.txt\n",
            "-rw-r--r-- 1 root root  4329 Oct 31 16:45 README.md\n",
            "drwxr-xr-x 2 root root  4096 Oct 31 16:45 \u001b[01;34mmodels\u001b[0m/\n",
            "-rw-r--r-- 1 root root     0 Oct 31 16:45 __init__.py\n",
            "-rw-r--r-- 1 root root   140 Oct 31 16:45 examples.txt\n",
            "drwxr-xr-x 2 root root  4096 Oct 31 16:45 \u001b[01;34mdata\u001b[0m/\n",
            "drwxr-xr-x 2 root root  4096 Oct 31 16:45 \u001b[01;34mweights\u001b[0m/\n",
            "-rw-r--r-- 1 root root  6341 Oct 31 16:45 visualize.py\n",
            "drwxr-xr-x 2 root root  4096 Oct 31 16:45 \u001b[01;34mutils\u001b[0m/\n",
            "drwxr-xr-x 7 root root  4096 Oct 31 16:45 \u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 8 root root  4096 Oct 31 16:45 \u001b[01;34m.git\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6a6nrmpGga",
        "colab_type": "code",
        "outputId": "c95007c9-7273-4fe0-f50c-ab829d6643f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!python data/generate.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating dataset\n",
            "dataset created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vO6Y50t4tKM",
        "colab_type": "code",
        "outputId": "9b865690-c0dc-4962-a289-af76efcdc7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "ls -alrt\n",
        "#ex) validation.csv\n",
        "#\"17.02.72\",\"1972-02-17\"\n",
        "#\"9 JULIO, 2013\",\"2013-07-09\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 15360\n",
            "-rw-r--r-- 1 root root      115 Nov  3 08:44 sample_machine_vocab.json\n",
            "-rw-r--r-- 1 root root    21714 Nov  3 08:44 sample_human_vocab.json\n",
            "-rw-r--r-- 1 root root     4822 Nov  3 08:44 reader.py\n",
            "-rw-r--r-- 1 root root     3549 Nov  3 08:44 generate.py\n",
            "drwxr-xr-x 7 root root     4096 Nov  3 08:44 \u001b[0m\u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 15614604 Nov  3 08:45 training.csv\n",
            "-rw-r--r-- 1 root root      115 Nov  3 08:45 machine_vocab.json\n",
            "-rw-r--r-- 1 root root    21153 Nov  3 08:45 human_vocab.json\n",
            "drwxr-xr-x 2 root root     4096 Nov  3 08:45 \u001b[01;34m.\u001b[0m/\n",
            "-rw-r--r-- 1 root root    30994 Nov  3 08:45 validation.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq6WU5adpLzr",
        "colab_type": "code",
        "outputId": "c708a5aa-d7d2-4970-9aa3-fa0174fb3127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#epochs default 50! but long time, I set 5 times\n",
        "\n",
        "!python run.py  #fit하면서 ModelCheckpoint로 weights값을 저장해둠"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Namespace(batch_size=32, epochs=5, gpu='0', padding=5, training_data='./data/training.csv', validation_data='./data/validation.csv')\n",
            "Loading datasets.\n",
            "Datasets Loaded.\n",
            "Compiling Model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-11-03 10:13:52.680742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-11-03 10:13:52.681036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18a9640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-03 10:13:52.681068: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-03 10:13:52.686815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-03 10:13:52.813635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:52.814440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x114ae1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-03 10:13:52.814472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-11-03 10:13:52.815750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:52.816471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-03 10:13:52.828434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-03 10:13:53.025109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-03 10:13:53.106830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-03 10:13:53.129056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-03 10:13:53.335023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-03 10:13:53.461027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-03 10:13:53.837587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-03 10:13:53.837906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:53.838835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:53.839648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-03 10:13:53.843504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-03 10:13:53.845132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-03 10:13:53.845190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-03 10:13:53.845210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-03 10:13:53.846585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:53.847540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-03 10:13:53.848354: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-11-03 10:13:53.848429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "AttentionDecoder init\n",
            "AttentionDecoder build:\n",
            "AttentionDecoder call:\n",
            "AttentionDecoder get_initial_state:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder step:\n",
            "AttentionDecoder compute_output_shape:\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "OneHot (Embedding)           (None, 5, 1402)           1965604   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 5, 512)            3397632   \n",
            "_________________________________________________________________\n",
            "attention_decoder_1 (Attenti (None, 5, 13)             938934    \n",
            "=================================================================\n",
            "Total params: 6,302,170\n",
            "Trainable params: 4,336,566\n",
            "Non-trainable params: 1,965,604\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model Compiled.\n",
            "Training. Ctrl+C to end early.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "2019-11-03 10:14:02.801592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 1.3012 - acc: 0.4757 - all_acc: 0.0000e+00 - val_loss: 1.0684 - val_acc: 0.4979 - val_all_acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0741 - acc: 0.4911 - all_acc: 0.0000e+00 - val_loss: 1.0742 - val_acc: 0.4926 - val_all_acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0669 - acc: 0.4993 - all_acc: 0.0000e+00 - val_loss: 1.0586 - val_acc: 0.4976 - val_all_acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 1.0621 - acc: 0.5007 - all_acc: 0.0000e+00 - val_loss: 1.0680 - val_acc: 0.4957 - val_all_acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0657 - acc: 0.4933 - all_acc: 0.0000e+00 - val_loss: 1.0781 - val_acc: 0.5011 - val_all_acc: 0.0000e+00\n",
            "Model training complete.\n",
            "~~~~~\n",
            "input: 26th January 2016\n",
            "output: 1984<eot>\n",
            "~~~~~\n",
            "input: 3 April 1989\n",
            "output: 1984<eot>\n",
            "~~~~~\n",
            "input: 5 Dec 09\n",
            "output: 1984<eot>\n",
            "~~~~~\n",
            "input: Sat 8 Jun 2017\n",
            "output: 1984<eot>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0s2_luBBycQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzn8urCQbc7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "1d6a0220-7de7-49ff-9a30-8b8cd7e5e0b3"
      },
      "source": [
        "#https://github.com/jukyellow/keras-attention/blob/master/visualize.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "from models.NMT import simpleNMT\n",
        "from utils.examples import run_example\n",
        "from data.reader import Vocabulary"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnj4uG2ebdtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f7fc28f6-d46e-4a49-e9bc-0cb42025905b"
      },
      "source": [
        "#HERE = os.path.realpath(os.path.join(os.path.realpath(__file__), '..'))\n",
        "HERE = os.path.realpath(os.path.join(os.path.abspath(''), '..'))\n",
        "print('HERE: ', HERE)\n",
        "\n",
        "def load_examples(file_name):\n",
        "    with open(file_name) as f:\n",
        "        return [s.replace('\\n', '') for s in f.readlines()]\n",
        "\n",
        "# create a directory if it doesn't already exist\n",
        "if not os.path.exists(os.path.join(HERE, 'attention_maps')):\n",
        "    os.makedirs(os.path.join(HERE, 'attention_maps'))\n",
        "\n",
        "SAMPLE_HUMAN_VOCAB = os.path.join(HERE, 'keras-attention/data', 'sample_human_vocab.json')\n",
        "SAMPLE_MACHINE_VOCAB = os.path.join(HERE, 'keras-attention/data', 'sample_machine_vocab.json')\n",
        "#이미 커밋된 weights값으로 테스트함...\n",
        "SAMPLE_WEIGHTS = os.path.join(HERE, 'keras-attention/weights', 'sample_NMT.49.0.01.hdf5')     \n",
        "print('SAMPLE_HUMAN_VOCAB:',SAMPLE_HUMAN_VOCAB)\n",
        "\n",
        "class Visualizer(object):\n",
        "\n",
        "    def __init__(self,\n",
        "                 padding=None,\n",
        "                 input_vocab=SAMPLE_HUMAN_VOCAB,\n",
        "                 output_vocab=SAMPLE_MACHINE_VOCAB):\n",
        "        \"\"\"\n",
        "            Visualizes attention maps\n",
        "            :param padding: the padding to use for the sequences.\n",
        "            :param input_vocab: the location of the input human\n",
        "                                vocabulary file\n",
        "            :param output_vocab: the location of the output \n",
        "                                 machine vocabulary file\n",
        "        \"\"\"\n",
        "        self.padding = padding\n",
        "        self.input_vocab = Vocabulary(\n",
        "            input_vocab, padding=padding)\n",
        "        self.output_vocab = Vocabulary(\n",
        "            output_vocab, padding=padding)\n",
        "\n",
        "    def set_models(self, pred_model, proba_model):\n",
        "        \"\"\"\n",
        "            Sets the models to use\n",
        "            :param pred_model: the prediction model\n",
        "            :param proba_model: the model that outputs the activation maps\n",
        "        \"\"\"\n",
        "        self.pred_model = pred_model\n",
        "        self.proba_model = proba_model\n",
        "\n",
        "    def attention_map(self, text):\n",
        "        \"\"\"\n",
        "            Text to visualze attention map for.\n",
        "        \"\"\"\n",
        "        # encode the string\n",
        "        d = self.input_vocab.string_to_int(text)\n",
        "        print('d: ', d)\n",
        "\n",
        "        # get the output sequence\n",
        "        predicted_text = run_example(self.pred_model, self.input_vocab, self.output_vocab, text)\n",
        "        print('predicted_text: ', predicted_text)\n",
        "\n",
        "        text_ = list(text) + ['<eot>'] + ['<unk>'] * self.input_vocab.padding\n",
        "        # get the lengths of the string\n",
        "        input_length = len(text)+1\n",
        "        output_length = predicted_text.index('<eot>')+1\n",
        "        # get the activation map\n",
        "        activation_map = np.squeeze(self.proba_model.predict(np.array([d])))[0:output_length, 0:input_length]\n",
        "        print('activation_map: ', activation_map)\n",
        "        # [[1.04707105e-05 1.22802967e-05 8.08871482e-06 2.06340337e-05\n",
        "        #   9.13377789e-06 8.17141245e-06 2.89358250e-05 1.30348863e-05\n",
        "        #   3.70874773e-06 1.70587246e-05 7.16923250e-06 4.97975234e-05\n",
        "        #   4.53671564e-05 2.57728461e-05 2.45305255e-05 3.59793594e-05\n",
        "        #   1.75800902e-04 3.21106811e-04 2.58878747e-04 9.57598037e-04]\n",
        "        # [2.88392557e-03 2.04139692e-03 8.94600758e-04 1.82232610e-03\n",
        "        #  ...\n",
        "\n",
        "        # import seaborn as sns\n",
        "        plt.clf()\n",
        "        f = plt.figure(figsize=(8, 8.5))\n",
        "        ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "        # add image\n",
        "        i = ax.imshow(activation_map, interpolation='nearest', cmap='gray') #weight값을 회색으로 표시...\n",
        "        \n",
        "        # add colorbar\n",
        "        cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "        cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
        "        cbar.ax.set_xlabel('Probability', labelpad=2)\n",
        "\n",
        "        # add labels\n",
        "        ax.set_yticks(range(output_length))\n",
        "        ax.set_yticklabels(predicted_text[:output_length])\n",
        "        \n",
        "        ax.set_xticks(range(input_length))\n",
        "        ax.set_xticklabels(text_[:input_length], rotation=45)\n",
        "        \n",
        "        ax.set_xlabel('Input Sequence')\n",
        "        ax.set_ylabel('Output Sequence')\n",
        "\n",
        "        # add grid and legend\n",
        "        ax.grid()\n",
        "        # ax.legend(loc='best')\n",
        "\n",
        "        f.savefig(os.path.join(HERE, 'attention_maps', text.replace('/', '')+'.pdf'), bbox_inches='tight')\n",
        "        f.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HERE:  /content\n",
            "SAMPLE_HUMAN_VOCAB: /content/keras-attention/data/sample_human_vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCbtv3n0bdrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(examples, args):\n",
        "    print('Total Number of Examples:', len(examples))\n",
        "    weights_file = os.path.expanduser(SAMPLE_WEIGHTS)\n",
        "    print('Weights loading from:', weights_file)\n",
        "    viz = Visualizer(padding=50,\n",
        "                     input_vocab=SAMPLE_HUMAN_VOCAB,\n",
        "                     output_vocab=SAMPLE_MACHINE_VOCAB)\n",
        "    print('Loading models')\n",
        "    pred_model = simpleNMT(trainable=False,\n",
        "                           pad_length=50,\n",
        "                           n_chars=viz.input_vocab.size(),\n",
        "                           n_labels=viz.output_vocab.size())\n",
        "\n",
        "    pred_model.load_weights(weights_file, by_name=True)\n",
        "    pred_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    proba_model = simpleNMT(trainable=False,\n",
        "                            pad_length=50,\n",
        "                            n_chars=viz.input_vocab.size(),\n",
        "                            n_labels=viz.output_vocab.size(),\n",
        "                            return_probabilities=True)\n",
        "\n",
        "    proba_model.load_weights(weights_file, by_name=True)\n",
        "    proba_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    viz.set_models(pred_model, proba_model)\n",
        "\n",
        "    print('Models loaded')\n",
        "\n",
        "    for example in examples:\n",
        "        viz.attention_map(example)\n",
        "\n",
        "    print('Completed visualizations')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXZc07YbdB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa66fd64-09da-4b46-bba3-078987150cdb"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # named_args = parser.add_argument_group('named arguments')\n",
        "\n",
        "    # named_args.add_argument('-e', '--examples', metavar='|',\n",
        "    #                         help='Example string/file to visualize attention map for\n",
        "    #                                 If file, it must end with '.txt'',\n",
        "    #                         required=True)\n",
        "    # print('named_args: ', named_args)\n",
        "\n",
        "    # named_args.add_argument('-w', '--weights', metavar='|',\n",
        "    #                         help='Location of weights',\n",
        "    #                         required=False,\n",
        "    #                         default=SAMPLE_WEIGHTS)\n",
        "    # named_args.add_argument('-p', '--padding', metavar='|',\n",
        "    #                         help='Length of padding',\n",
        "    #                         required=False, default=50, type=int)\n",
        "    # named_args.add_argument('-hv', '--human-vocab', metavar='|',\n",
        "    #                         help='Path to the human vocabulary',\n",
        "    #                         required=False,\n",
        "    #                         default=SAMPLE_HUMAN_VOCAB,\n",
        "    #                         type=str)\n",
        "    # named_args.add_argument('-mv', '--machine-vocab', metavar='|',\n",
        "    #                         help='Path to the machine vocabulary',\n",
        "    #                         required=False,\n",
        "    #                         default=SAMPLE_MACHINE_VOCAB,\n",
        "    #                         type=str)\n",
        "    # args = parser.parse_args()\n",
        "    # print('args.examples: ', args.examples)\n",
        "    # if '.txt' in args.examples:\n",
        "    #     examples = load_examples(args.examples)\n",
        "\n",
        "    #parser = argparse.ArgumentParser()\n",
        "    #args = parser.parse_args()\n",
        "\n",
        "    args = ''\n",
        "    args_exam = 'examples.txt';\n",
        "    if args_exam.find('.txt') > 0:\n",
        "        examples = load_examples(args_exam)\n",
        "    else:\n",
        "        examples = [args_exam]\n",
        "\n",
        "    main(examples, args)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Examples: 10\n",
            "Weights loading from: /content/keras-attention/weights/sample_NMT.49.0.01.hdf5\n",
            "Loading models\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "inputs shape: (?, ?, 512)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "inputs shape: (?, ?, 512)\n",
            "Models loaded\n",
            "d:  [635, 919, 657, 739, 919, 970, 640, 880, 1100, 880, 593, 1345, 251, 363, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '6', '-', '0', '1', '-', '0', '5', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[3.63950785e-05 6.94214541e-05 5.30203179e-05 8.81299129e-05\n",
            "  1.73083303e-04 1.81027179e-04 3.73659750e-05 1.73229691e-05\n",
            "  2.19173398e-05 4.38164752e-05 9.49483510e-05 6.30074239e-04\n",
            "  1.04544184e-03 3.87195527e-04 8.39718967e-04]\n",
            " [5.03576221e-03 3.29270284e-03 3.26845958e-03 4.17170115e-03\n",
            "  3.78980348e-03 5.38507150e-03 2.21187272e-03 3.03212740e-03\n",
            "  1.89499476e-03 4.87292605e-03 8.63438286e-03 9.54403058e-02\n",
            "  5.85059598e-02 1.27936006e-02 9.01508611e-03]\n",
            " [6.78722290e-06 1.26640373e-06 2.58125215e-06 1.73341539e-06\n",
            "  9.33738590e-07 1.68475754e-06 1.51032498e-06 5.42185626e-06\n",
            "  5.61184333e-06 4.70926989e-06 6.65670132e-06 2.58141221e-03\n",
            "  9.89037156e-01 8.30919016e-03 6.75038291e-06]\n",
            " [4.67218888e-06 1.08582553e-05 1.53324015e-06 5.61398838e-06\n",
            "  5.81903521e-07 8.35061144e-07 2.41307191e-07 8.27792501e-09\n",
            "  9.20317461e-07 1.41220804e-08 5.16691401e-08 1.97455938e-06\n",
            "  1.81633517e-01 8.18186879e-01 1.21233439e-04]\n",
            " [7.09089488e-02 9.04019475e-01 4.21995996e-03 2.06955858e-02\n",
            "  9.07055073e-05 4.15961040e-05 1.68312617e-05 3.88219429e-10\n",
            "  2.00464137e-06 1.36936524e-08 3.90593959e-06 1.07143713e-07\n",
            "  2.49594443e-08 2.93341493e-08 5.60209052e-08]\n",
            " [5.77930808e-01 4.18791443e-01 1.21930183e-03 1.43626414e-03\n",
            "  2.23600491e-05 6.77209937e-06 5.83861511e-05 6.12294997e-08\n",
            "  3.51378985e-05 7.18241199e-06 4.89047263e-04 3.26916916e-06\n",
            "  1.90455580e-08 5.05310549e-09 6.67271127e-10]\n",
            " [7.45998994e-02 8.87564242e-01 4.03655414e-03 3.31520177e-02\n",
            "  4.06330364e-04 3.41927807e-05 4.15607174e-05 1.60614499e-09\n",
            "  1.55833099e-04 6.43937824e-07 5.54169083e-06 9.98583403e-08\n",
            "  7.69570434e-08 6.27799679e-08 2.87619315e-07]\n",
            " [5.83905540e-03 4.12421860e-03 5.42855014e-05 3.19113547e-04\n",
            "  2.96851558e-05 8.14801533e-05 9.45726759e-04 6.94202899e-05\n",
            "  9.87401724e-01 2.67400283e-05 2.41238973e-04 2.25402968e-04\n",
            "  1.99577727e-04 2.48219148e-04 3.80171878e-06]\n",
            " [1.49257397e-02 6.49980363e-03 2.74693914e-04 6.80603727e-04\n",
            "  1.09021646e-04 4.81651135e-04 5.25723491e-03 1.23014743e-03\n",
            "  9.64386880e-01 2.90370430e-04 4.92090266e-03 7.88312871e-04\n",
            "  1.83393513e-05 5.45195871e-05 9.54444772e-07]\n",
            " [5.28440205e-03 5.29214879e-03 6.60871592e-05 2.37138505e-04\n",
            "  1.63920286e-05 1.26028375e-04 1.64537854e-03 6.78328142e-05\n",
            "  9.84241068e-01 2.33971878e-05 1.29020261e-03 9.29212139e-04\n",
            "  1.69062230e-04 1.81422030e-04 1.31801039e-06]\n",
            " [9.27904993e-03 3.47036943e-02 4.69607720e-03 8.60476308e-03\n",
            "  4.18286258e-03 4.26799245e-03 1.15849590e-03 1.83649518e-05\n",
            "  1.68518233e-03 1.91918982e-04 1.13801355e-03 3.58730002e-04\n",
            "  7.68573955e-02 5.61521292e-01 1.00275554e-01]]\n",
            "d:  [593, 1345, 251, 363, 880, 635, 919, 657, 739, 919, 970, 640, 880, 1100, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '6', '-', '0', '1', '-', '0', '5', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.43528878e-05 1.23934651e-05 3.04947971e-05 2.38061170e-06\n",
            "  4.24404516e-06 4.42487726e-05 1.34076065e-04 1.17195093e-04\n",
            "  2.12404018e-04 4.57368529e-04 4.89082362e-04 3.45943234e-04\n",
            "  4.59431089e-04 4.98261070e-03 6.17064349e-03]\n",
            " [4.33554919e-03 5.46026975e-03 1.63910128e-02 2.11363984e-03\n",
            "  2.47783237e-03 4.59734397e-03 3.87659017e-03 4.08988679e-03\n",
            "  4.66214772e-03 4.63591609e-03 6.00581570e-03 5.38617931e-03\n",
            "  1.90952197e-02 4.58085015e-02 3.35727632e-02]\n",
            " [5.96929807e-04 2.53468682e-03 9.87807095e-01 6.20790618e-03\n",
            "  1.82227872e-04 7.75894441e-05 7.59558679e-06 7.90069953e-06\n",
            "  7.74980708e-06 5.12253973e-06 1.09226039e-05 2.33817991e-05\n",
            "  3.55054566e-04 1.66691805e-03 5.85312373e-05]\n",
            " [2.36723577e-06 3.76674029e-06 3.05667799e-02 9.69198763e-01\n",
            "  4.88342775e-05 8.70090371e-05 1.69731811e-05 5.63404626e-07\n",
            "  7.80143296e-07 1.16914016e-07 1.85230661e-07 1.79936904e-07\n",
            "  8.21966992e-08 3.59320547e-05 1.24149319e-05]\n",
            " [2.47900175e-07 1.43768989e-06 2.27666787e-05 2.61647569e-04\n",
            "  1.02266049e-05 2.65939385e-01 7.29402125e-01 1.09285989e-03\n",
            "  3.20721953e-03 3.23889726e-05 1.80740335e-05 6.70849158e-06\n",
            "  7.34664607e-10 3.54514350e-06 7.63636478e-07]\n",
            " [7.28579550e-07 3.98058319e-06 1.12069642e-06 2.76022661e-06\n",
            "  8.82624045e-06 3.68898809e-01 6.27656043e-01 1.58184534e-03\n",
            "  1.60433736e-03 9.79764591e-05 2.51648253e-05 9.76727097e-05\n",
            "  1.48651267e-07 2.00753220e-05 1.86898902e-07]\n",
            " [2.35449060e-09 1.93443994e-09 1.83302422e-08 1.10194328e-07\n",
            "  2.38249959e-06 2.14343905e-01 7.64297664e-01 6.65426115e-03\n",
            "  1.43315932e-02 3.44392756e-04 1.55397356e-05 7.95569758e-06\n",
            "  4.27089281e-10 6.73730653e-07 6.56925010e-07]\n",
            " [2.62892368e-04 1.37237529e-03 3.96978925e-04 7.06305495e-04\n",
            "  4.73939417e-06 6.16544858e-05 8.74660618e-05 3.27152202e-06\n",
            "  2.99866515e-05 1.66940808e-05 1.23090154e-04 1.04102714e-03\n",
            "  1.63105040e-04 9.95361388e-01 1.77595837e-04]\n",
            " [1.05967075e-02 4.27749706e-03 1.06134197e-04 4.06095467e-04\n",
            "  1.15630544e-04 7.76753877e-04 5.51184465e-04 7.15324350e-05\n",
            "  3.72530340e-04 3.30822426e-04 2.57923338e-03 1.56508926e-02\n",
            "  1.15818428e-02 9.48176742e-01 2.40281201e-03]\n",
            " [4.15732386e-04 3.66005203e-04 7.09960150e-05 9.53416311e-05\n",
            "  2.46239051e-06 5.96274840e-05 6.75403498e-05 5.04539457e-06\n",
            "  3.44613327e-05 1.18596363e-05 2.28065241e-04 3.30554368e-03\n",
            "  2.46635376e-04 9.94136572e-01 5.92101598e-04]\n",
            " [6.22338790e-04 6.94616901e-05 3.29133682e-03 2.89257063e-04\n",
            "  2.45506060e-04 1.99214332e-02 4.10344861e-02 4.59542684e-03\n",
            "  5.39634330e-03 2.78515229e-03 3.03796562e-03 1.71151571e-03\n",
            "  4.81931551e-04 2.43041649e-01 1.82140574e-01]]\n",
            "d:  [635, 919, 657, 739, 919, 970, 640, 880, 593, 1345, 251, 363, 880, 1100, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '6', '-', '0', '1', '-', '0', '2', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[4.50104708e-05 8.57388659e-05 5.35319086e-05 8.08918412e-05\n",
            "  1.25294668e-04 1.05193321e-04 2.43808245e-05 2.92184304e-05\n",
            "  3.56574601e-05 5.35242507e-05 1.37409035e-04 2.92027726e-05\n",
            "  1.23161488e-04 6.32212905e-04 1.98464026e-03]\n",
            " [4.29674378e-03 2.96325632e-03 2.62045697e-03 3.01676453e-03\n",
            "  2.69951927e-03 4.46304306e-03 2.05028104e-03 2.05793162e-03\n",
            "  2.60753860e-03 7.16000050e-03 1.46328062e-02 6.57347543e-03\n",
            "  2.23972574e-02 4.26435731e-02 1.91759430e-02]\n",
            " [7.82054703e-05 1.71395641e-05 3.82394028e-05 2.51215279e-05\n",
            "  1.69003815e-05 5.61500419e-05 2.77700565e-05 3.05937683e-05\n",
            "  6.01608008e-05 8.02910828e-04 8.84823084e-01 4.89010587e-02\n",
            "  2.55524479e-02 3.90327871e-02 5.73091820e-05]\n",
            " [7.69311300e-05 1.48933497e-04 1.44284877e-05 5.08466292e-05\n",
            "  3.23972813e-06 3.98935163e-06 6.72141141e-06 4.90987446e-08\n",
            "  2.56302997e-07 1.07482379e-06 2.32454203e-02 9.22497809e-01\n",
            "  2.28234596e-04 5.27598932e-02 7.68140890e-04]\n",
            " [1.22319505e-01 8.56459379e-01 2.82085664e-03 1.83125958e-02\n",
            "  2.57470419e-05 9.59352110e-06 4.47416714e-05 7.25261295e-10\n",
            "  1.32982407e-07 4.14287371e-07 3.73548886e-07 8.71107034e-07\n",
            "  1.26635119e-10 8.30792942e-07 8.37719540e-07]\n",
            " [6.18429601e-01 3.78285080e-01 1.27275172e-03 1.93059142e-03\n",
            "  1.41048786e-05 4.13231828e-06 5.02187941e-05 5.76882861e-08\n",
            "  4.67959489e-06 7.31752152e-06 1.87259232e-07 3.33559001e-07\n",
            "  1.15615084e-09 8.02682507e-07 1.56980846e-08]\n",
            " [8.54087621e-02 8.77930403e-01 3.84248141e-03 3.25376838e-02\n",
            "  1.70730680e-04 1.04459632e-05 7.66738085e-05 2.82655566e-09\n",
            "  1.55074773e-07 5.42852696e-08 5.62379796e-07 4.79644996e-07\n",
            "  1.75483228e-09 1.56768911e-05 1.87255068e-06]\n",
            " [1.56918824e-01 1.23483092e-01 1.68860890e-03 1.07451323e-02\n",
            "  7.82798859e-04 3.91455833e-03 1.62876546e-01 4.20247816e-04\n",
            "  5.89451827e-02 1.44130975e-01 1.90397725e-03 2.45629763e-03\n",
            "  4.63328819e-04 3.18537295e-01 3.05763038e-04]\n",
            " [1.19312078e-01 7.04215840e-02 4.21680976e-03 1.12782558e-02\n",
            "  2.29615578e-03 1.05206966e-02 1.20588288e-01 3.62849259e-03\n",
            "  3.08467478e-01 1.77483901e-01 4.27178165e-04 1.85901683e-03\n",
            "  1.06186175e-03 1.61830604e-01 2.41871880e-04]\n",
            " [3.64186876e-02 1.90244857e-02 7.64303608e-04 2.88816495e-03\n",
            "  1.85759520e-04 4.82614106e-03 8.79100263e-02 4.05228726e-04\n",
            "  2.73682982e-01 9.90339145e-02 1.20286853e-03 3.15216626e-03\n",
            "  6.87671243e-04 4.46357697e-01 3.23601038e-04]\n",
            " [1.96545962e-02 7.23253936e-02 7.62414932e-03 1.09993676e-02\n",
            "  4.18573106e-03 3.25656263e-03 2.08218163e-03 7.84460135e-05\n",
            "  1.05567288e-03 6.06617614e-05 1.52592512e-03 1.78612710e-03\n",
            "  9.67737578e-04 1.73188150e-01 2.30047002e-01]]\n",
            "d:  [635, 919, 657, 880, 1100, 880, 593, 1345, 251, 363, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '6', '-', '0', '1', '-', '0', '5', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.60470649e-04 1.96435445e-04 2.71174613e-05 1.12973330e-05\n",
            "  1.80660008e-05 3.38560858e-05 9.08923976e-05 7.34140805e-04\n",
            "  1.26097107e-03 3.02382337e-04 3.98917095e-04]\n",
            " [9.04740766e-03 4.37020324e-03 1.35630439e-03 3.59142106e-03\n",
            "  2.02017068e-03 4.15641861e-03 1.04398429e-02 1.07910052e-01\n",
            "  6.05818592e-02 6.70645619e-03 3.33191035e-03]\n",
            " [1.53851634e-05 1.19006609e-06 8.28420070e-07 9.44688418e-06\n",
            "  6.65540620e-06 4.78762558e-06 6.32732554e-06 3.12364101e-03\n",
            "  9.86306012e-01 1.05005186e-02 6.05099558e-06]\n",
            " [2.67421692e-05 1.14898676e-05 1.29526001e-07 8.89001317e-09\n",
            "  9.99091753e-07 6.75790401e-09 1.53829642e-08 6.16965906e-07\n",
            "  1.22653373e-01 8.77229810e-01 6.28575581e-05]\n",
            " [4.50305909e-01 5.49596190e-01 7.10214736e-05 1.67722825e-09\n",
            "  1.91052204e-05 3.46146329e-08 5.69852546e-06 1.48530859e-07\n",
            "  5.67145015e-08 5.15779632e-08 9.69475735e-08]\n",
            " [8.16869497e-01 1.81641892e-01 6.28045309e-05 5.65214350e-07\n",
            "  6.68005378e-04 2.00664308e-05 7.31168024e-04 5.90645004e-06\n",
            "  6.11644637e-08 1.10898659e-08 1.32625511e-09]\n",
            " [3.23442340e-01 6.74880147e-01 6.35204560e-05 1.12436762e-08\n",
            "  1.60443294e-03 8.20604669e-07 4.88479282e-06 4.89745879e-08\n",
            "  3.71639679e-08 3.48507747e-08 1.71737128e-07]\n",
            " [3.97016993e-03 5.93206054e-03 1.21759476e-04 8.82181266e-05\n",
            "  9.85976934e-01 3.97169351e-05 7.38877337e-04 1.00361893e-03\n",
            "  9.37893463e-04 7.18042254e-04 9.45703778e-06]\n",
            " [5.62198227e-03 4.86141257e-03 4.69500170e-04 1.22604461e-03\n",
            "  9.74968374e-01 2.97130144e-04 1.10882912e-02 1.23626448e-03\n",
            "  2.90530188e-05 6.26796318e-05 2.15692899e-06]\n",
            " [5.08300355e-03 9.97605454e-03 3.28495051e-04 1.39309283e-04\n",
            "  9.72317755e-01 4.88647202e-05 4.87939641e-03 4.40790458e-03\n",
            "  6.44884596e-04 4.97202447e-04 5.66318477e-06]\n",
            " [1.07379124e-01 1.12939075e-01 1.27333927e-03 2.81664852e-05\n",
            "  1.94084155e-03 2.43549672e-04 1.13241887e-03 2.68217875e-04\n",
            "  6.41530082e-02 4.52485859e-01 8.24473426e-02]]\n",
            "d:  [635, 880, 1100, 880, 593, 1345, 251, 363, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '6', '-', '0', '5', '-', '0', '5', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[4.02810110e-05 2.46167147e-05 5.55750230e-05 6.53076349e-05\n",
            "  1.94420194e-04 1.06633850e-03 4.94709052e-03 1.12789019e-03\n",
            "  7.53017608e-04]\n",
            " [2.20170314e-03 4.82458994e-03 3.39605403e-03 6.15781639e-03\n",
            "  1.31861968e-02 1.05199896e-01 8.84350389e-02 1.08458735e-02\n",
            "  5.84298931e-03]\n",
            " [8.52110861e-06 2.57622105e-05 1.87855694e-05 1.66124573e-05\n",
            "  2.13069252e-05 5.38355438e-03 9.82860804e-01 1.15986792e-02\n",
            "  1.20005989e-05]\n",
            " [7.01704494e-07 3.86928463e-08 4.12794361e-06 4.76194444e-08\n",
            "  9.02591921e-08 2.25057011e-06 1.31016076e-01 8.68795693e-01\n",
            "  1.39782511e-04]\n",
            " [7.36048460e-01 2.95437094e-05 1.81930944e-01 4.47500934e-04\n",
            "  6.87456802e-02 1.06661685e-03 5.01805218e-04 5.47799340e-04\n",
            "  7.33684865e-04]\n",
            " [2.74515599e-01 5.72231540e-04 3.00230801e-01 1.35087091e-02\n",
            "  4.07485753e-01 3.45534505e-03 1.09555083e-04 1.47293813e-05\n",
            "  2.55130180e-06]\n",
            " [2.18509600e-01 8.05121181e-06 7.77796328e-01 5.11017512e-04\n",
            "  2.96849548e-03 1.30763292e-05 7.15804163e-06 6.81226402e-06\n",
            "  2.69297980e-05]\n",
            " [6.23845076e-03 2.78483058e-04 9.90059495e-01 7.99923655e-05\n",
            "  7.68382684e-04 8.09148303e-04 5.50139579e-04 5.66822535e-04\n",
            "  1.14139384e-05]\n",
            " [1.18165528e-02 2.83382391e-03 9.74836230e-01 5.78281586e-04\n",
            "  8.41094553e-03 1.06456433e-03 3.00809788e-05 1.16710587e-04\n",
            "  3.57283307e-06]\n",
            " [5.06392866e-03 1.76293106e-04 9.88952935e-01 3.69314512e-05\n",
            "  2.14879005e-03 2.00365088e-03 3.18077189e-04 3.62142106e-04\n",
            "  3.55643306e-06]\n",
            " [2.32327566e-03 6.36316690e-05 4.00748802e-03 4.08527121e-04\n",
            "  1.82486186e-03 4.44841426e-04 9.01021808e-02 5.55396199e-01\n",
            "  1.09897330e-01]]\n",
            "d:  [635, 739, 549, 640, 880, 433, 862, 1364, 880, 251, 433, 363, 1283, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['1', '9', '8', '7', '-', '0', '7', '-', '0', '8', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.30927865e-05 1.95106695e-05 1.65902147e-05 3.71569490e-06\n",
            "  2.68724557e-06 1.51592749e-05 3.95321185e-05 1.89996535e-05\n",
            "  1.73810568e-05 6.29633796e-05 6.84894476e-05 1.32007306e-04\n",
            "  2.92359473e-04 4.15109127e-04]\n",
            " [3.72203678e-04 5.41868038e-04 6.25780842e-04 7.04040722e-05\n",
            "  5.57363892e-05 2.48386030e-04 2.74765468e-03 4.54889581e-04\n",
            "  5.73573867e-04 3.97686474e-03 1.29056973e-02 3.30524035e-02\n",
            "  9.12017655e-03 3.90844932e-03]\n",
            " [1.62707656e-05 1.26274172e-05 1.57144368e-05 8.28433883e-07\n",
            "  2.86042427e-06 8.97022692e-05 6.23130181e-04 7.42551993e-06\n",
            "  2.78607495e-05 6.64058665e-04 6.83908984e-02 7.90268362e-01\n",
            "  1.29736364e-01 1.27396220e-03]\n",
            " [1.10348185e-06 4.11805814e-07 1.58804042e-07 2.03625106e-07\n",
            "  3.99678646e-09 9.42115264e-07 4.44300241e-07 5.05390335e-06\n",
            "  3.02710212e-08 4.22798735e-07 5.30047000e-05 9.50668752e-03\n",
            "  9.87256467e-01 2.79339147e-03]\n",
            " [4.29560363e-01 4.34380770e-02 2.69883720e-04 6.71670423e-04\n",
            "  3.61510537e-08 1.54647933e-04 5.41863992e-05 5.25156260e-01\n",
            "  4.51206142e-06 3.39843653e-04 3.95632242e-06 7.70539259e-07\n",
            "  2.75080329e-05 7.00279406e-06]\n",
            " [2.49038637e-01 1.39445690e-02 8.98427912e-04 2.52388064e-02\n",
            "  3.10134259e-04 2.49876618e-01 1.54356798e-02 4.37429130e-01\n",
            "  6.41713792e-04 6.62648119e-03 4.60851006e-04 1.42831650e-05\n",
            "  2.12213363e-05 1.10555413e-06]\n",
            " [3.79529297e-01 2.11253539e-02 8.03126721e-04 1.20016355e-02\n",
            "  4.52609811e-06 8.74870084e-03 7.93344341e-04 5.73266983e-01\n",
            "  1.64831057e-04 2.00468302e-03 1.72870001e-04 9.02272041e-06\n",
            "  1.06324058e-03 2.28011795e-05]\n",
            " [9.79016796e-02 2.20731962e-02 1.25418212e-02 1.88935488e-01\n",
            "  2.70651584e-03 5.95163524e-01 6.57642842e-04 1.97678562e-02\n",
            "  2.61270645e-04 2.67278426e-03 2.63420027e-02 1.83375354e-03\n",
            "  9.44145769e-03 4.68114049e-05]\n",
            " [6.67438582e-02 1.53890355e-02 1.08903246e-02 1.28618717e-01\n",
            "  6.66388962e-03 6.58348501e-01 3.04567255e-03 2.73798183e-02\n",
            "  1.34996499e-03 2.54820101e-03 3.65239680e-02 2.32689618e-03\n",
            "  1.33881662e-02 1.83885059e-05]\n",
            " [8.44840929e-02 2.33266614e-02 1.28202522e-02 6.71693742e-01\n",
            "  3.36809928e-04 8.65426958e-02 2.60400644e-04 1.32827302e-02\n",
            "  1.25172955e-04 1.42698106e-03 1.66031756e-02 1.24197127e-03\n",
            "  3.79552599e-03 1.95572775e-05]\n",
            " [3.46518937e-03 1.21111411e-03 4.45727201e-04 3.72349023e-04\n",
            "  1.10106448e-05 1.34118029e-03 1.32363301e-03 6.27480028e-03\n",
            "  6.02581204e-05 6.31582050e-04 2.64257687e-04 3.86212021e-03\n",
            "  5.84885478e-02 1.15843676e-01]]\n",
            "d:  [635, 739, 657, 1333, 880, 433, 862, 1364, 880, 251, 433, 363, 1283, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['1', '9', '8', '7', '-', '0', '6', '-', '0', '8', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.47218496e-04 1.16022435e-04 3.85886160e-05 9.90893022e-06\n",
            "  3.40154634e-06 3.69964546e-05 5.23506496e-05 4.26335282e-05\n",
            "  2.62170579e-05 8.45337854e-05 2.05784454e-04 8.61783454e-04\n",
            "  1.47264078e-03 5.64156799e-04]\n",
            " [1.58739591e-03 6.79842138e-04 2.96630751e-04 7.72632557e-05\n",
            "  1.35195578e-05 1.09083419e-04 9.02787026e-04 2.63358903e-04\n",
            "  1.89054597e-04 1.78259017e-03 7.45301321e-03 2.16640588e-02\n",
            "  4.95147984e-03 2.38829642e-03]\n",
            " [4.88163023e-05 7.58307624e-06 6.65553989e-06 4.24924991e-07\n",
            "  9.42902659e-07 6.10424686e-05 3.94997100e-04 3.03191564e-06\n",
            "  8.23853679e-06 2.71441531e-04 6.32512569e-02 7.93186486e-01\n",
            "  1.36268154e-01 7.12486915e-04]\n",
            " [4.11441928e-04 2.40535101e-05 1.97847339e-06 1.04131182e-07\n",
            "  3.92603727e-09 1.31224601e-06 4.25718468e-07 4.89044987e-06\n",
            "  1.62161786e-08 3.11937896e-07 3.35317054e-05 7.32105877e-03\n",
            "  9.89097774e-01 2.76179146e-03]\n",
            " [9.86608803e-01 1.21677844e-02 9.51732291e-05 1.01768046e-06\n",
            "  1.08214833e-10 4.44328435e-07 8.47074020e-08 1.12492649e-03\n",
            "  5.66630254e-09 7.66786741e-07 3.81246723e-09 7.10099313e-10\n",
            "  2.93616349e-08 9.36987554e-09]\n",
            " [9.46592152e-01 1.47695467e-03 5.84884896e-04 1.39189753e-04\n",
            "  6.60193928e-06 2.97400355e-02 1.21556783e-04 2.10895538e-02\n",
            "  6.52559675e-06 2.32883773e-04 7.50472918e-06 2.05940140e-07\n",
            "  6.50688833e-07 3.07412087e-08]\n",
            " [9.56513643e-01 7.59206340e-03 2.57134158e-03 1.37657116e-04\n",
            "  1.59557310e-08 1.22899062e-03 7.07883155e-05 3.18542831e-02\n",
            "  3.87453724e-07 1.85595891e-05 2.55900858e-07 8.34754932e-09\n",
            "  1.37364395e-06 4.18656612e-07]\n",
            " [2.03373089e-01 1.39712095e-02 4.80761938e-03 1.20972740e-02\n",
            "  5.47192991e-04 6.75836563e-01 5.66596224e-04 1.21109057e-02\n",
            "  1.94931708e-04 3.05088540e-03 4.06120755e-02 2.36836751e-03\n",
            "  2.06511933e-02 4.28808889e-05]\n",
            " [6.82279840e-02 1.10055562e-02 8.45819619e-03 1.55661041e-02\n",
            "  3.98091832e-03 7.76204348e-01 1.41736632e-03 3.46706063e-02\n",
            "  9.40142258e-04 3.89182102e-03 4.18866016e-02 2.14259722e-03\n",
            "  1.37141505e-02 2.21824521e-05]\n",
            " [4.14227039e-01 6.03994615e-02 1.86597034e-02 8.41262266e-02\n",
            "  7.93707673e-04 2.64297366e-01 5.24482632e-04 3.07801366e-02\n",
            "  2.95486971e-04 4.74910485e-03 3.63798961e-02 2.65605981e-03\n",
            "  8.94878060e-03 5.40365472e-05]\n",
            " [8.20362791e-02 1.89251807e-02 2.49920343e-03 2.85112328e-04\n",
            "  7.71053146e-06 7.59004964e-04 6.31211617e-04 2.68174126e-03\n",
            "  3.86652027e-05 4.33578272e-04 2.67918862e-04 3.53819062e-03\n",
            "  5.45276888e-02 1.03504092e-01]]\n",
            "d:  [635, 739, 549, 640, 880, 433, 862, 1364, 880, 251, 928, 928, 928, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['1', '9', '9', '9', '-', '0', '7', '-', '0', '8', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.71245701e-05 2.31265603e-05 2.11297356e-05 5.47802529e-06\n",
            "  3.06643892e-06 1.86704838e-05 4.92984727e-05 2.46381551e-05\n",
            "  3.26602094e-05 7.69946419e-05 1.15597417e-04 3.69865185e-04\n",
            "  7.69220933e-04 3.64510342e-04]\n",
            " [1.98963768e-04 2.90074386e-04 2.99944484e-04 2.86787599e-05\n",
            "  1.86834568e-05 1.66610975e-04 2.32406682e-03 5.46106778e-04\n",
            "  8.40155757e-04 3.97201302e-03 7.77703337e-03 2.63261218e-02\n",
            "  6.28577871e-03 1.53974583e-03]\n",
            " [1.11222516e-06 8.68484790e-07 1.36401798e-06 1.05322201e-07\n",
            "  2.51367567e-07 1.47683331e-05 7.92800638e-05 1.42521378e-06\n",
            "  6.83727603e-06 4.70574487e-05 1.96559704e-03 9.56531703e-01\n",
            "  2.91824006e-02 1.92595355e-04]\n",
            " [7.67207720e-09 1.93978256e-09 6.89033108e-10 1.20414445e-09\n",
            "  2.26749175e-11 1.06850759e-08 6.10134387e-09 5.34395497e-08\n",
            "  4.76486128e-10 9.45362366e-09 1.80988859e-08 2.37602126e-05\n",
            "  9.99420941e-01 4.20139258e-04]\n",
            " [3.08205456e-01 2.00591665e-02 7.49055980e-05 1.01099562e-04\n",
            "  2.03740758e-08 6.25352550e-05 2.59275967e-05 6.70969188e-01\n",
            "  3.98445036e-06 1.51657310e-04 1.24300570e-07 1.55433888e-08\n",
            "  1.56351939e-06 3.63364165e-06]\n",
            " [2.51166552e-01 1.12725282e-02 8.08845740e-04 9.40722227e-03\n",
            "  2.57350475e-04 2.18756899e-01 9.38017108e-03 4.97993112e-01\n",
            "  2.54191022e-04 5.43240516e-04 7.10700260e-06 3.33567732e-06\n",
            "  3.35966797e-05 6.22411426e-06]\n",
            " [2.93845773e-01 1.03786960e-02 4.06212785e-04 4.59059933e-03\n",
            "  2.38226471e-06 6.68516057e-03 7.50677602e-04 6.81399643e-01\n",
            "  1.69997409e-04 1.72085117e-03 4.10598022e-06 9.98857175e-08\n",
            "  2.68991994e-06 5.93598259e-07]\n",
            " [9.10786167e-02 1.35508301e-02 7.46005308e-03 1.87609956e-01\n",
            "  2.10896996e-03 6.73817098e-01 3.72181705e-04 1.07437531e-02\n",
            "  1.62074575e-04 2.81167426e-03 3.80137004e-03 1.21277221e-03\n",
            "  5.59275912e-04 5.06503102e-06]\n",
            " [6.52756318e-02 1.15073351e-02 8.80991761e-03 1.19906984e-01\n",
            "  6.89349929e-03 7.49185085e-01 2.38085561e-03 2.29719710e-02\n",
            "  1.03621499e-03 3.13955452e-03 6.96135918e-03 3.30645446e-04\n",
            "  5.97694634e-05 1.67990876e-07]\n",
            " [1.12542748e-01 1.97254289e-02 1.02099348e-02 7.52716482e-01\n",
            "  3.66450229e-04 8.54619369e-02 1.23290694e-04 1.00811217e-02\n",
            "  7.14969283e-05 1.47674652e-03 2.24108133e-03 1.03939157e-04\n",
            "  7.19671661e-05 1.03548052e-06]\n",
            " [6.93565642e-04 2.01224480e-04 6.63780884e-05 4.43420831e-05\n",
            "  1.39578765e-06 2.79747765e-04 2.21752605e-04 1.74251932e-03\n",
            "  1.91857034e-05 1.49641855e-04 1.46933708e-05 1.37280251e-04\n",
            "  2.10324619e-02 6.08333312e-02]]\n",
            "d:  [635, 739, 657, 1333, 880, 433, 862, 1364, 880, 251, 928, 928, 928, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['1', '9', '9', '9', '-', '0', '6', '-', '0', '8', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[8.47520132e-05 7.63035569e-05 2.67126979e-05 6.72023771e-06\n",
            "  2.60378783e-06 2.27822384e-05 3.35248515e-05 3.02458175e-05\n",
            "  2.80343920e-05 7.37322043e-05 1.53111425e-04 6.53351715e-04\n",
            "  5.78183739e-04 1.30993489e-04]\n",
            " [1.29126466e-03 7.37277616e-04 2.45909003e-04 2.42283513e-05\n",
            "  4.87060061e-06 7.36201182e-05 8.62616173e-04 3.32317839e-04\n",
            "  2.69572804e-04 2.18714657e-03 4.31242073e-03 8.15555360e-03\n",
            "  3.19153839e-03 9.14017961e-04]\n",
            " [4.99813996e-06 1.31017850e-06 1.04948913e-06 6.97871769e-08\n",
            "  2.37477053e-07 2.39236142e-05 9.29530797e-05 1.06801372e-06\n",
            "  4.28531212e-06 3.39353537e-05 2.84414622e-03 9.63488102e-01\n",
            "  2.27845311e-02 7.96344611e-05]\n",
            " [1.70202679e-06 8.36091587e-08 4.56186111e-09 2.55082760e-10\n",
            "  1.72724005e-11 1.17871775e-08 5.68367620e-09 4.19252117e-08\n",
            "  1.63305286e-10 4.69532679e-09 1.01501216e-08 1.79721283e-05\n",
            "  9.99762714e-01 1.54661553e-04]\n",
            " [9.76784825e-01 1.87015031e-02 1.65573860e-04 8.29710928e-07\n",
            "  1.46823859e-10 5.65355208e-07 1.14958056e-07 4.34344541e-03\n",
            "  1.78073005e-08 1.12512816e-06 5.62162872e-10 5.26678492e-11\n",
            "  5.15383070e-09 7.10305414e-09]\n",
            " [9.45199490e-01 1.56930625e-03 7.34407397e-04 8.10768979e-05\n",
            "  6.17358137e-06 2.80493218e-02 1.60005409e-04 2.41667833e-02\n",
            "  4.45944215e-06 2.22588642e-05 1.33522917e-07 8.80814852e-08\n",
            "  1.43203636e-06 2.15661714e-07]\n",
            " [9.38432574e-01 7.59594142e-03 3.68498405e-03 7.21957476e-05\n",
            "  9.82725190e-09 8.82016437e-04 6.87367501e-05 4.92503345e-02\n",
            "  6.78501181e-07 8.94014738e-06 8.19945001e-09 2.12746221e-09\n",
            "  4.45725817e-07 1.30471292e-07]\n",
            " [2.31516659e-01 1.38323959e-02 4.33125673e-03 8.63573141e-03\n",
            "  4.45748534e-04 7.12465763e-01 4.32491885e-04 8.25043488e-03\n",
            "  1.88983147e-04 3.57486680e-03 5.34575200e-03 1.68008718e-03\n",
            "  1.34395051e-03 1.09198645e-05]\n",
            " [7.19365701e-02 8.30932334e-03 6.28259080e-03 1.29053351e-02\n",
            "  4.03257692e-03 8.54635656e-01 9.95477545e-04 2.54895128e-02\n",
            "  6.85517851e-04 4.64276038e-03 8.38499237e-03 2.67720869e-04\n",
            "  6.22936641e-05 1.95778796e-07]\n",
            " [5.81946552e-01 6.41386434e-02 1.84182581e-02 7.85380602e-02\n",
            "  6.56168791e-04 2.13791817e-01 2.25543074e-04 2.21584551e-02\n",
            "  1.61897813e-04 5.04615949e-03 6.53686421e-03 3.22904612e-04\n",
            "  2.48285796e-04 3.04582045e-06]\n",
            " [8.59171711e-03 1.97243644e-03 2.51556165e-04 2.14592274e-05\n",
            "  6.01855220e-07 9.83691498e-05 6.45808832e-05 4.34682646e-04\n",
            "  7.43528699e-06 6.40234866e-05 9.24609867e-06 1.19809352e-04\n",
            "  1.43532231e-02 6.33082017e-02]]\n",
            "d:  [962, 919, 862, 739, 970, 492, 919, 640, 880, 928, 880, 1159, 919, 640, 880, 593, 1345, 251, 433, 1425, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424, 1424]\n",
            "predicted_text:  ['2', '0', '1', '8', '-', '0', '5', '-', '0', '9', '<eot>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "activation_map:  [[1.04707105e-05 1.22802967e-05 8.08871482e-06 2.06340337e-05\n",
            "  9.13377789e-06 8.17141245e-06 2.89358250e-05 1.30348863e-05\n",
            "  3.70874773e-06 1.70587246e-05 7.16923250e-06 4.97975234e-05\n",
            "  4.53671564e-05 2.57728461e-05 2.45305255e-05 3.59793594e-05\n",
            "  1.75800902e-04 3.21106811e-04 2.58878747e-04 9.57598037e-04]\n",
            " [2.88392557e-03 2.04139692e-03 8.94600758e-04 1.82232610e-03\n",
            "  1.61480403e-03 1.75323524e-03 2.10437179e-03 1.21751055e-03\n",
            "  1.54816115e-03 1.77025318e-03 1.15152251e-03 2.02282914e-03\n",
            "  3.03077511e-03 2.33992981e-03 2.55076587e-03 2.10708170e-03\n",
            "  1.69713907e-02 8.44880119e-02 1.84010062e-02 4.24654549e-03]\n",
            " [8.43201815e-06 3.42195835e-06 1.62318486e-06 1.22512745e-06\n",
            "  3.69929285e-06 5.95502252e-06 1.39359702e-06 1.78298490e-06\n",
            "  1.46493458e-05 3.28790447e-05 3.97307849e-06 2.08614347e-06\n",
            "  4.15157820e-06 3.38642940e-06 2.53301164e-06 2.80062682e-06\n",
            "  6.27523696e-05 9.54504371e-01 4.52837311e-02 1.15335806e-05]\n",
            " [7.13865802e-06 2.41469957e-06 9.61474257e-07 5.44090085e-07\n",
            "  1.94048766e-06 1.89949913e-06 6.59642410e-07 1.45839510e-06\n",
            "  7.90476591e-08 6.31947551e-05 1.01818077e-05 3.12548036e-05\n",
            "  4.44533771e-06 1.10138426e-05 5.54642199e-08 4.49405491e-08\n",
            "  5.10359364e-08 2.86915037e-03 9.96083200e-01 7.84105388e-04]\n",
            " [1.81301602e-05 3.73556350e-06 4.00313684e-06 2.42960958e-08\n",
            "  1.15924891e-07 7.34329205e-07 2.52110181e-06 8.26254382e-06\n",
            "  2.06296605e-10 1.21145804e-05 7.03404730e-05 9.96394455e-01\n",
            "  1.59629574e-03 1.88904849e-03 1.23220878e-09 2.34216113e-08\n",
            "  2.51685645e-10 2.44377651e-09 2.69608371e-08 1.27401956e-08]\n",
            " [2.16925196e-06 3.70209222e-07 1.72306684e-07 8.09156964e-10\n",
            "  2.45024934e-09 9.72605747e-08 7.86436544e-07 1.37114864e-06\n",
            "  4.00889100e-09 4.24649261e-06 4.76355381e-05 9.83084798e-01\n",
            "  1.36052435e-02 3.24673555e-03 1.94071887e-07 6.04445995e-06\n",
            "  4.17237160e-08 7.73017028e-09 4.69365435e-09 3.06767750e-10]\n",
            " [9.19393096e-06 1.86049931e-06 1.05763081e-06 2.53111598e-09\n",
            "  2.48174459e-08 6.73855823e-07 6.16545606e-07 2.00330055e-06\n",
            "  1.68683220e-10 1.78941584e-04 9.03334236e-04 9.92308080e-01\n",
            "  2.34787213e-03 4.24453197e-03 4.78380180e-08 1.18830712e-06\n",
            "  2.54719829e-10 1.47910117e-09 1.43568883e-07 7.03320850e-08]\n",
            " [4.51888336e-04 1.88589795e-04 1.75513152e-04 1.30347471e-05\n",
            "  8.16022730e-05 5.59255830e-04 4.32279776e-05 1.79149021e-04\n",
            "  7.01048339e-05 9.96819377e-01 8.52358789e-05 1.02842940e-04\n",
            "  1.17911859e-05 1.13412563e-04 1.47355456e-06 1.17586991e-04\n",
            "  2.68022384e-04 1.74768866e-04 4.85598517e-04 2.03150762e-07]\n",
            " [1.58341031e-03 5.52699436e-04 7.73549313e-04 1.97314439e-05\n",
            "  1.97876332e-04 2.42762873e-03 1.88448656e-04 8.22777743e-04\n",
            "  9.12644027e-04 9.82110500e-01 8.30539328e-04 6.89820561e-04\n",
            "  6.55280310e-05 5.78455336e-04 1.80225543e-05 5.19344211e-03\n",
            "  2.67228181e-03 6.24222521e-05 2.41717062e-04 2.28822387e-07]\n",
            " [5.20700232e-05 8.56867518e-06 1.62408051e-05 9.45222894e-07\n",
            "  1.13819160e-05 2.57353153e-04 9.65933941e-06 5.56415034e-05\n",
            "  6.27269037e-06 9.98856843e-01 1.54579848e-05 3.43785578e-05\n",
            "  3.15258535e-06 2.96197650e-05 1.64847350e-07 3.45928245e-04\n",
            "  1.80975767e-04 1.87915757e-05 7.45424186e-05 5.51791501e-08]\n",
            " [9.43367556e-03 4.92233597e-03 4.59333794e-04 3.05006135e-04\n",
            "  7.25961407e-04 1.00142602e-03 1.46739522e-03 1.52899011e-03\n",
            "  2.70795008e-05 9.44321230e-02 5.14861569e-03 2.57769469e-02\n",
            "  6.57296134e-03 4.17757407e-03 9.03611217e-05 7.89189769e-04\n",
            "  5.21365982e-05 3.95515328e-03 2.73591310e-01 2.30234981e-01]]\n",
            "Completed visualizations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x612 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAHSCAYAAACXeAMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkjoGA0mS1DEYSJKkzv8DRj/tCaSFTQkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x612 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}