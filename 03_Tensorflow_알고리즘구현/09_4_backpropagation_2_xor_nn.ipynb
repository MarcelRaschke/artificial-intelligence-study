{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab-09-x-xor-nn-back_prop.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyRFXHZWp6n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lab 9 XOR-back_prop\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRR34OSRp_Aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_data = [[0, 0],\n",
        "          [0, 1],\n",
        "          [1, 0],\n",
        "          [1, 1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]\n",
        "\n",
        "x_data = np.array(x_data, dtype=np.float32)\n",
        "y_data = np.array(y_data, dtype=np.float32)\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 2])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_5Ixusp_DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
        "l1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
        "Y_pred = tf.sigmoid(tf.matmul(l1, W2) + b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0f-1ewp_Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y * tf.log(Y_pred) + (1 - Y) *\n",
        "                       tf.log(1 - Y_pred))\n",
        "\n",
        "# Network\n",
        "#          p1     a1           l1     p2     a2           l2 (y_pred)\n",
        "# X -> (*) -> (+) -> (sigmoid) -> (*) -> (+) -> (sigmoid) -> (loss)\n",
        "#       ^      ^                   ^      ^\n",
        "#       |      |                   |      |\n",
        "#       W1     b1                  W2     b2\n",
        "\n",
        "# Loss derivative\n",
        "d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
        "\n",
        "# Layer 2\n",
        "d_sigma2 = Y_pred * (1 - Y_pred)\n",
        "d_a2 = d_Y_pred * d_sigma2\n",
        "d_p2 = d_a2\n",
        "d_b2 = d_a2\n",
        "d_W2 = tf.matmul(tf.transpose(l1), d_p2)\n",
        "\n",
        "# Mean\n",
        "d_b2_mean = tf.reduce_mean(d_b2, axis=[0])\n",
        "d_W2_mean = d_W2 / tf.cast(tf.shape(l1)[0], dtype=tf.float32)\n",
        "\n",
        "# Layer 1\n",
        "d_l1 = tf.matmul(d_p2, tf.transpose(W2))\n",
        "d_sigma1 = l1 * (1 - l1)\n",
        "d_a1 = d_l1 * d_sigma1\n",
        "d_b1 = d_a1\n",
        "d_p1 = d_a1\n",
        "d_W1 = tf.matmul(tf.transpose(X), d_a1)\n",
        "\n",
        "# Mean\n",
        "d_W1_mean = d_W1 / tf.cast(tf.shape(X)[0], dtype=tf.float32)\n",
        "d_b1_mean = tf.reduce_mean(d_b1, axis=[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krw5FQEgp8AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Weight update\n",
        "step = [\n",
        "  tf.assign(W2, W2 - learning_rate * d_W2_mean),\n",
        "  tf.assign(b2, b2 - learning_rate * d_b2_mean),\n",
        "  tf.assign(W1, W1 - learning_rate * d_W1_mean),\n",
        "  tf.assign(b1, b1 - learning_rate * d_b1_mean)\n",
        "]\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis > 0.5 else False\n",
        "predicted = tf.cast(Y_pred > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBGBr8OVp8C8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1fd32ac-3927-4630-ef35-88284ad440d6"
      },
      "source": [
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    print(\"shape\", sess.run(tf.shape(X)[0], feed_dict={X: x_data}))\n",
        "\n",
        "\n",
        "    for i in range(10001):\n",
        "        sess.run([step, cost], feed_dict={X: x_data, Y: y_data})\n",
        "        if i % 1000 == 0:\n",
        "            print(i, sess.run([cost, d_W1], feed_dict={\n",
        "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
        "\n",
        "    # Accuracy report\n",
        "    h, c, a = sess.run([Y_pred, predicted, accuracy],\n",
        "                       feed_dict={X: x_data, Y: y_data})\n",
        "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape 4\n",
            "0 [0.75390565, array([[ 0.14797616, -0.05841842],\n",
            "       [ 0.0989486 , -0.06082926]], dtype=float32)] [array([[ 0.7988948 ,  0.68012893],\n",
            "       [-1.2198448 , -0.30359986]], dtype=float32), array([[ 1.3752297 ],\n",
            "       [-0.78823847]], dtype=float32)]\n",
            "1000 [0.6712502, array([[-0.0533312 , -0.00568972],\n",
            "       [ 0.0450673 ,  0.00137405]], dtype=float32)] [array([[ 1.157007  ,  0.70471925],\n",
            "       [-1.8540648 , -0.15275571]], dtype=float32), array([[ 1.3881938],\n",
            "       [-0.8743605]], dtype=float32)]\n",
            "2000 [0.5340059, array([[-0.07985361, -0.06230266],\n",
            "       [ 0.06754018,  0.05502707]], dtype=float32)] [array([[ 3.0524423,  1.3880699],\n",
            "       [-3.4552968, -0.6527326]], dtype=float32), array([[ 3.2826777],\n",
            "       [-1.5613475]], dtype=float32)]\n",
            "3000 [0.19793856, array([[-0.04036475, -0.07030873],\n",
            "       [ 0.0351082 ,  0.08072164]], dtype=float32)] [array([[ 4.6230903,  3.5024679],\n",
            "       [-4.7518783, -3.0356026]], dtype=float32), array([[ 5.564288],\n",
            "       [-4.343899]], dtype=float32)]\n",
            "4000 [0.07766898, array([[-0.0172586 , -0.02849679],\n",
            "       [ 0.01704809,  0.03009769]], dtype=float32)] [array([[ 5.282227 ,  4.6322246],\n",
            "       [-5.363503 , -4.274026 ]], dtype=float32), array([[ 7.0582504],\n",
            "       [-6.298696 ]], dtype=float32)]\n",
            "5000 [0.045366682, array([[-0.01010492, -0.01578839],\n",
            "       [ 0.01045697,  0.01638275]], dtype=float32)] [array([[ 5.610217 ,  5.159416 ],\n",
            "       [-5.6956997, -4.8254066]], dtype=float32), array([[ 7.9715805],\n",
            "       [-7.3486066]], dtype=float32)]\n",
            "6000 [0.031539492, array([[-0.00697261, -0.01050025],\n",
            "       [ 0.00735245,  0.01082826]], dtype=float32)] [array([[ 5.8192773,  5.4801235],\n",
            "       [-5.9142394, -5.1570864]], dtype=float32), array([[ 8.610165],\n",
            "       [-8.044054]], dtype=float32)]\n",
            "7000 [0.024019329, array([[-0.0052633 , -0.00772242],\n",
            "       [ 0.00559919,  0.00793848]], dtype=float32)] [array([[ 5.970381 ,  5.7047296],\n",
            "       [-6.074329 , -5.388329 ]], dtype=float32), array([[ 9.097342],\n",
            "       [-8.560523]], dtype=float32)]\n",
            "8000 [0.01933278, array([[-0.00420012, -0.00604314],\n",
            "       [ 0.00448823,  0.00619962]], dtype=float32)] [array([[ 6.0877485,  5.875254 ],\n",
            "       [-6.1994867, -5.5634437]], dtype=float32), array([[ 9.489928],\n",
            "       [-8.970264]], dtype=float32)]\n",
            "9000 [0.016146379, array([[-0.00347979, -0.00493058],\n",
            "       [ 0.00372739,  0.00505071]], dtype=float32)] [array([[ 6.183227 ,  6.0115743],\n",
            "       [-6.301644 , -5.7031865]], dtype=float32), array([[ 9.81818 ],\n",
            "       [-9.309434]], dtype=float32)]\n",
            "10000 [0.013845395, array([[-0.00296187, -0.0041448 ],\n",
            "       [ 0.00317654,  0.0042407 ]], dtype=float32)] [array([[ 6.263425 ,  6.1245017],\n",
            "       [-6.387606 , -5.818796 ]], dtype=float32), array([[10.099953],\n",
            "       [-9.598571]], dtype=float32)]\n",
            "\n",
            "Hypothesis:  [[0.01338281]\n",
            " [0.98166317]\n",
            " [0.98809355]\n",
            " [0.01135852]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jqbhxFfp8Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6fWTCFp8IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}