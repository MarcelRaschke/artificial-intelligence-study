{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cluster_test05_Autoencoder_Spherical_Clustering_20200114.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLnlUx0nMWnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "a818018f-7f36-43b7-df6a-421d40145d50"
      },
      "source": [
        "!git clone https://github.com/jasonlaska/spherecluster"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'spherecluster'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 686 (delta 4), reused 6 (delta 2), pack-reused 672\u001b[K\n",
            "Receiving objects: 100% (686/686), 1.64 MiB | 10.87 MiB/s, done.\n",
            "Resolving deltas: 100% (434/434), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va3pe6XCMZJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10204ad2-e98d-4704-aa96-db6193265903"
      },
      "source": [
        "cd spherecluster"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spherecluster\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxxXb8lTMZRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0059df5-0f87-4e34-e706-5498ee5b9d91"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating spherecluster.egg-info\n",
            "writing spherecluster.egg-info/PKG-INFO\n",
            "writing dependency_links to spherecluster.egg-info/dependency_links.txt\n",
            "writing requirements to spherecluster.egg-info/requires.txt\n",
            "writing top-level names to spherecluster.egg-info/top_level.txt\n",
            "writing manifest file 'spherecluster.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'spherecluster.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/spherecluster\n",
            "copying spherecluster/spherical_kmeans.py -> build/lib/spherecluster\n",
            "copying spherecluster/__init__.py -> build/lib/spherecluster\n",
            "copying spherecluster/von_mises_fisher_mixture.py -> build/lib/spherecluster\n",
            "copying spherecluster/util.py -> build/lib/spherecluster\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/spherecluster\n",
            "copying build/lib/spherecluster/spherical_kmeans.py -> build/bdist.linux-x86_64/egg/spherecluster\n",
            "copying build/lib/spherecluster/__init__.py -> build/bdist.linux-x86_64/egg/spherecluster\n",
            "copying build/lib/spherecluster/von_mises_fisher_mixture.py -> build/bdist.linux-x86_64/egg/spherecluster\n",
            "copying build/lib/spherecluster/util.py -> build/bdist.linux-x86_64/egg/spherecluster\n",
            "byte-compiling build/bdist.linux-x86_64/egg/spherecluster/spherical_kmeans.py to spherical_kmeans.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/spherecluster/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/spherecluster/von_mises_fisher_mixture.py to von_mises_fisher_mixture.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/spherecluster/util.py to util.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying spherecluster.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying spherecluster.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying spherecluster.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying spherecluster.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying spherecluster.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/spherecluster-0.1.7-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing spherecluster-0.1.7-py3.6.egg\n",
            "Copying spherecluster-0.1.7-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding spherecluster 0.1.7 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/spherecluster-0.1.7-py3.6.egg\n",
            "Processing dependencies for spherecluster==0.1.7\n",
            "Searching for nose\n",
            "Reading https://pypi.org/simple/nose/\n",
            "Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl#sha256=9ff7c6cc443f8c51994b34a667bbcf45afd6d945be7477b52e97516fd17c53ac\n",
            "Best match: nose 1.3.7\n",
            "Processing nose-1.3.7-py3-none-any.whl\n",
            "Installing nose-1.3.7-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding nose 1.3.7 to easy-install.pth file\n",
            "Installing nosetests script to /usr/local/bin\n",
            "Installing nosetests-3.4 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/nose-1.3.7-py3.6.egg\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytest==3.6.4\n",
            "Best match: pytest 3.6.4\n",
            "Adding pytest 3.6.4 to easy-install.pth file\n",
            "Installing py.test script to /usr/local/bin\n",
            "Installing pytest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.1\n",
            "Best match: scikit-learn 0.22.1\n",
            "Adding scikit-learn 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==42.0.2\n",
            "Best match: setuptools 42.0.2\n",
            "Adding setuptools 42.0.2 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pluggy==0.7.1\n",
            "Best match: pluggy 0.7.1\n",
            "Adding pluggy 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for py==1.8.1\n",
            "Best match: py 1.8.1\n",
            "Adding py 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for atomicwrites==1.3.0\n",
            "Best match: atomicwrites 1.3.0\n",
            "Adding atomicwrites 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for more-itertools==8.0.2\n",
            "Best match: more-itertools 8.0.2\n",
            "Adding more-itertools 8.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for attrs==19.3.0\n",
            "Best match: attrs 19.3.0\n",
            "Adding attrs 19.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for spherecluster==0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73z8vOOkMcZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "beceead5-c21b-4293-f38f-01f7c4dfaffe"
      },
      "source": [
        "!pip install spherecluster"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spherecluster in /usr/local/lib/python3.6/dist-packages/spherecluster-0.1.7-py3.6.egg (0.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spherecluster) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spherecluster) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from spherecluster) (0.22.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from spherecluster) (3.6.4)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages/nose-1.3.7-py3.6.egg (from spherecluster) (1.3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spherecluster) (0.14.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (8.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (42.0.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spherecluster) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8rwA6vmAfsW",
        "colab_type": "code",
        "outputId": "be807ff1-61a7-4984-ec4f-503ba3a4bb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "#참고: https://yamalab.tistory.com/118\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icFu0OrdBYZa",
        "colab_type": "code",
        "outputId": "a204a456-865c-418c-db93-46b32e19d679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "# configure\n",
        "encoding_dim = 200\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# layers\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "\n",
        "# Models\n",
        "autoencoder = Model(input_img, decoded) # autoencoder\n",
        "\n",
        "encoder = Model(input_img, encoded) # encoder\n",
        "\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input)) # decoder"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOUPezdDBYmj",
        "colab_type": "code",
        "outputId": "d6db93f8-310b-4053-9cba-dd305c4810a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
        "\n",
        "    count_true_positive = K.sum(y_true_yn * y_pred_yn)\n",
        "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "# train autoencoder\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[rmse, recall])\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=512,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "\n",
        "# encoding result\n",
        "encoded_imgs = encoder.predict(x_train)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "encoded_imgs.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.3968 - rmse: 0.3209 - recall: 0.2727 - val_loss: 0.2744 - val_rmse: 0.2596 - val_recall: 0.2219\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2668 - rmse: 0.2550 - recall: 0.2413 - val_loss: 0.2575 - val_rmse: 0.2494 - val_recall: 0.2638\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2500 - rmse: 0.2433 - recall: 0.3324 - val_loss: 0.2398 - val_rmse: 0.2358 - val_recall: 0.4065\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2329 - rmse: 0.2297 - recall: 0.4467 - val_loss: 0.2233 - val_rmse: 0.2226 - val_recall: 0.5178\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2182 - rmse: 0.2180 - recall: 0.5287 - val_loss: 0.2103 - val_rmse: 0.2123 - val_recall: 0.5533\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.2065 - rmse: 0.2087 - recall: 0.5815 - val_loss: 0.1998 - val_rmse: 0.2037 - val_recall: 0.6021\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1970 - rmse: 0.2010 - recall: 0.6206 - val_loss: 0.1914 - val_rmse: 0.1967 - val_recall: 0.6320\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1893 - rmse: 0.1944 - recall: 0.6502 - val_loss: 0.1843 - val_rmse: 0.1906 - val_recall: 0.6637\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1827 - rmse: 0.1888 - recall: 0.6738 - val_loss: 0.1782 - val_rmse: 0.1853 - val_recall: 0.6830\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1769 - rmse: 0.1838 - recall: 0.6925 - val_loss: 0.1728 - val_rmse: 0.1805 - val_recall: 0.7025\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1719 - rmse: 0.1792 - recall: 0.7086 - val_loss: 0.1680 - val_rmse: 0.1760 - val_recall: 0.7240\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1673 - rmse: 0.1750 - recall: 0.7231 - val_loss: 0.1638 - val_rmse: 0.1722 - val_recall: 0.7232\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1631 - rmse: 0.1711 - recall: 0.7346 - val_loss: 0.1598 - val_rmse: 0.1684 - val_recall: 0.7324\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1592 - rmse: 0.1675 - recall: 0.7456 - val_loss: 0.1561 - val_rmse: 0.1648 - val_recall: 0.7434\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1557 - rmse: 0.1640 - recall: 0.7552 - val_loss: 0.1526 - val_rmse: 0.1614 - val_recall: 0.7551\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1524 - rmse: 0.1608 - recall: 0.7644 - val_loss: 0.1493 - val_rmse: 0.1581 - val_recall: 0.7744\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1493 - rmse: 0.1577 - recall: 0.7730 - val_loss: 0.1464 - val_rmse: 0.1552 - val_recall: 0.7754\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1464 - rmse: 0.1548 - recall: 0.7802 - val_loss: 0.1437 - val_rmse: 0.1525 - val_recall: 0.7765\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1437 - rmse: 0.1521 - recall: 0.7867 - val_loss: 0.1410 - val_rmse: 0.1497 - val_recall: 0.7881\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1412 - rmse: 0.1495 - recall: 0.7930 - val_loss: 0.1386 - val_rmse: 0.1472 - val_recall: 0.7956\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1388 - rmse: 0.1471 - recall: 0.7988 - val_loss: 0.1363 - val_rmse: 0.1447 - val_recall: 0.8026\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1366 - rmse: 0.1448 - recall: 0.8043 - val_loss: 0.1341 - val_rmse: 0.1424 - val_recall: 0.8081\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1345 - rmse: 0.1425 - recall: 0.8090 - val_loss: 0.1320 - val_rmse: 0.1403 - val_recall: 0.8102\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1325 - rmse: 0.1404 - recall: 0.8135 - val_loss: 0.1300 - val_rmse: 0.1381 - val_recall: 0.8193\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1306 - rmse: 0.1384 - recall: 0.8179 - val_loss: 0.1283 - val_rmse: 0.1362 - val_recall: 0.8168\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1288 - rmse: 0.1364 - recall: 0.8216 - val_loss: 0.1264 - val_rmse: 0.1341 - val_recall: 0.8268\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1270 - rmse: 0.1345 - recall: 0.8258 - val_loss: 0.1248 - val_rmse: 0.1325 - val_recall: 0.8213\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1254 - rmse: 0.1327 - recall: 0.8289 - val_loss: 0.1232 - val_rmse: 0.1306 - val_recall: 0.8256\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1238 - rmse: 0.1309 - recall: 0.8324 - val_loss: 0.1216 - val_rmse: 0.1287 - val_recall: 0.8330\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1223 - rmse: 0.1291 - recall: 0.8354 - val_loss: 0.1201 - val_rmse: 0.1270 - val_recall: 0.8364\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1208 - rmse: 0.1274 - recall: 0.8387 - val_loss: 0.1186 - val_rmse: 0.1253 - val_recall: 0.8392\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1194 - rmse: 0.1258 - recall: 0.8415 - val_loss: 0.1172 - val_rmse: 0.1237 - val_recall: 0.8427\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1180 - rmse: 0.1242 - recall: 0.8443 - val_loss: 0.1158 - val_rmse: 0.1220 - val_recall: 0.8478\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1166 - rmse: 0.1226 - recall: 0.8470 - val_loss: 0.1145 - val_rmse: 0.1204 - val_recall: 0.8560\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1154 - rmse: 0.1211 - recall: 0.8498 - val_loss: 0.1133 - val_rmse: 0.1191 - val_recall: 0.8483\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1141 - rmse: 0.1196 - recall: 0.8519 - val_loss: 0.1121 - val_rmse: 0.1176 - val_recall: 0.8515\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1129 - rmse: 0.1182 - recall: 0.8541 - val_loss: 0.1109 - val_rmse: 0.1162 - val_recall: 0.8535\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1118 - rmse: 0.1168 - recall: 0.8564 - val_loss: 0.1098 - val_rmse: 0.1148 - val_recall: 0.8566\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1107 - rmse: 0.1154 - recall: 0.8585 - val_loss: 0.1087 - val_rmse: 0.1134 - val_recall: 0.8580\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1096 - rmse: 0.1141 - recall: 0.8604 - val_loss: 0.1076 - val_rmse: 0.1121 - val_recall: 0.8602\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1085 - rmse: 0.1128 - recall: 0.8624 - val_loss: 0.1066 - val_rmse: 0.1106 - val_recall: 0.8677\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1075 - rmse: 0.1115 - recall: 0.8645 - val_loss: 0.1057 - val_rmse: 0.1097 - val_recall: 0.8592\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1066 - rmse: 0.1103 - recall: 0.8656 - val_loss: 0.1047 - val_rmse: 0.1083 - val_recall: 0.8663\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1056 - rmse: 0.1091 - recall: 0.8676 - val_loss: 0.1038 - val_rmse: 0.1071 - val_recall: 0.8699\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1048 - rmse: 0.1079 - recall: 0.8693 - val_loss: 0.1029 - val_rmse: 0.1060 - val_recall: 0.8689\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1039 - rmse: 0.1068 - recall: 0.8705 - val_loss: 0.1021 - val_rmse: 0.1047 - val_recall: 0.8775\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1031 - rmse: 0.1057 - recall: 0.8723 - val_loss: 0.1013 - val_rmse: 0.1038 - val_recall: 0.8741\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1023 - rmse: 0.1047 - recall: 0.8736 - val_loss: 0.1005 - val_rmse: 0.1028 - val_recall: 0.8741\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1015 - rmse: 0.1037 - recall: 0.8748 - val_loss: 0.0998 - val_rmse: 0.1017 - val_recall: 0.8756\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1008 - rmse: 0.1027 - recall: 0.8762 - val_loss: 0.0990 - val_rmse: 0.1008 - val_recall: 0.8755\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.1001 - rmse: 0.1017 - recall: 0.8773 - val_loss: 0.0983 - val_rmse: 0.0998 - val_recall: 0.8792\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0994 - rmse: 0.1008 - recall: 0.8785 - val_loss: 0.0977 - val_rmse: 0.0991 - val_recall: 0.8761\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0987 - rmse: 0.0999 - recall: 0.8795 - val_loss: 0.0971 - val_rmse: 0.0981 - val_recall: 0.8796\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0981 - rmse: 0.0991 - recall: 0.8807 - val_loss: 0.0964 - val_rmse: 0.0972 - val_recall: 0.8825\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0975 - rmse: 0.0982 - recall: 0.8817 - val_loss: 0.0959 - val_rmse: 0.0964 - val_recall: 0.8829\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0969 - rmse: 0.0974 - recall: 0.8828 - val_loss: 0.0954 - val_rmse: 0.0958 - val_recall: 0.8793\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0964 - rmse: 0.0967 - recall: 0.8835 - val_loss: 0.0948 - val_rmse: 0.0949 - val_recall: 0.8845\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0958 - rmse: 0.0959 - recall: 0.8846 - val_loss: 0.0942 - val_rmse: 0.0941 - val_recall: 0.8860\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0953 - rmse: 0.0952 - recall: 0.8854 - val_loss: 0.0937 - val_rmse: 0.0934 - val_recall: 0.8896\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0948 - rmse: 0.0945 - recall: 0.8864 - val_loss: 0.0932 - val_rmse: 0.0927 - val_recall: 0.8879\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0943 - rmse: 0.0938 - recall: 0.8872 - val_loss: 0.0928 - val_rmse: 0.0920 - val_recall: 0.8903\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0938 - rmse: 0.0932 - recall: 0.8880 - val_loss: 0.0923 - val_rmse: 0.0914 - val_recall: 0.8902\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0934 - rmse: 0.0925 - recall: 0.8888 - val_loss: 0.0919 - val_rmse: 0.0908 - val_recall: 0.8916\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0930 - rmse: 0.0919 - recall: 0.8895 - val_loss: 0.0915 - val_rmse: 0.0901 - val_recall: 0.8937\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0926 - rmse: 0.0913 - recall: 0.8903 - val_loss: 0.0911 - val_rmse: 0.0896 - val_recall: 0.8904\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0922 - rmse: 0.0907 - recall: 0.8910 - val_loss: 0.0907 - val_rmse: 0.0890 - val_recall: 0.8920\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0918 - rmse: 0.0902 - recall: 0.8917 - val_loss: 0.0903 - val_rmse: 0.0885 - val_recall: 0.8924\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0914 - rmse: 0.0896 - recall: 0.8923 - val_loss: 0.0900 - val_rmse: 0.0880 - val_recall: 0.8929\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0910 - rmse: 0.0891 - recall: 0.8930 - val_loss: 0.0896 - val_rmse: 0.0874 - val_recall: 0.8960\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0907 - rmse: 0.0886 - recall: 0.8937 - val_loss: 0.0893 - val_rmse: 0.0869 - val_recall: 0.8953\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0903 - rmse: 0.0881 - recall: 0.8943 - val_loss: 0.0890 - val_rmse: 0.0865 - val_recall: 0.8946\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0900 - rmse: 0.0876 - recall: 0.8949 - val_loss: 0.0886 - val_rmse: 0.0860 - val_recall: 0.8961\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0897 - rmse: 0.0871 - recall: 0.8955 - val_loss: 0.0883 - val_rmse: 0.0855 - val_recall: 0.8971\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0894 - rmse: 0.0866 - recall: 0.8961 - val_loss: 0.0880 - val_rmse: 0.0850 - val_recall: 0.8989\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0891 - rmse: 0.0862 - recall: 0.8967 - val_loss: 0.0877 - val_rmse: 0.0846 - val_recall: 0.8984\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0888 - rmse: 0.0858 - recall: 0.8973 - val_loss: 0.0874 - val_rmse: 0.0842 - val_recall: 0.8984\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0885 - rmse: 0.0853 - recall: 0.8979 - val_loss: 0.0872 - val_rmse: 0.0838 - val_recall: 0.8985\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0882 - rmse: 0.0849 - recall: 0.8984 - val_loss: 0.0869 - val_rmse: 0.0833 - val_recall: 0.8997\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0879 - rmse: 0.0845 - recall: 0.8989 - val_loss: 0.0866 - val_rmse: 0.0829 - val_recall: 0.9007\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0877 - rmse: 0.0841 - recall: 0.8995 - val_loss: 0.0864 - val_rmse: 0.0826 - val_recall: 0.8986\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0874 - rmse: 0.0837 - recall: 0.8999 - val_loss: 0.0861 - val_rmse: 0.0821 - val_recall: 0.9024\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0872 - rmse: 0.0833 - recall: 0.9005 - val_loss: 0.0859 - val_rmse: 0.0817 - val_recall: 0.9027\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0869 - rmse: 0.0829 - recall: 0.9010 - val_loss: 0.0857 - val_rmse: 0.0814 - val_recall: 0.9019\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0867 - rmse: 0.0826 - recall: 0.9014 - val_loss: 0.0854 - val_rmse: 0.0810 - val_recall: 0.9032\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0865 - rmse: 0.0822 - recall: 0.9020 - val_loss: 0.0852 - val_rmse: 0.0807 - val_recall: 0.9030\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0862 - rmse: 0.0819 - recall: 0.9024 - val_loss: 0.0850 - val_rmse: 0.0803 - val_recall: 0.9051\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0860 - rmse: 0.0815 - recall: 0.9029 - val_loss: 0.0848 - val_rmse: 0.0800 - val_recall: 0.9041\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0858 - rmse: 0.0812 - recall: 0.9033 - val_loss: 0.0846 - val_rmse: 0.0796 - val_recall: 0.9066\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0856 - rmse: 0.0808 - recall: 0.9038 - val_loss: 0.0844 - val_rmse: 0.0794 - val_recall: 0.9045\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0854 - rmse: 0.0805 - recall: 0.9042 - val_loss: 0.0842 - val_rmse: 0.0790 - val_recall: 0.9059\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0852 - rmse: 0.0802 - recall: 0.9047 - val_loss: 0.0840 - val_rmse: 0.0787 - val_recall: 0.9063\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0850 - rmse: 0.0799 - recall: 0.9051 - val_loss: 0.0838 - val_rmse: 0.0784 - val_recall: 0.9064\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0848 - rmse: 0.0796 - recall: 0.9055 - val_loss: 0.0836 - val_rmse: 0.0781 - val_recall: 0.9069\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0846 - rmse: 0.0793 - recall: 0.9059 - val_loss: 0.0834 - val_rmse: 0.0777 - val_recall: 0.9093\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0844 - rmse: 0.0790 - recall: 0.9064 - val_loss: 0.0832 - val_rmse: 0.0774 - val_recall: 0.9093\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0842 - rmse: 0.0787 - recall: 0.9068 - val_loss: 0.0831 - val_rmse: 0.0771 - val_recall: 0.9099\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0841 - rmse: 0.0784 - recall: 0.9073 - val_loss: 0.0829 - val_rmse: 0.0769 - val_recall: 0.9083\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0839 - rmse: 0.0781 - recall: 0.9076 - val_loss: 0.0827 - val_rmse: 0.0767 - val_recall: 0.9084\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0837 - rmse: 0.0778 - recall: 0.9079 - val_loss: 0.0826 - val_rmse: 0.0763 - val_recall: 0.9103\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0835 - rmse: 0.0775 - recall: 0.9083 - val_loss: 0.0824 - val_rmse: 0.0760 - val_recall: 0.9111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEVGZS8aCNT2",
        "colab_type": "code",
        "outputId": "ae1f24ba-1e98-4cce-aca1-ec7fd0cbd2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from spherecluster import SphericalKMeans\n",
        "\n",
        "skm = SphericalKMeans(n_clusters=10)\n",
        "skm.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVW53hAcBYhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def viz_img(y_pred):\n",
        "    n = 10\n",
        "    fig = plt.figure(1)\n",
        "    box_index = 1\n",
        "    for cluster in range(10):\n",
        "        result = np.where(y_pred == cluster)\n",
        "        for i in np.random.choice(result[0].tolist(), n, replace=False):\n",
        "            ax = fig.add_subplot(n, n, box_index)\n",
        "            plt.imshow(x_train[i].reshape(28, 28))\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "            box_index += 1\n",
        "    plt.show()\n",
        "    \n",
        "viz_img(skm.labels_)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}