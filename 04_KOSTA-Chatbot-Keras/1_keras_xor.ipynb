{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy7Ru9EXcB8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcSpEjB5cO4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_data = np.array([[0,0], [0,1], [1,0], [1,1]], \"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILf1T3zcnMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_data = np.array([[0],[1],[1],[0]], \"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tco2ZFzhcvPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential(); # 연속적으로 hyden layer 통과\n",
        "model.add(Dense(8, input_dim=2, activation='relu')) # input 2, 히든8개, dense: 전체 연결, relu: 0보다 작으면0, 크면 1, input값 range가 너무 크면 relu가 안맞을수있\n",
        "model.add(Dense(4, activation='relu'))              # 히든8개\n",
        "model.add(Dense(1, activation='sigmoid'))           # output 1 , sigmoid:-1~1 (weight값이 작아질수 있음: banissing문제, 히든레이어에서는 sigmoid잘 안씀) -> binary classfication\n",
        "#마지막 레이어에 sofrmax면 multi classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JtdyQEdKky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC3zIa3zel6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11001
        },
        "outputId": "99954445-af4a-4a65-930a-eda39a762670"
      },
      "source": [
        "model.fit(feature_data, target_data, epochs=300, verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0620 01:28:18.916612 140179459811200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            " - 1s - loss: 0.9029 - binary_accuracy: 0.7500\n",
            "Epoch 2/300\n",
            " - 0s - loss: 0.9007 - binary_accuracy: 0.7500\n",
            "Epoch 3/300\n",
            " - 0s - loss: 0.8981 - binary_accuracy: 0.7500\n",
            "Epoch 4/300\n",
            " - 0s - loss: 0.8954 - binary_accuracy: 0.7500\n",
            "Epoch 5/300\n",
            " - 0s - loss: 0.8927 - binary_accuracy: 0.7500\n",
            "Epoch 6/300\n",
            " - 0s - loss: 0.8899 - binary_accuracy: 0.7500\n",
            "Epoch 7/300\n",
            " - 0s - loss: 0.8871 - binary_accuracy: 0.7500\n",
            "Epoch 8/300\n",
            " - 0s - loss: 0.8843 - binary_accuracy: 0.7500\n",
            "Epoch 9/300\n",
            " - 0s - loss: 0.8815 - binary_accuracy: 0.7500\n",
            "Epoch 10/300\n",
            " - 0s - loss: 0.8788 - binary_accuracy: 0.7500\n",
            "Epoch 11/300\n",
            " - 0s - loss: 0.8761 - binary_accuracy: 0.7500\n",
            "Epoch 12/300\n",
            " - 0s - loss: 0.8734 - binary_accuracy: 0.7500\n",
            "Epoch 13/300\n",
            " - 0s - loss: 0.8708 - binary_accuracy: 0.7500\n",
            "Epoch 14/300\n",
            " - 0s - loss: 0.8682 - binary_accuracy: 0.7500\n",
            "Epoch 15/300\n",
            " - 0s - loss: 0.8656 - binary_accuracy: 0.7500\n",
            "Epoch 16/300\n",
            " - 0s - loss: 0.8630 - binary_accuracy: 0.7500\n",
            "Epoch 17/300\n",
            " - 0s - loss: 0.8605 - binary_accuracy: 0.7500\n",
            "Epoch 18/300\n",
            " - 0s - loss: 0.8581 - binary_accuracy: 0.7500\n",
            "Epoch 19/300\n",
            " - 0s - loss: 0.8556 - binary_accuracy: 0.7500\n",
            "Epoch 20/300\n",
            " - 0s - loss: 0.8532 - binary_accuracy: 0.7500\n",
            "Epoch 21/300\n",
            " - 0s - loss: 0.8508 - binary_accuracy: 0.7500\n",
            "Epoch 22/300\n",
            " - 0s - loss: 0.8485 - binary_accuracy: 0.7500\n",
            "Epoch 23/300\n",
            " - 0s - loss: 0.8462 - binary_accuracy: 0.7500\n",
            "Epoch 24/300\n",
            " - 0s - loss: 0.8439 - binary_accuracy: 0.7500\n",
            "Epoch 25/300\n",
            " - 0s - loss: 0.8417 - binary_accuracy: 0.7500\n",
            "Epoch 26/300\n",
            " - 0s - loss: 0.8395 - binary_accuracy: 0.7500\n",
            "Epoch 27/300\n",
            " - 0s - loss: 0.8373 - binary_accuracy: 0.7500\n",
            "Epoch 28/300\n",
            " - 0s - loss: 0.8352 - binary_accuracy: 0.7500\n",
            "Epoch 29/300\n",
            " - 0s - loss: 0.8331 - binary_accuracy: 0.7500\n",
            "Epoch 30/300\n",
            " - 0s - loss: 0.8310 - binary_accuracy: 0.7500\n",
            "Epoch 31/300\n",
            " - 0s - loss: 0.8289 - binary_accuracy: 0.7500\n",
            "Epoch 32/300\n",
            " - 0s - loss: 0.8269 - binary_accuracy: 0.7500\n",
            "Epoch 33/300\n",
            " - 0s - loss: 0.8249 - binary_accuracy: 0.7500\n",
            "Epoch 34/300\n",
            " - 0s - loss: 0.8230 - binary_accuracy: 0.7500\n",
            "Epoch 35/300\n",
            " - 0s - loss: 0.8210 - binary_accuracy: 0.7500\n",
            "Epoch 36/300\n",
            " - 0s - loss: 0.8192 - binary_accuracy: 0.7500\n",
            "Epoch 37/300\n",
            " - 0s - loss: 0.8173 - binary_accuracy: 0.7500\n",
            "Epoch 38/300\n",
            " - 0s - loss: 0.8154 - binary_accuracy: 0.7500\n",
            "Epoch 39/300\n",
            " - 0s - loss: 0.8137 - binary_accuracy: 0.7500\n",
            "Epoch 40/300\n",
            " - 0s - loss: 0.8119 - binary_accuracy: 0.7500\n",
            "Epoch 41/300\n",
            " - 0s - loss: 0.8102 - binary_accuracy: 0.7500\n",
            "Epoch 42/300\n",
            " - 0s - loss: 0.8085 - binary_accuracy: 0.7500\n",
            "Epoch 43/300\n",
            " - 0s - loss: 0.8068 - binary_accuracy: 0.7500\n",
            "Epoch 44/300\n",
            " - 0s - loss: 0.8052 - binary_accuracy: 0.7500\n",
            "Epoch 45/300\n",
            " - 0s - loss: 0.8035 - binary_accuracy: 0.7500\n",
            "Epoch 46/300\n",
            " - 0s - loss: 0.8019 - binary_accuracy: 0.7500\n",
            "Epoch 47/300\n",
            " - 0s - loss: 0.8004 - binary_accuracy: 0.7500\n",
            "Epoch 48/300\n",
            " - 0s - loss: 0.7988 - binary_accuracy: 0.7500\n",
            "Epoch 49/300\n",
            " - 0s - loss: 0.7973 - binary_accuracy: 0.7500\n",
            "Epoch 50/300\n",
            " - 0s - loss: 0.7958 - binary_accuracy: 0.7500\n",
            "Epoch 51/300\n",
            " - 0s - loss: 0.7944 - binary_accuracy: 0.7500\n",
            "Epoch 52/300\n",
            " - 0s - loss: 0.7929 - binary_accuracy: 0.7500\n",
            "Epoch 53/300\n",
            " - 0s - loss: 0.7914 - binary_accuracy: 0.7500\n",
            "Epoch 54/300\n",
            " - 0s - loss: 0.7900 - binary_accuracy: 0.7500\n",
            "Epoch 55/300\n",
            " - 0s - loss: 0.7886 - binary_accuracy: 0.7500\n",
            "Epoch 56/300\n",
            " - 0s - loss: 0.7873 - binary_accuracy: 0.7500\n",
            "Epoch 57/300\n",
            " - 0s - loss: 0.7859 - binary_accuracy: 0.7500\n",
            "Epoch 58/300\n",
            " - 0s - loss: 0.7846 - binary_accuracy: 0.7500\n",
            "Epoch 59/300\n",
            " - 0s - loss: 0.7833 - binary_accuracy: 0.7500\n",
            "Epoch 60/300\n",
            " - 0s - loss: 0.7820 - binary_accuracy: 0.7500\n",
            "Epoch 61/300\n",
            " - 0s - loss: 0.7807 - binary_accuracy: 0.7500\n",
            "Epoch 62/300\n",
            " - 0s - loss: 0.7794 - binary_accuracy: 0.7500\n",
            "Epoch 63/300\n",
            " - 0s - loss: 0.7781 - binary_accuracy: 0.7500\n",
            "Epoch 64/300\n",
            " - 0s - loss: 0.7769 - binary_accuracy: 0.7500\n",
            "Epoch 65/300\n",
            " - 0s - loss: 0.7757 - binary_accuracy: 0.7500\n",
            "Epoch 66/300\n",
            " - 0s - loss: 0.7745 - binary_accuracy: 0.7500\n",
            "Epoch 67/300\n",
            " - 0s - loss: 0.7733 - binary_accuracy: 0.7500\n",
            "Epoch 68/300\n",
            " - 0s - loss: 0.7721 - binary_accuracy: 0.7500\n",
            "Epoch 69/300\n",
            " - 0s - loss: 0.7709 - binary_accuracy: 0.7500\n",
            "Epoch 70/300\n",
            " - 0s - loss: 0.7697 - binary_accuracy: 0.7500\n",
            "Epoch 71/300\n",
            " - 0s - loss: 0.7686 - binary_accuracy: 0.7500\n",
            "Epoch 72/300\n",
            " - 0s - loss: 0.7674 - binary_accuracy: 0.7500\n",
            "Epoch 73/300\n",
            " - 0s - loss: 0.7663 - binary_accuracy: 0.7500\n",
            "Epoch 74/300\n",
            " - 0s - loss: 0.7652 - binary_accuracy: 0.7500\n",
            "Epoch 75/300\n",
            " - 0s - loss: 0.7640 - binary_accuracy: 0.7500\n",
            "Epoch 76/300\n",
            " - 0s - loss: 0.7629 - binary_accuracy: 0.7500\n",
            "Epoch 77/300\n",
            " - 0s - loss: 0.7618 - binary_accuracy: 0.7500\n",
            "Epoch 78/300\n",
            " - 0s - loss: 0.7608 - binary_accuracy: 0.7500\n",
            "Epoch 79/300\n",
            " - 0s - loss: 0.7597 - binary_accuracy: 0.7500\n",
            "Epoch 80/300\n",
            " - 0s - loss: 0.7586 - binary_accuracy: 0.7500\n",
            "Epoch 81/300\n",
            " - 0s - loss: 0.7575 - binary_accuracy: 0.7500\n",
            "Epoch 82/300\n",
            " - 0s - loss: 0.7565 - binary_accuracy: 0.7500\n",
            "Epoch 83/300\n",
            " - 0s - loss: 0.7555 - binary_accuracy: 0.7500\n",
            "Epoch 84/300\n",
            " - 0s - loss: 0.7545 - binary_accuracy: 0.7500\n",
            "Epoch 85/300\n",
            " - 0s - loss: 0.7535 - binary_accuracy: 0.7500\n",
            "Epoch 86/300\n",
            " - 0s - loss: 0.7526 - binary_accuracy: 0.7500\n",
            "Epoch 87/300\n",
            " - 0s - loss: 0.7516 - binary_accuracy: 0.7500\n",
            "Epoch 88/300\n",
            " - 0s - loss: 0.7507 - binary_accuracy: 0.7500\n",
            "Epoch 89/300\n",
            " - 0s - loss: 0.7497 - binary_accuracy: 0.7500\n",
            "Epoch 90/300\n",
            " - 0s - loss: 0.7488 - binary_accuracy: 0.7500\n",
            "Epoch 91/300\n",
            " - 0s - loss: 0.7478 - binary_accuracy: 0.7500\n",
            "Epoch 92/300\n",
            " - 0s - loss: 0.7468 - binary_accuracy: 0.7500\n",
            "Epoch 93/300\n",
            " - 0s - loss: 0.7459 - binary_accuracy: 0.7500\n",
            "Epoch 94/300\n",
            " - 0s - loss: 0.7449 - binary_accuracy: 0.7500\n",
            "Epoch 95/300\n",
            " - 0s - loss: 0.7440 - binary_accuracy: 0.7500\n",
            "Epoch 96/300\n",
            " - 0s - loss: 0.7431 - binary_accuracy: 0.7500\n",
            "Epoch 97/300\n",
            " - 0s - loss: 0.7422 - binary_accuracy: 0.7500\n",
            "Epoch 98/300\n",
            " - 0s - loss: 0.7413 - binary_accuracy: 0.7500\n",
            "Epoch 99/300\n",
            " - 0s - loss: 0.7404 - binary_accuracy: 0.7500\n",
            "Epoch 100/300\n",
            " - 0s - loss: 0.7395 - binary_accuracy: 0.7500\n",
            "Epoch 101/300\n",
            " - 0s - loss: 0.7386 - binary_accuracy: 0.7500\n",
            "Epoch 102/300\n",
            " - 0s - loss: 0.7377 - binary_accuracy: 0.7500\n",
            "Epoch 103/300\n",
            " - 0s - loss: 0.7368 - binary_accuracy: 0.7500\n",
            "Epoch 104/300\n",
            " - 0s - loss: 0.7360 - binary_accuracy: 0.7500\n",
            "Epoch 105/300\n",
            " - 0s - loss: 0.7351 - binary_accuracy: 0.7500\n",
            "Epoch 106/300\n",
            " - 0s - loss: 0.7342 - binary_accuracy: 0.7500\n",
            "Epoch 107/300\n",
            " - 0s - loss: 0.7334 - binary_accuracy: 0.7500\n",
            "Epoch 108/300\n",
            " - 0s - loss: 0.7325 - binary_accuracy: 0.7500\n",
            "Epoch 109/300\n",
            " - 0s - loss: 0.7317 - binary_accuracy: 0.7500\n",
            "Epoch 110/300\n",
            " - 0s - loss: 0.7308 - binary_accuracy: 0.7500\n",
            "Epoch 111/300\n",
            " - 0s - loss: 0.7300 - binary_accuracy: 0.7500\n",
            "Epoch 112/300\n",
            " - 0s - loss: 0.7291 - binary_accuracy: 0.7500\n",
            "Epoch 113/300\n",
            " - 0s - loss: 0.7283 - binary_accuracy: 0.7500\n",
            "Epoch 114/300\n",
            " - 0s - loss: 0.7275 - binary_accuracy: 0.7500\n",
            "Epoch 115/300\n",
            " - 0s - loss: 0.7266 - binary_accuracy: 0.7500\n",
            "Epoch 116/300\n",
            " - 0s - loss: 0.7258 - binary_accuracy: 0.7500\n",
            "Epoch 117/300\n",
            " - 0s - loss: 0.7250 - binary_accuracy: 0.7500\n",
            "Epoch 118/300\n",
            " - 0s - loss: 0.7242 - binary_accuracy: 0.7500\n",
            "Epoch 119/300\n",
            " - 0s - loss: 0.7235 - binary_accuracy: 0.7500\n",
            "Epoch 120/300\n",
            " - 0s - loss: 0.7227 - binary_accuracy: 0.7500\n",
            "Epoch 121/300\n",
            " - 0s - loss: 0.7219 - binary_accuracy: 0.7500\n",
            "Epoch 122/300\n",
            " - 0s - loss: 0.7212 - binary_accuracy: 0.7500\n",
            "Epoch 123/300\n",
            " - 0s - loss: 0.7204 - binary_accuracy: 0.7500\n",
            "Epoch 124/300\n",
            " - 0s - loss: 0.7196 - binary_accuracy: 0.7500\n",
            "Epoch 125/300\n",
            " - 0s - loss: 0.7188 - binary_accuracy: 0.7500\n",
            "Epoch 126/300\n",
            " - 0s - loss: 0.7180 - binary_accuracy: 0.7500\n",
            "Epoch 127/300\n",
            " - 0s - loss: 0.7173 - binary_accuracy: 0.7500\n",
            "Epoch 128/300\n",
            " - 0s - loss: 0.7165 - binary_accuracy: 0.7500\n",
            "Epoch 129/300\n",
            " - 0s - loss: 0.7158 - binary_accuracy: 0.7500\n",
            "Epoch 130/300\n",
            " - 0s - loss: 0.7150 - binary_accuracy: 0.7500\n",
            "Epoch 131/300\n",
            " - 0s - loss: 0.7143 - binary_accuracy: 0.7500\n",
            "Epoch 132/300\n",
            " - 0s - loss: 0.7136 - binary_accuracy: 0.7500\n",
            "Epoch 133/300\n",
            " - 0s - loss: 0.7128 - binary_accuracy: 0.7500\n",
            "Epoch 134/300\n",
            " - 0s - loss: 0.7121 - binary_accuracy: 0.7500\n",
            "Epoch 135/300\n",
            " - 0s - loss: 0.7113 - binary_accuracy: 0.7500\n",
            "Epoch 136/300\n",
            " - 0s - loss: 0.7106 - binary_accuracy: 0.7500\n",
            "Epoch 137/300\n",
            " - 0s - loss: 0.7099 - binary_accuracy: 0.7500\n",
            "Epoch 138/300\n",
            " - 0s - loss: 0.7092 - binary_accuracy: 0.7500\n",
            "Epoch 139/300\n",
            " - 0s - loss: 0.7084 - binary_accuracy: 0.7500\n",
            "Epoch 140/300\n",
            " - 0s - loss: 0.7077 - binary_accuracy: 0.7500\n",
            "Epoch 141/300\n",
            " - 0s - loss: 0.7070 - binary_accuracy: 0.7500\n",
            "Epoch 142/300\n",
            " - 0s - loss: 0.7063 - binary_accuracy: 0.7500\n",
            "Epoch 143/300\n",
            " - 0s - loss: 0.7056 - binary_accuracy: 0.7500\n",
            "Epoch 144/300\n",
            " - 0s - loss: 0.7048 - binary_accuracy: 0.7500\n",
            "Epoch 145/300\n",
            " - 0s - loss: 0.7041 - binary_accuracy: 0.7500\n",
            "Epoch 146/300\n",
            " - 0s - loss: 0.7034 - binary_accuracy: 0.7500\n",
            "Epoch 147/300\n",
            " - 0s - loss: 0.7027 - binary_accuracy: 0.7500\n",
            "Epoch 148/300\n",
            " - 0s - loss: 0.7020 - binary_accuracy: 0.7500\n",
            "Epoch 149/300\n",
            " - 0s - loss: 0.7013 - binary_accuracy: 0.7500\n",
            "Epoch 150/300\n",
            " - 0s - loss: 0.7007 - binary_accuracy: 0.7500\n",
            "Epoch 151/300\n",
            " - 0s - loss: 0.7000 - binary_accuracy: 0.7500\n",
            "Epoch 152/300\n",
            " - 0s - loss: 0.6993 - binary_accuracy: 0.7500\n",
            "Epoch 153/300\n",
            " - 0s - loss: 0.6986 - binary_accuracy: 0.7500\n",
            "Epoch 154/300\n",
            " - 0s - loss: 0.6979 - binary_accuracy: 0.7500\n",
            "Epoch 155/300\n",
            " - 0s - loss: 0.6972 - binary_accuracy: 0.7500\n",
            "Epoch 156/300\n",
            " - 0s - loss: 0.6966 - binary_accuracy: 0.7500\n",
            "Epoch 157/300\n",
            " - 0s - loss: 0.6959 - binary_accuracy: 0.7500\n",
            "Epoch 158/300\n",
            " - 0s - loss: 0.6952 - binary_accuracy: 0.7500\n",
            "Epoch 159/300\n",
            " - 0s - loss: 0.6945 - binary_accuracy: 0.7500\n",
            "Epoch 160/300\n",
            " - 0s - loss: 0.6939 - binary_accuracy: 0.7500\n",
            "Epoch 161/300\n",
            " - 0s - loss: 0.6932 - binary_accuracy: 0.7500\n",
            "Epoch 162/300\n",
            " - 0s - loss: 0.6926 - binary_accuracy: 0.7500\n",
            "Epoch 163/300\n",
            " - 0s - loss: 0.6919 - binary_accuracy: 0.7500\n",
            "Epoch 164/300\n",
            " - 0s - loss: 0.6912 - binary_accuracy: 0.7500\n",
            "Epoch 165/300\n",
            " - 0s - loss: 0.6906 - binary_accuracy: 0.7500\n",
            "Epoch 166/300\n",
            " - 0s - loss: 0.6899 - binary_accuracy: 0.7500\n",
            "Epoch 167/300\n",
            " - 0s - loss: 0.6892 - binary_accuracy: 0.7500\n",
            "Epoch 168/300\n",
            " - 0s - loss: 0.6886 - binary_accuracy: 0.7500\n",
            "Epoch 169/300\n",
            " - 0s - loss: 0.6880 - binary_accuracy: 0.7500\n",
            "Epoch 170/300\n",
            " - 0s - loss: 0.6873 - binary_accuracy: 0.7500\n",
            "Epoch 171/300\n",
            " - 0s - loss: 0.6866 - binary_accuracy: 0.7500\n",
            "Epoch 172/300\n",
            " - 0s - loss: 0.6860 - binary_accuracy: 0.7500\n",
            "Epoch 173/300\n",
            " - 0s - loss: 0.6854 - binary_accuracy: 0.7500\n",
            "Epoch 174/300\n",
            " - 0s - loss: 0.6847 - binary_accuracy: 0.7500\n",
            "Epoch 175/300\n",
            " - 0s - loss: 0.6841 - binary_accuracy: 0.7500\n",
            "Epoch 176/300\n",
            " - 0s - loss: 0.6835 - binary_accuracy: 0.7500\n",
            "Epoch 177/300\n",
            " - 0s - loss: 0.6828 - binary_accuracy: 0.7500\n",
            "Epoch 178/300\n",
            " - 0s - loss: 0.6821 - binary_accuracy: 0.7500\n",
            "Epoch 179/300\n",
            " - 0s - loss: 0.6815 - binary_accuracy: 0.7500\n",
            "Epoch 180/300\n",
            " - 0s - loss: 0.6808 - binary_accuracy: 0.7500\n",
            "Epoch 181/300\n",
            " - 0s - loss: 0.6802 - binary_accuracy: 0.7500\n",
            "Epoch 182/300\n",
            " - 0s - loss: 0.6795 - binary_accuracy: 0.7500\n",
            "Epoch 183/300\n",
            " - 0s - loss: 0.6789 - binary_accuracy: 0.7500\n",
            "Epoch 184/300\n",
            " - 0s - loss: 0.6783 - binary_accuracy: 0.7500\n",
            "Epoch 185/300\n",
            " - 0s - loss: 0.6777 - binary_accuracy: 0.7500\n",
            "Epoch 186/300\n",
            " - 0s - loss: 0.6771 - binary_accuracy: 0.7500\n",
            "Epoch 187/300\n",
            " - 0s - loss: 0.6764 - binary_accuracy: 0.7500\n",
            "Epoch 188/300\n",
            " - 0s - loss: 0.6757 - binary_accuracy: 0.7500\n",
            "Epoch 189/300\n",
            " - 0s - loss: 0.6751 - binary_accuracy: 0.7500\n",
            "Epoch 190/300\n",
            " - 0s - loss: 0.6745 - binary_accuracy: 0.7500\n",
            "Epoch 191/300\n",
            " - 0s - loss: 0.6739 - binary_accuracy: 0.7500\n",
            "Epoch 192/300\n",
            " - 0s - loss: 0.6732 - binary_accuracy: 0.7500\n",
            "Epoch 193/300\n",
            " - 0s - loss: 0.6726 - binary_accuracy: 0.7500\n",
            "Epoch 194/300\n",
            " - 0s - loss: 0.6720 - binary_accuracy: 0.7500\n",
            "Epoch 195/300\n",
            " - 0s - loss: 0.6714 - binary_accuracy: 0.7500\n",
            "Epoch 196/300\n",
            " - 0s - loss: 0.6707 - binary_accuracy: 0.7500\n",
            "Epoch 197/300\n",
            " - 0s - loss: 0.6701 - binary_accuracy: 0.7500\n",
            "Epoch 198/300\n",
            " - 0s - loss: 0.6694 - binary_accuracy: 0.7500\n",
            "Epoch 199/300\n",
            " - 0s - loss: 0.6687 - binary_accuracy: 0.7500\n",
            "Epoch 200/300\n",
            " - 0s - loss: 0.6681 - binary_accuracy: 0.7500\n",
            "Epoch 201/300\n",
            " - 0s - loss: 0.6675 - binary_accuracy: 0.7500\n",
            "Epoch 202/300\n",
            " - 0s - loss: 0.6669 - binary_accuracy: 0.7500\n",
            "Epoch 203/300\n",
            " - 0s - loss: 0.6662 - binary_accuracy: 0.7500\n",
            "Epoch 204/300\n",
            " - 0s - loss: 0.6656 - binary_accuracy: 0.7500\n",
            "Epoch 205/300\n",
            " - 0s - loss: 0.6650 - binary_accuracy: 0.7500\n",
            "Epoch 206/300\n",
            " - 0s - loss: 0.6643 - binary_accuracy: 0.7500\n",
            "Epoch 207/300\n",
            " - 0s - loss: 0.6637 - binary_accuracy: 0.7500\n",
            "Epoch 208/300\n",
            " - 0s - loss: 0.6631 - binary_accuracy: 0.7500\n",
            "Epoch 209/300\n",
            " - 0s - loss: 0.6625 - binary_accuracy: 0.7500\n",
            "Epoch 210/300\n",
            " - 0s - loss: 0.6619 - binary_accuracy: 0.7500\n",
            "Epoch 211/300\n",
            " - 0s - loss: 0.6613 - binary_accuracy: 0.7500\n",
            "Epoch 212/300\n",
            " - 0s - loss: 0.6607 - binary_accuracy: 0.7500\n",
            "Epoch 213/300\n",
            " - 0s - loss: 0.6600 - binary_accuracy: 0.7500\n",
            "Epoch 214/300\n",
            " - 0s - loss: 0.6595 - binary_accuracy: 0.7500\n",
            "Epoch 215/300\n",
            " - 0s - loss: 0.6590 - binary_accuracy: 0.7500\n",
            "Epoch 216/300\n",
            " - 0s - loss: 0.6585 - binary_accuracy: 0.7500\n",
            "Epoch 217/300\n",
            " - 0s - loss: 0.6580 - binary_accuracy: 0.7500\n",
            "Epoch 218/300\n",
            " - 0s - loss: 0.6574 - binary_accuracy: 0.7500\n",
            "Epoch 219/300\n",
            " - 0s - loss: 0.6569 - binary_accuracy: 0.7500\n",
            "Epoch 220/300\n",
            " - 0s - loss: 0.6563 - binary_accuracy: 0.7500\n",
            "Epoch 221/300\n",
            " - 0s - loss: 0.6559 - binary_accuracy: 0.7500\n",
            "Epoch 222/300\n",
            " - 0s - loss: 0.6554 - binary_accuracy: 0.7500\n",
            "Epoch 223/300\n",
            " - 0s - loss: 0.6550 - binary_accuracy: 0.7500\n",
            "Epoch 224/300\n",
            " - 0s - loss: 0.6547 - binary_accuracy: 0.7500\n",
            "Epoch 225/300\n",
            " - 0s - loss: 0.6544 - binary_accuracy: 0.7500\n",
            "Epoch 226/300\n",
            " - 0s - loss: 0.6541 - binary_accuracy: 0.7500\n",
            "Epoch 227/300\n",
            " - 0s - loss: 0.6537 - binary_accuracy: 0.7500\n",
            "Epoch 228/300\n",
            " - 0s - loss: 0.6533 - binary_accuracy: 0.7500\n",
            "Epoch 229/300\n",
            " - 0s - loss: 0.6529 - binary_accuracy: 0.7500\n",
            "Epoch 230/300\n",
            " - 0s - loss: 0.6525 - binary_accuracy: 0.7500\n",
            "Epoch 231/300\n",
            " - 0s - loss: 0.6521 - binary_accuracy: 0.7500\n",
            "Epoch 232/300\n",
            " - 0s - loss: 0.6518 - binary_accuracy: 0.7500\n",
            "Epoch 233/300\n",
            " - 0s - loss: 0.6514 - binary_accuracy: 0.7500\n",
            "Epoch 234/300\n",
            " - 0s - loss: 0.6510 - binary_accuracy: 0.7500\n",
            "Epoch 235/300\n",
            " - 0s - loss: 0.6507 - binary_accuracy: 0.7500\n",
            "Epoch 236/300\n",
            " - 0s - loss: 0.6503 - binary_accuracy: 0.7500\n",
            "Epoch 237/300\n",
            " - 0s - loss: 0.6499 - binary_accuracy: 0.7500\n",
            "Epoch 238/300\n",
            " - 0s - loss: 0.6495 - binary_accuracy: 0.7500\n",
            "Epoch 239/300\n",
            " - 0s - loss: 0.6492 - binary_accuracy: 0.7500\n",
            "Epoch 240/300\n",
            " - 0s - loss: 0.6489 - binary_accuracy: 0.7500\n",
            "Epoch 241/300\n",
            " - 0s - loss: 0.6485 - binary_accuracy: 0.7500\n",
            "Epoch 242/300\n",
            " - 0s - loss: 0.6481 - binary_accuracy: 0.7500\n",
            "Epoch 243/300\n",
            " - 0s - loss: 0.6478 - binary_accuracy: 0.7500\n",
            "Epoch 244/300\n",
            " - 0s - loss: 0.6474 - binary_accuracy: 0.7500\n",
            "Epoch 245/300\n",
            " - 0s - loss: 0.6470 - binary_accuracy: 0.7500\n",
            "Epoch 246/300\n",
            " - 0s - loss: 0.6467 - binary_accuracy: 0.7500\n",
            "Epoch 247/300\n",
            " - 0s - loss: 0.6464 - binary_accuracy: 0.7500\n",
            "Epoch 248/300\n",
            " - 0s - loss: 0.6460 - binary_accuracy: 0.7500\n",
            "Epoch 249/300\n",
            " - 0s - loss: 0.6457 - binary_accuracy: 0.7500\n",
            "Epoch 250/300\n",
            " - 0s - loss: 0.6454 - binary_accuracy: 0.7500\n",
            "Epoch 251/300\n",
            " - 0s - loss: 0.6450 - binary_accuracy: 0.7500\n",
            "Epoch 252/300\n",
            " - 0s - loss: 0.6447 - binary_accuracy: 0.7500\n",
            "Epoch 253/300\n",
            " - 0s - loss: 0.6443 - binary_accuracy: 0.7500\n",
            "Epoch 254/300\n",
            " - 0s - loss: 0.6440 - binary_accuracy: 0.7500\n",
            "Epoch 255/300\n",
            " - 0s - loss: 0.6437 - binary_accuracy: 0.7500\n",
            "Epoch 256/300\n",
            " - 0s - loss: 0.6433 - binary_accuracy: 0.7500\n",
            "Epoch 257/300\n",
            " - 0s - loss: 0.6430 - binary_accuracy: 0.7500\n",
            "Epoch 258/300\n",
            " - 0s - loss: 0.6426 - binary_accuracy: 0.7500\n",
            "Epoch 259/300\n",
            " - 0s - loss: 0.6422 - binary_accuracy: 0.7500\n",
            "Epoch 260/300\n",
            " - 0s - loss: 0.6419 - binary_accuracy: 0.7500\n",
            "Epoch 261/300\n",
            " - 0s - loss: 0.6416 - binary_accuracy: 0.7500\n",
            "Epoch 262/300\n",
            " - 0s - loss: 0.6412 - binary_accuracy: 0.7500\n",
            "Epoch 263/300\n",
            " - 0s - loss: 0.6408 - binary_accuracy: 0.7500\n",
            "Epoch 264/300\n",
            " - 0s - loss: 0.6405 - binary_accuracy: 0.7500\n",
            "Epoch 265/300\n",
            " - 0s - loss: 0.6402 - binary_accuracy: 0.7500\n",
            "Epoch 266/300\n",
            " - 0s - loss: 0.6398 - binary_accuracy: 0.7500\n",
            "Epoch 267/300\n",
            " - 0s - loss: 0.6395 - binary_accuracy: 0.7500\n",
            "Epoch 268/300\n",
            " - 0s - loss: 0.6391 - binary_accuracy: 0.7500\n",
            "Epoch 269/300\n",
            " - 0s - loss: 0.6388 - binary_accuracy: 0.7500\n",
            "Epoch 270/300\n",
            " - 0s - loss: 0.6384 - binary_accuracy: 0.7500\n",
            "Epoch 271/300\n",
            " - 0s - loss: 0.6381 - binary_accuracy: 0.7500\n",
            "Epoch 272/300\n",
            " - 0s - loss: 0.6377 - binary_accuracy: 0.7500\n",
            "Epoch 273/300\n",
            " - 0s - loss: 0.6374 - binary_accuracy: 0.7500\n",
            "Epoch 274/300\n",
            " - 0s - loss: 0.6370 - binary_accuracy: 0.7500\n",
            "Epoch 275/300\n",
            " - 0s - loss: 0.6367 - binary_accuracy: 0.7500\n",
            "Epoch 276/300\n",
            " - 0s - loss: 0.6363 - binary_accuracy: 0.7500\n",
            "Epoch 277/300\n",
            " - 0s - loss: 0.6360 - binary_accuracy: 0.7500\n",
            "Epoch 278/300\n",
            " - 0s - loss: 0.6357 - binary_accuracy: 0.7500\n",
            "Epoch 279/300\n",
            " - 0s - loss: 0.6353 - binary_accuracy: 0.7500\n",
            "Epoch 280/300\n",
            " - 0s - loss: 0.6350 - binary_accuracy: 0.7500\n",
            "Epoch 281/300\n",
            " - 0s - loss: 0.6347 - binary_accuracy: 0.7500\n",
            "Epoch 282/300\n",
            " - 0s - loss: 0.6343 - binary_accuracy: 0.7500\n",
            "Epoch 283/300\n",
            " - 0s - loss: 0.6339 - binary_accuracy: 0.7500\n",
            "Epoch 284/300\n",
            " - 0s - loss: 0.6336 - binary_accuracy: 0.7500\n",
            "Epoch 285/300\n",
            " - 0s - loss: 0.6332 - binary_accuracy: 0.7500\n",
            "Epoch 286/300\n",
            " - 0s - loss: 0.6328 - binary_accuracy: 0.7500\n",
            "Epoch 287/300\n",
            " - 0s - loss: 0.6325 - binary_accuracy: 0.7500\n",
            "Epoch 288/300\n",
            " - 0s - loss: 0.6321 - binary_accuracy: 0.7500\n",
            "Epoch 289/300\n",
            " - 0s - loss: 0.6318 - binary_accuracy: 0.7500\n",
            "Epoch 290/300\n",
            " - 0s - loss: 0.6314 - binary_accuracy: 0.7500\n",
            "Epoch 291/300\n",
            " - 0s - loss: 0.6311 - binary_accuracy: 0.7500\n",
            "Epoch 292/300\n",
            " - 0s - loss: 0.6307 - binary_accuracy: 0.7500\n",
            "Epoch 293/300\n",
            " - 0s - loss: 0.6303 - binary_accuracy: 0.7500\n",
            "Epoch 294/300\n",
            " - 0s - loss: 0.6300 - binary_accuracy: 0.7500\n",
            "Epoch 295/300\n",
            " - 0s - loss: 0.6297 - binary_accuracy: 0.7500\n",
            "Epoch 296/300\n",
            " - 0s - loss: 0.6293 - binary_accuracy: 0.7500\n",
            "Epoch 297/300\n",
            " - 0s - loss: 0.6290 - binary_accuracy: 0.7500\n",
            "Epoch 298/300\n",
            " - 0s - loss: 0.6286 - binary_accuracy: 0.7500\n",
            "Epoch 299/300\n",
            " - 0s - loss: 0.6283 - binary_accuracy: 0.7500\n",
            "Epoch 300/300\n",
            " - 0s - loss: 0.6279 - binary_accuracy: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e05a30860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SggP_xNfgS3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "a211e684-f5fd-469c-fca2-bf96d44120a8"
      },
      "source": [
        "print(feature_data)\n",
        "print(model.predict_classes(feature_data)) #classification일때 predict_classes, regression일때는 pretict()사"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}