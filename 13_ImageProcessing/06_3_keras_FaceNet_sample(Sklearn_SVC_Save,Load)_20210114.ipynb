{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06_2_keras_FaceNet_sample(Sklearn_SVC_Save,Load)_20210114.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPHM1-dJ7-4q"
      },
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQHEIgdTM80",
        "outputId": "46270e9b-6dd0-47f7-d180-b73c4751c8eb"
      },
      "source": [
        "# python/tensorflow 워닝 막기\r\n",
        "import warnings , os\r\n",
        "#warnings.filterwarnings(action='ignore')\r\n",
        "warnings.filterwarnings(action='once')\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \r\n",
        "import tensorflow as tf\r\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUTGOVZmqinW"
      },
      "source": [
        "# # # # # https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-17%EC%9D%BC%EC%B0%A8-%EB%A1%9C%EC%9D%B4%ED%84%B0-%EB%89%B4%EC%8A%A4-%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0-f5466abe9196\r\n",
        "# # # # np.load()에서 import_pickle=False오류 날경우, 최초실행시 한번 설치해, 주석처리하고 재실행하면 downgrade로 적용됨\r\n",
        "# !pip uninstall numpy -y\r\n",
        "# !pip install --upgrade numpy==1.16.1\r\n",
        "# # ##!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfXNEM5mrF_l",
        "outputId": "dea43c77-a460-4e67-f944-b24492577f65"
      },
      "source": [
        "import numpy as np\r\n",
        "print(np.__version__) #'1.16.1'\r\n",
        "\r\n",
        "import dill\r\n",
        "print('dill.__version__:', dill.__version__)\r\n",
        "import sklearn\r\n",
        "print('sklearn.__version__:', sklearn.__version__)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.5\n",
            "dill.__version__: 0.3.3\n",
            "sklearn.__version__: 0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHP91hX8pITS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ee05f4-536a-4444-cbb8-3bf49c47c22c"
      },
      "source": [
        "###########################\r\n",
        "# google drive 저장/로딩\r\n",
        "###########################\r\n",
        "#구글 드라이브 저장\r\n",
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gcp_drive = None\r\n",
        "def doGoodleDriveAuth():\r\n",
        "    # 1. Authenticate and create the PyDrive client.\r\n",
        "    auth.authenticate_user()\r\n",
        "    gauth = GoogleAuth()\r\n",
        "    print('gauth:',gauth)\r\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "\r\n",
        "    gcp_drive = GoogleDrive(gauth)\r\n",
        "    print('gcp_drive:', gcp_drive)\r\n",
        "    return gcp_drive\r\n",
        "\r\n",
        "# PyDrive reference:\r\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\r\n",
        "def gcp_upload(file_path, w_file_name):\r\n",
        "    try:\r\n",
        "        if gcp_drive == None:\r\n",
        "            drive = doGoodleDriveAuth()\r\n",
        "\r\n",
        "        # 특정 폴더 안으로 파일 삽입\r\n",
        "        uploaded = drive.CreateFile({'title': w_file_name}) #, \"parents\": [{\"kind\": \"drive#fileLink\",\"id\": 'jukyellow@gmail.com'}]})\r\n",
        "        uploaded.SetContentString(w_file_name)\r\n",
        "        uploaded.SetContentFile(file_path + w_file_name)\r\n",
        "        uploaded.Upload()\r\n",
        "        print('Uploaded file with ID {}'.format(uploaded.get('id')))\r\n",
        "        return uploaded.get('id')\r\n",
        "    except Exception as e: print('gcp_upload err:', e)\r\n",
        "\r\n",
        "#구글 드라이브에서 다운로드\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from googleapiclient.discovery import build\r\n",
        "drive_service = build('drive', 'v3')\r\n",
        "import io\r\n",
        "from io import BytesIO \r\n",
        "from googleapiclient.http import MediaIoBaseDownload\r\n",
        "\r\n",
        "TEMP_PATH = '/tmp/'\r\n",
        "def gcp_download(file_name, key):\r\n",
        "    #3. 모델 다운로드\r\n",
        "    #https://drive.google.com/open?id=1TlvbayGRCjAI6bOZrUYMmv6g6b95rnRM\r\n",
        "    request = drive_service.files().get_media(fileId=key)\r\n",
        "\r\n",
        "    downloaded = io.BytesIO()\r\n",
        "    downloader = MediaIoBaseDownload(downloaded, request)\r\n",
        "    done = False\r\n",
        "    while done is False:\r\n",
        "      status, done = downloader.next_chunk()\r\n",
        "      if status:\r\n",
        "          print(\"Download %%%d%%.\" % int(status.progress() * 100))\r\n",
        "      print(\"Download Complete!\")\r\n",
        "    downloaded.seek(0)\r\n",
        "\r\n",
        "    with open(TEMP_PATH + file_name, 'wb') as f:\r\n",
        "        f.write(downloaded.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google/colab/auth.py:148: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 33208), raddr=('173.194.202.95', 443)>\n",
            "  if not _check_adc():\n",
            "/usr/local/lib/python3.6/dist-packages/google/colab/auth.py:169: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 47060), raddr=('74.125.142.95', 443)>\n",
            "  if _check_adc():\n",
            "/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py:134: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 47062), raddr=('74.125.142.95', 443)>\n",
            "  return wrapped(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYrTxvCnpIaP",
        "outputId": "3a9c7305-a96b-45fb-a093-68f3a741e7ca"
      },
      "source": [
        "# https://drive.google.com/file/d/1_Hj9zu0lYUoeL0d1AqPGZa78OxNrpER2/view?usp=sharing\r\n",
        "# gcp에서 폴더명 사진 다운로드, 압축풀기\r\n",
        "down_file_name = 'facenet_keras.h5'\r\n",
        "gcp_download(down_file_name, '1_Hj9zu0lYUoeL0d1AqPGZa78OxNrpER2') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download %100%.\n",
            "Download Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-SAXUVCqYD_"
      },
      "source": [
        "!mv /tmp/facenet_keras.h5 /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dok51GcsqIr6",
        "outputId": "5c5b26b5-8040-4c48-e559-84f922a83083"
      },
      "source": [
        "# # gcp에서 폴더명 사진 다운로드, 압축풀기\r\n",
        "# down_file_name = '00_origin_전체.zip'\r\n",
        "# gcp_download(down_file_name, '1k0lm-uBfxlUbqtzvZ4xjVa_ojS0fPFUG')  #https://drive.google.com/file/d/1k0lm-uBfxlUbqtzvZ4xjVa_ojS0fPFUG/view?usp=sharing\r\n",
        "down_file_name = '00_Total.zip'\r\n",
        "gcp_download(down_file_name, '1Ur65v2wTgFTGmr-mLTft9kOl9pDLnH7Z')  #https://drive.google.com/file/d/1Ur65v2wTgFTGmr-mLTft9kOl9pDLnH7Z/view?usp=sharing "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download %100%.\n",
            "Download Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IFufKgcwS4_"
      },
      "source": [
        "!\\rm -rf /content/origin_data\r\n",
        "!\\rm -rf /content/face_data\r\n",
        "\r\n",
        "!mkdir /content/origin_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "063fiJrTqUTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538975af-804e-4bdf-e8bf-380cc653d5c9"
      },
      "source": [
        "# 한글깨짐 방지: -O cp949 \r\n",
        "!unzip -O cp949 /tmp/00_Total.zip\r\n",
        "!rm -rf /tmp/00_Total.zip\r\n",
        "\r\n",
        "!mv /content/00_Total/00_전체 /content/origin_data\r\n",
        "\r\n",
        "!mkdir /content/face_data\r\n",
        "!mkdir /content/face_data/train\r\n",
        "!mkdir /content/face_data/test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/00_Total/00_전체': No such file or directory\n",
            "mkdir: cannot create directory ‘/content/face_data’: File exists\n",
            "mkdir: cannot create directory ‘/content/face_data/train’: File exists\n",
            "mkdir: cannot create directory ‘/content/face_data/test’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCeZDod9Tqxs"
      },
      "source": [
        "# 원본경로 파일목록 읽기\r\n",
        "import os\r\n",
        "\r\n",
        "path = '/content/origin_data/'\r\n",
        "imgFileList = os.listdir(path)\r\n",
        "\r\n",
        "imgFileList = [x for x in imgFileList if 'jpg' in x or 'jpeg' in x] # jpg파일만 불러오기\r\n",
        "\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "  print('i:',i+1 , ' ,name:', file_name)\r\n",
        "  #if i > 1 : break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yFSaZcStsQ"
      },
      "source": [
        "# preview 이미지 생성 메소드 \r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "\r\n",
        "def save_img_by_img_gen(path, file_name, MAX_GEN_CNT, save_path, new_dir, gen_type):\r\n",
        "    if \"train\" == gen_type:\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            rotation_range=10,\r\n",
        "            width_shift_range=0.1,\r\n",
        "            height_shift_range=0.1,\r\n",
        "            #rescale=1./255, predict시에는 이미지 스케일 작업없어서 제외\r\n",
        "            shear_range=0.1,\r\n",
        "            zoom_range=0.1, #확대/축소 비율\r\n",
        "            brightness_range= [0.1, 1.0], # 밝기 비율\r\n",
        "            channel_shift_range=80, # rgb 채널 랜덤 섞기(명암 어둡게 변함)\r\n",
        "            horizontal_flip=True,  #가로 대칭 전환\r\n",
        "            cval = 255, # constant일때 여백 흰색\r\n",
        "            fill_mode='constant') #nearest constant\r\n",
        "    else:\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            rotation_range=20,\r\n",
        "            width_shift_range=0.1,\r\n",
        "            height_shift_range=0.1,\r\n",
        "            #rescale=1./255, predict시에는 이미지 스케일 작업없어서 제외\r\n",
        "            shear_range=0.2,\r\n",
        "            zoom_range=0.2, #확대/축소 비율\r\n",
        "            brightness_range= [0.1, 1.0], # 밝기 비율\r\n",
        "            channel_shift_range=80, # rgb 채널 랜덤 섞기(명암 어둡게 변함)\r\n",
        "            horizontal_flip=True,  #가로 대칭 전환\r\n",
        "            cval = 255, # constant일때 여백 흰색\r\n",
        "            fill_mode='constant') #nearest constant\r\n",
        "\r\n",
        "    img = load_img(path+\"/\"+file_name)  # PIL 이미지\r\n",
        "    x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\r\n",
        "    x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\r\n",
        "    print('x.shape:', x.shape)\r\n",
        "\r\n",
        "    #파일명별 폴더 생성\r\n",
        "    file_name = file_name.replace(\".jpg\",\"\")\r\n",
        "    new_path = new_dir + file_name\r\n",
        "    if not(os.path.isdir(new_path)): os.makedirs(os.path.join(new_path))\r\n",
        "\r\n",
        "    # 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서, save_to_dir저장\r\n",
        "    i = 0\r\n",
        "    for batch in datagen.flow(x, batch_size=1, save_to_dir=save_path+file_name, save_prefix=file_name, save_format='jpg'):\r\n",
        "        i += 1\r\n",
        "        if i > MAX_GEN_CNT: break \r\n",
        "\r\n",
        "# 이미지 변환 파일 생성\r\n",
        "MAX_GEN_CNT = 20\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "    save_img_by_img_gen(path, file_name, MAX_GEN_CNT, 'face_data/train/', '/content/face_data/train/', 'train')\r\n",
        "    print('i:',i+1 , ' ,name:', file_name + \" 변형 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdil8jljY2n5"
      },
      "source": [
        "# 추가 이미지 train data로 복사\r\n",
        "!mv /content/00_Total/*1.jpg /content/face_data/train/A06_OOO/\r\n",
        "!mv /content/00_Total/*2.jpg /content/face_data/train/A06_OOO/\r\n",
        "!\\rm -rf /content/00_Total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HUNHOeEjwLZ"
      },
      "source": [
        "# 이미지 변환 파일 생성\r\n",
        "MAX_GEN_CNT = 5\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "    save_img_by_img_gen(path, file_name, MAX_GEN_CNT, 'face_data/test/', '/content/face_data/test/', 'test')\r\n",
        "    print('i:',i+1 , ' ,name:', file_name + \" 변형 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHAwr_l_8GPv",
        "outputId": "1ed4913c-2207-484d-a8e2-25f8ab12a376"
      },
      "source": [
        "# example of loading the keras facenet model\r\n",
        "from keras.models import load_model\r\n",
        "# load the model\r\n",
        "facenet_model = load_model('facenet_keras.h5')\r\n",
        "# summarize input and output shape\r\n",
        "print(facenet_model.inputs)\r\n",
        "print(facenet_model.outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
            "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgCLdxxs8GSG",
        "outputId": "f8fdda04-1e04-41ce-f47a-81da57b38084"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.16.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google/colab/_pip.py:87: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.6/dist-packages/mtcnn-0.1.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLrgdv0L8GUY",
        "outputId": "1e21338f-f174-4fa8-f2ea-23997823685d"
      },
      "source": [
        "# confirm mtcnn was installed correctly\r\n",
        "import mtcnn\r\n",
        "# print version\r\n",
        "print(mtcnn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UNLqXLw8GXV"
      },
      "source": [
        "# demonstrate face detection on 5 Celebrity Faces Dataset\r\n",
        "from os import listdir\r\n",
        "from PIL import Image\r\n",
        "from numpy import asarray\r\n",
        "from matplotlib import pyplot\r\n",
        "from mtcnn.mtcnn import MTCNN\r\n",
        " \r\n",
        "# extract a single face from a given photograph\r\n",
        "def extract_face(filename, required_size=(160, 160)):\r\n",
        "    # load image from file\r\n",
        "    image = Image.open(filename)\r\n",
        "    # convert to RGB, if needed\r\n",
        "    image = image.convert('RGB')\r\n",
        "    # convert to array\r\n",
        "    pixels = asarray(image)\r\n",
        "    # create the detector, using default weights\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect faces in the image\r\n",
        "    results = detector.detect_faces(pixels)\r\n",
        "    if len(results) == 0 :\r\n",
        "        print('------------------------------------------')\r\n",
        "        print('results:', results, ', filename:', filename)\r\n",
        "        print('------------------------------------------')\r\n",
        "        return []\r\n",
        "\r\n",
        "    # extract the bounding box from the first face\r\n",
        "    x1, y1, width, height = results[0]['box']\r\n",
        "    # bug fix\r\n",
        "    x1, y1 = abs(x1), abs(y1)\r\n",
        "    x2, y2 = x1 + width, y1 + height\r\n",
        "    # extract the face\r\n",
        "    face = pixels[y1:y2, x1:x2]\r\n",
        "    # resize pixels to the model size\r\n",
        "    image = Image.fromarray(face)\r\n",
        "    image = image.resize(required_size)\r\n",
        "    face_array = asarray(image)\r\n",
        "    return face_array\r\n",
        " \r\n",
        "# specify folder to plot\r\n",
        "folder = './face_data/test/A06_OOO/'\r\n",
        "i = 1\r\n",
        "# enumerate files\r\n",
        "for filename in listdir(folder):\r\n",
        "    if 'jpg' not in filename and 'jpeg' not in filename: continue\r\n",
        "    # path\r\n",
        "    path = folder + filename\r\n",
        "    # get face\r\n",
        "    face = extract_face(path)\r\n",
        "\r\n",
        "    if len(face) != 0 :\r\n",
        "        print(i, face.shape)\r\n",
        "        # plot\r\n",
        "        pyplot.subplot(2, 7, i)\r\n",
        "        pyplot.axis('off')\r\n",
        "        pyplot.imshow(face)\r\n",
        "        i += 1\r\n",
        "    else: print('extract_face err:', i)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbaCLXOG8GaG"
      },
      "source": [
        "# face detection for the 5 Celebrity Faces Dataset\r\n",
        "from os import listdir\r\n",
        "from os.path import isdir\r\n",
        "from PIL import Image\r\n",
        "from matplotlib import pyplot\r\n",
        "from numpy import savez_compressed\r\n",
        "from numpy import asarray\r\n",
        "from mtcnn.mtcnn import MTCNN\r\n",
        "\r\n",
        "# extract a single face from a given photograph\r\n",
        "def extract_face(filename, required_size=(160, 160)):\r\n",
        "    # load image from file\r\n",
        "    image = Image.open(filename)\r\n",
        "    # convert to RGB, if needed\r\n",
        "    image = image.convert('RGB')\r\n",
        "    # convert to array\r\n",
        "    pixels = asarray(image)\r\n",
        "    # create the detector, using default weights\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect faces in the image\r\n",
        "    results = detector.detect_faces(pixels)\r\n",
        "\r\n",
        "    if len(results) == 0 :\r\n",
        "        print('------------------------------------------')\r\n",
        "        print('results:', results, ', filename:', filename)\r\n",
        "        print('------------------------------------------')\r\n",
        "        return []\r\n",
        "\r\n",
        "    # extract the bounding box from the first face\r\n",
        "    x1, y1, width, height = results[0]['box']\r\n",
        "    # bug fix\r\n",
        "    x1, y1 = abs(x1), abs(y1)\r\n",
        "    x2, y2 = x1 + width, y1 + height\r\n",
        "    # extract the face\r\n",
        "    face = pixels[y1:y2, x1:x2]\r\n",
        "    # resize pixels to the model size\r\n",
        "    image = Image.fromarray(face)\r\n",
        "    image = image.resize(required_size)\r\n",
        "    face_array = asarray(image)\r\n",
        "    return face_array\r\n",
        "\r\n",
        "# load images and extract faces for all images in a directory\r\n",
        "def load_faces(directory):\r\n",
        "    faces = list()\r\n",
        "    # enumerate files\r\n",
        "    for filename in listdir(directory):\r\n",
        "        if 'jpg' not in filename and 'jpeg' not in filename: continue\r\n",
        "\r\n",
        "        # path\r\n",
        "        path = directory + filename\r\n",
        "        # get face\r\n",
        "        face = extract_face(path)\r\n",
        "        if len(face) != 0:\r\n",
        "            # store\r\n",
        "            faces.append(face)\r\n",
        "        else: print('extract_face err')\r\n",
        "    return faces\r\n",
        "\r\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\r\n",
        "def load_dataset(directory):\r\n",
        "    X, y = list(), list()\r\n",
        "    # enumerate folders, on per class\r\n",
        "    cnt = 0\r\n",
        "    for subdir in listdir(directory):\r\n",
        "        cnt += 1\r\n",
        "        # path\r\n",
        "        path = directory + subdir + '/'\r\n",
        "        # skip any files that might be in the dir\r\n",
        "        if not isdir(path):\r\n",
        "          continue\r\n",
        "        # load all faces in the subdirectory\r\n",
        "        faces = load_faces(path)\r\n",
        "        # create labels\r\n",
        "        labels = [subdir for _ in range(len(faces))]\r\n",
        "        # summarize progress\r\n",
        "        print('>cnt:', cnt, ' ,loaded %d examples for class: %s' % (len(faces), subdir), ' ,labels:', labels)\r\n",
        "        # store\r\n",
        "        X.extend(faces)\r\n",
        "        y.extend(labels)\r\n",
        "    return asarray(X), asarray(y)\r\n",
        "\r\n",
        "import time\r\n",
        "start = time.time() # 시작 시간 저장\r\n",
        "\r\n",
        "# load train dataset\r\n",
        "trainX, trainy = load_dataset('./face_data/train/')\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "print('trainy.shape:', trainy.shape)\r\n",
        "\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfFX6Dh6sE1R"
      },
      "source": [
        "# 작업 코드\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간\r\n",
        "\r\n",
        "# load test dataset\r\n",
        "testX, testy = load_dataset('./face_data/test/')\r\n",
        "print('testX.shape:', testX.shape)\r\n",
        "print('testy.shape:', testy.shape)\r\n",
        "print(testy)\r\n",
        "\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSPrmQBbsNyT"
      },
      "source": [
        "# save arrays to one file in compressed format\r\n",
        "savez_compressed('faces-dataset.npz', trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUuZNtAXuOZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c52c91-7680-4d19-8ab0-8a4d7ca28f7e"
      },
      "source": [
        "print('trainX:', trainX.shape)\r\n",
        "print('trainy:', trainy.shape)\r\n",
        "print('testX:', testX.shape)\r\n",
        "print('testy:', testy.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX: (3292, 160, 160, 3)\n",
            "trainy: (3292,)\n",
            "testX: (941, 160, 160, 3)\n",
            "testy: (941,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9zgGRNr7Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b055ca7-1d97-4f3b-9be7-5893deed610c"
      },
      "source": [
        "# calculate a face embedding for each face in the dataset using facenet\r\n",
        "import numpy as np\r\n",
        "from numpy import load\r\n",
        "from numpy import expand_dims\r\n",
        "from numpy import asarray\r\n",
        "from numpy import savez_compressed\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "# #https://d-tail.tistory.com/31\r\n",
        "# ## 먼저 기존의 np.load를 np_load_old에 저장해둠.\r\n",
        "# np_load_old = np.load\r\n",
        "# ## 기존의 parameter을 바꿔줌\r\n",
        "# np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\r\n",
        "\r\n",
        "# get the face embedding for one face\r\n",
        "def get_embedding(model, face_pixels):\r\n",
        "    # scale pixel values\r\n",
        "    face_pixels = face_pixels.astype('float32')\r\n",
        "    # standardize pixel values across channels (global)\r\n",
        "    mean, std = face_pixels.mean(), face_pixels.std()\r\n",
        "    face_pixels = (face_pixels - mean) / std\r\n",
        "    # transform face into one sample\r\n",
        "    samples = expand_dims(face_pixels, axis=0)\r\n",
        "    # make prediction to get embedding\r\n",
        "    yhat = model.predict(samples)\r\n",
        "    return yhat[0]\r\n",
        "\r\n",
        "# load the face dataset\r\n",
        "data = load('faces-dataset.npz')\r\n",
        "#print('data:', data)\r\n",
        "#for item in data: print(data[item])\r\n",
        "\r\n",
        "print('trainX:', data['arr_0'].shape)\r\n",
        "print('trainy:', data['arr_1'].shape)\r\n",
        "print('testX:', data['arr_2'].shape)\r\n",
        "print('testy:', data['arr_3'].shape)\r\n",
        "\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX: (3292, 160, 160, 3)\n",
            "trainy: (3292,)\n",
            "testX: (941, 160, 160, 3)\n",
            "testy: (941,)\n",
            "Loaded:  (3292, 160, 160, 3) (3292,) (941, 160, 160, 3) (941,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU3R4Gogudob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57604bef-7e10-4129-d303-60b0a8cd50ce"
      },
      "source": [
        "# load the facenet model\r\n",
        "facenet_model = load_model('./facenet_keras.h5')\r\n",
        "print('Loaded Model')\r\n",
        "\r\n",
        "# convert each face in the train set to an embedding\r\n",
        "newTrainX = list()\r\n",
        "for face_pixels in trainX:\r\n",
        "    embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "    newTrainX.append(embedding)\r\n",
        "newTrainX = asarray(newTrainX)\r\n",
        "print(newTrainX.shape)\r\n",
        "\r\n",
        "# convert each face in the test set to an embedding\r\n",
        "newTestX = list()\r\n",
        "for idx, face_pixels in enumerate(testX):\r\n",
        "    if len(face_pixels)==0: \r\n",
        "        print('idx:', idx)\r\n",
        "        continue\r\n",
        "    embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "    newTestX.append(embedding)\r\n",
        "newTestX = asarray(newTestX)\r\n",
        "print(newTestX.shape)\r\n",
        "\r\n",
        "# save arrays to one file in compressed format\r\n",
        "savez_compressed('faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Model\n",
            "(3292, 128)\n",
            "(941, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqjvUav-r7NP"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\r\n",
        "from numpy import load\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.svm import SVC\r\n",
        "# load dataset\r\n",
        "data = load('faces-embeddings.npz')\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\r\n",
        "\r\n",
        "# normalize input vectors\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "print('trainX.shape:',trainX.shape)\r\n",
        "print('trainX[0].shape:',trainX[0].shape)\r\n",
        "trainX = in_encoder.transform(trainX)\r\n",
        "testX = in_encoder.transform(testX)\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "print('testX.shape:', testX.shape)\r\n",
        "\r\n",
        "# label encode targets\r\n",
        "out_encoder = LabelEncoder()\r\n",
        "out_encoder.fit(trainy)\r\n",
        "trainy = out_encoder.transform(trainy)\r\n",
        "testy = out_encoder.transform(testy)\r\n",
        "print('trainy.shape:', trainy.shape)\r\n",
        "print('testy.shape:', testy.shape)\r\n",
        "\r\n",
        "print('testX:', testX)\r\n",
        "print('testy:', testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEof2wzuyN1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed45905-a0ec-415b-b484-01cd34715b1e"
      },
      "source": [
        "# fit model\r\n",
        "pred_model = SVC(kernel='linear', probability=True)\r\n",
        "pred_model.fit(trainX, trainy)\r\n",
        "\r\n",
        "# predict\r\n",
        "yhat_train = pred_model.predict(trainX)\r\n",
        "yhat_test = pred_model.predict(testX)\r\n",
        "\r\n",
        "# score\r\n",
        "score_train = accuracy_score(trainy, yhat_train)\r\n",
        "score_test = accuracy_score(testy, yhat_test)\r\n",
        "# summarize\r\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: train=99.939, test=99.894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5anMjX66vgRC"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\r\n",
        "from random import choice\r\n",
        "from numpy import load\r\n",
        "from numpy import expand_dims\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.svm import SVC\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# load faces\r\n",
        "data = load('faces-dataset.npz')\r\n",
        "testX_faces = data['arr_2']\r\n",
        "\r\n",
        "# load face embeddings\r\n",
        "data = load('faces-embeddings.npz')\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "\r\n",
        "# normalize input vectors\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "trainX = in_encoder.transform(trainX)\r\n",
        "testX = in_encoder.transform(testX)\r\n",
        "\r\n",
        "# label encode targets\r\n",
        "out_encoder = LabelEncoder()\r\n",
        "out_encoder.fit(trainy)\r\n",
        "trainy = out_encoder.transform(trainy)\r\n",
        "testy = out_encoder.transform(testy)\r\n",
        "\r\n",
        "# fit model\r\n",
        "pred_model = SVC(kernel='linear', probability=True)\r\n",
        "pred_model.fit(trainX, trainy)\r\n",
        "\r\n",
        "# test model on a random example from the test dataset\r\n",
        "selection = choice([i for i in range(testX.shape[0])])\r\n",
        "random_face_pixels = testX_faces[selection]\r\n",
        "random_face_emb = testX[selection]\r\n",
        "random_face_class = testy[selection]\r\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\r\n",
        "\r\n",
        "# prediction for the face\r\n",
        "samples = expand_dims(random_face_emb, axis=0)\r\n",
        "yhat_class = pred_model.predict(samples)\r\n",
        "yhat_prob = pred_model.predict_proba(samples)\r\n",
        "\r\n",
        "# get name\r\n",
        "class_index = yhat_class[0]\r\n",
        "class_probability = yhat_prob[0,class_index] * 100\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\r\n",
        "print('Expected: %s' % random_face_name[0])\r\n",
        "\r\n",
        "# plot for fun\r\n",
        "pyplot.imshow(random_face_pixels)\r\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\r\n",
        "pyplot.title(title)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjbWzkSiA1h8"
      },
      "source": [
        "path=\"./webcam3.jpg\"\r\n",
        "face_pixels = extract_face(path)\r\n",
        "print('face:', face_pixels.shape)\r\n",
        "\r\n",
        "embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "print('embedding:', embedding.shape)\r\n",
        "\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "#dataX = in_encoder.transform(np.array([embedding]))\r\n",
        "dataX = in_encoder.transform([embedding])\r\n",
        "print('dataX:', dataX.shape)\r\n",
        "\r\n",
        "# # test model on a random example from the test dataset\r\n",
        "# selection = choice([i for i in range(testX.shape[0])])\r\n",
        "# random_face_pixels = testX_faces[selection]\r\n",
        "# random_face_emb = testX[selection]\r\n",
        "# random_face_class = testy[selection]\r\n",
        "# random_face_name = out_encoder.inverse_transform([random_face_class])\r\n",
        "\r\n",
        "# prediction for the face\r\n",
        "#dataX = expand_dims(dataX, axis=0)\r\n",
        "#print('dataX:', dataX.shape)\r\n",
        "yhat_class = pred_model.predict(dataX)\r\n",
        "yhat_prob = pred_model.predict_proba(dataX)\r\n",
        "\r\n",
        "# get name\r\n",
        "class_index = yhat_class[0]\r\n",
        "class_probability = yhat_prob[0,class_index] * 100\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\r\n",
        "# print('Expected: %s' % random_face_name[0])\r\n",
        "\r\n",
        "# plot for fun\r\n",
        "pyplot.imshow(face_pixels)\r\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\r\n",
        "pyplot.title(title)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8LNiPcYANEX"
      },
      "source": [
        "import joblib\r\n",
        "\r\n",
        "joblib.dump(out_encoder, 'label_out_encoder.joblib')\r\n",
        "out_encoder = joblib.load('label_out_encoder.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6eEXEDXJ-T",
        "outputId": "68aed0be-3ae4-4abd-e417-27e8562831bd"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\r\n",
        "from random import choice\r\n",
        "from numpy import load\r\n",
        "from numpy import expand_dims\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# load faces\r\n",
        "data = load('faces-dataset.npz')\r\n",
        "testX_faces = data['arr_2']\r\n",
        "\r\n",
        "# load face embeddings\r\n",
        "data = load('faces-embeddings.npz')\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "\r\n",
        "# normalize input vectors\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "trainX = in_encoder.transform(trainX)\r\n",
        "testX = in_encoder.transform(testX)\r\n",
        "\r\n",
        "# label encode targets\r\n",
        "out_encoder = LabelEncoder()\r\n",
        "out_encoder.fit(trainy)\r\n",
        "trainy = out_encoder.transform(trainy)\r\n",
        "testy = out_encoder.transform(testy)\r\n",
        "\r\n",
        "def get_random_sample():      \r\n",
        "    # test model on a random example from the test dataset\r\n",
        "    selection = choice([i for i in range(testX.shape[0])])\r\n",
        "    random_face_pixels = testX_faces[selection]\r\n",
        "    random_face_emb = testX[selection]\r\n",
        "    random_face_class = testy[selection]\r\n",
        "    random_face_name = out_encoder.inverse_transform([random_face_class])\r\n",
        "    print('selection:',selection, ' ,random_face_class:', random_face_class, ' ,Expected: %s' % random_face_name[0])\r\n",
        "    print()\r\n",
        "    random_face_emb = expand_dims(random_face_emb, axis=0)\r\n",
        "    print('random_face_emb.shape:', random_face_emb.shape)\r\n",
        "\r\n",
        "    return random_face_emb, random_face_pixels\r\n",
        "\r\n",
        "def pred_result(random_face_emb, random_face_pixels):  \r\n",
        "    # prediction for the face\r\n",
        "    yhat_class = pred_model.predict(random_face_emb)\r\n",
        "    print('samples.shape:', samples.shape, ' ,yhat_class.shape:', yhat_class.shape)\r\n",
        "\r\n",
        "    class_index = yhat_class[0]\r\n",
        "    class_probability = yhat_prob[0,class_index] * 100\r\n",
        "    predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "    print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\r\n",
        "    # print('Expected: %s' % random_face_name[0])\r\n",
        "    \r\n",
        "    # prediction_max_idx = np.argmax(yhat_class[0], axis=-1)\r\n",
        "    # predict_names = out_encoder.inverse_transform(prediction_max_idx)\r\n",
        "    # max_percentage = np.max(yhat_class)\r\n",
        "    # print('prediction_max_idx:',prediction_max_idx,' ,predict_names:',predict_names, ' ,max_percentage:', max_percentage)\r\n",
        "    # print()\r\n",
        "\r\n",
        "    # plot for fun\r\n",
        "    pyplot.imshow(random_face_pixels)\r\n",
        "    title = '%s (%.3f)' % (predict_names[0], class_probability)\r\n",
        "    pyplot.title(title)\r\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX.shape: (3292, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeIscy4nXKAl"
      },
      "source": [
        "random_face_emb, random_face_pixels = get_random_sample()\r\n",
        "pred_result(random_face_emb, random_face_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-24QxQXdTM"
      },
      "source": [
        "path=\"./webcam3.jpg\"\r\n",
        "face_pixels = extract_face(path)\r\n",
        "print('face:', face_pixels.shape)\r\n",
        "\r\n",
        "embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "print('embedding:', embedding.shape)\r\n",
        "print('embedding[0]:', embedding[0])\r\n",
        "\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "#dataX = in_encoder.transform(np.array([embedding]))\r\n",
        "dataX = in_encoder.transform([embedding]) # https://2-chae.github.io/category/1.ai/31\r\n",
        "print('dataX:', dataX.shape)\r\n",
        "print('dataX[0]:', dataX[0][0])\r\n",
        "print()\r\n",
        "\r\n",
        "random_face_emb = expand_dims(dataX[0], axis=0) #https://js.tensorflow.org/api/latest/ > tf.expandDims\r\n",
        "print('random_face_emb:', random_face_emb.shape)\r\n",
        "print('random_face_emb[0]:', random_face_emb[0][0])\r\n",
        "\r\n",
        "pred_result(random_face_emb, face_pixels)\r\n",
        "\r\n",
        "#pred_result(dataX[0], face_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAsK5DW5XdWm"
      },
      "source": [
        "#https://gaussian37.github.io/ml-sklearn-saving-model/\r\n",
        "from sklearn.externals import joblib\r\n",
        "import pickle\r\n",
        "\r\n",
        "saved_model = pickle.dumps(pred_model) #, 'pred_model.pickle'\r\n",
        "\r\n",
        "clf_from_pickle = pickle.loads(saved_model)\r\n",
        "yhat_class = clf_from_pickle.predict(dataX)\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('predict_names:', predict_names)\r\n",
        "\r\n",
        "joblib.dump(pred_model, 'pred_sklearn_model.pkl') \r\n",
        "clf_from_joblib = joblib.load('pred_sklearn_model.pkl') \r\n",
        "yhat_class = clf_from_pickle.predict(dataX)\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('predict_names:', predict_names)\r\n",
        "\r\n",
        "# out_encoder도 다운로드!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}