{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06_keras_FaceNet_sample_20210105.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPHM1-dJ7-4q"
      },
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQHEIgdTM80",
        "outputId": "5ae85437-fd63-4fa0-f5df-e25193388256"
      },
      "source": [
        "# python/tensorflow 워닝 막기\r\n",
        "import warnings , os\r\n",
        "#warnings.filterwarnings(action='ignore')\r\n",
        "warnings.filterwarnings(action='once')\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \r\n",
        "import tensorflow as tf\r\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUTGOVZmqinW"
      },
      "source": [
        "# # # https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-17%EC%9D%BC%EC%B0%A8-%EB%A1%9C%EC%9D%B4%ED%84%B0-%EB%89%B4%EC%8A%A4-%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0-f5466abe9196\r\n",
        "# # np.load()에서 import_pickle=False오류 날경우, 최초실행시 한번 설치해, 주석처리하고 재실행하면 downgrade로 적용됨\r\n",
        "# !pip uninstall numpy\r\n",
        "# !pip install --upgrade numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfXNEM5mrF_l",
        "outputId": "d9f5ff26-45da-4617-98cc-108b682d0add"
      },
      "source": [
        "import numpy as np\r\n",
        "print(np.__version__) #'1.16.1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.16.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHP91hX8pITS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ef0eb2-df30-43fa-a11d-5f4b9e4d12fb"
      },
      "source": [
        "###########################\r\n",
        "# google drive 저장/로딩\r\n",
        "###########################\r\n",
        "#구글 드라이브 저장\r\n",
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "gcp_drive = None\r\n",
        "def doGoodleDriveAuth():\r\n",
        "    # 1. Authenticate and create the PyDrive client.\r\n",
        "    auth.authenticate_user()\r\n",
        "    gauth = GoogleAuth()\r\n",
        "    print('gauth:',gauth)\r\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "\r\n",
        "    gcp_drive = GoogleDrive(gauth)\r\n",
        "    print('gcp_drive:', gcp_drive)\r\n",
        "    return gcp_drive\r\n",
        "\r\n",
        "# PyDrive reference:\r\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\r\n",
        "def gcp_upload(file_path, w_file_name):\r\n",
        "    try:\r\n",
        "        if gcp_drive == None:\r\n",
        "            drive = doGoodleDriveAuth()\r\n",
        "\r\n",
        "        # 특정 폴더 안으로 파일 삽입\r\n",
        "        uploaded = drive.CreateFile({'title': w_file_name}) #, \"parents\": [{\"kind\": \"drive#fileLink\",\"id\": 'jukyellow@gmail.com'}]})\r\n",
        "        uploaded.SetContentString(w_file_name)\r\n",
        "        uploaded.SetContentFile(file_path + w_file_name)\r\n",
        "        uploaded.Upload()\r\n",
        "        print('Uploaded file with ID {}'.format(uploaded.get('id')))\r\n",
        "        return uploaded.get('id')\r\n",
        "    except Exception as e: print('gcp_upload err:', e)\r\n",
        "\r\n",
        "#구글 드라이브에서 다운로드\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from googleapiclient.discovery import build\r\n",
        "drive_service = build('drive', 'v3')\r\n",
        "import io\r\n",
        "from io import BytesIO \r\n",
        "from googleapiclient.http import MediaIoBaseDownload\r\n",
        "\r\n",
        "TEMP_PATH = '/tmp/'\r\n",
        "def gcp_download(file_name, key):\r\n",
        "    #3. 모델 다운로드\r\n",
        "    #https://drive.google.com/open?id=1TlvbayGRCjAI6bOZrUYMmv6g6b95rnRM\r\n",
        "    request = drive_service.files().get_media(fileId=key)\r\n",
        "\r\n",
        "    downloaded = io.BytesIO()\r\n",
        "    downloader = MediaIoBaseDownload(downloaded, request)\r\n",
        "    done = False\r\n",
        "    while done is False:\r\n",
        "      status, done = downloader.next_chunk()\r\n",
        "      if status:\r\n",
        "          print(\"Download %%%d%%.\" % int(status.progress() * 100))\r\n",
        "      print(\"Download Complete!\")\r\n",
        "    downloaded.seek(0)\r\n",
        "\r\n",
        "    with open(TEMP_PATH + file_name, 'wb') as f:\r\n",
        "        f.write(downloaded.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google/colab/auth.py:148: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 42174), raddr=('172.217.13.74', 443)>\n",
            "  if not _check_adc():\n",
            "/usr/local/lib/python3.6/dist-packages/google/colab/auth.py:169: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 42176), raddr=('172.217.13.74', 443)>\n",
            "  if _check_adc():\n",
            "/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py:134: ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('172.28.0.2', 35236), raddr=('172.217.9.202', 443)>\n",
            "  return wrapped(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYrTxvCnpIaP",
        "outputId": "72f06cb7-4fc4-4498-8eb1-239d2cd67b30"
      },
      "source": [
        "# https://drive.google.com/file/d/1_Hj9zu0lYUoeL0d1AqPGZa78OxNrpER2/view?usp=sharing\r\n",
        "# gcp에서 폴더명 사진 다운로드, 압축풀기\r\n",
        "down_file_name = 'facenet_keras.h5'\r\n",
        "gcp_download(down_file_name, '1_Hj9zu0lYUoeL0d1AqPGZa78OxNrpER2') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download %100%.\n",
            "Download Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-SAXUVCqYD_"
      },
      "source": [
        "!mv /tmp/facenet_keras.h5 /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dok51GcsqIr6",
        "outputId": "1f920950-7a9b-40b7-ddc7-00f5b6a1e729"
      },
      "source": [
        "# gcp에서 폴더명 사진 다운로드, 압축풀기\r\n",
        "down_file_name = '00_origin_전체.zip'\r\n",
        "gcp_download(down_file_name, '1k0lm-uBfxlUbqtzvZ4xjVa_ojS0fPFUG')  #https://drive.google.com/file/d/1k0lm-uBfxlUbqtzvZ4xjVa_ojS0fPFUG/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download %100%.\n",
            "Download Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IFufKgcwS4_"
      },
      "source": [
        "!\\rm -rf /content/origin_data\r\n",
        "!\\rm -rf /content/face_data\r\n",
        "\r\n",
        "!mkdir /content/origin_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "063fiJrTqUTf"
      },
      "source": [
        "# 한글깨짐 방지: -O cp949 \r\n",
        "!unzip -O cp949 /tmp/00_origin_전체.zip\r\n",
        "!rm -rf /tmp/00_origin_전체.zip\r\n",
        "\r\n",
        "!mv /content/00_전체 /content/origin_data\r\n",
        "\r\n",
        "!mkdir /content/face_data\r\n",
        "!mkdir /content/face_data/train\r\n",
        "!mkdir /content/face_data/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCeZDod9Tqxs"
      },
      "source": [
        "# 원본경로 파일목록 읽기\r\n",
        "import os\r\n",
        "\r\n",
        "path = '/content/origin_data/00_전체'\r\n",
        "imgFileList = os.listdir(path)\r\n",
        "\r\n",
        "imgFileList = [x for x in imgFileList if 'jpg' in x or 'jpeg' in x] # jpg파일만 불러오기\r\n",
        "\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "  print('i:',i+1 , ' ,name:', file_name)\r\n",
        "  #if i > 1 : break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yFSaZcStsQ"
      },
      "source": [
        "# preview 이미지 생성 메소드 \r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "\r\n",
        "def save_img_by_img_gen(path, file_name, MAX_GEN_CNT, save_path, new_dir, gen_type):\r\n",
        "    if \"train\" == gen_type:\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            rotation_range=10,\r\n",
        "            width_shift_range=0.1,\r\n",
        "            height_shift_range=0.1,\r\n",
        "            #rescale=1./255, predict시에는 이미지 스케일 작업없어서 제외\r\n",
        "            shear_range=0.1,\r\n",
        "            zoom_range=0.1, #확대/축소 비율\r\n",
        "            brightness_range= [0.1, 1.0], # 밝기 비율\r\n",
        "            channel_shift_range=80, # rgb 채널 랜덤 섞기(명암 어둡게 변함)\r\n",
        "            horizontal_flip=True,  #가로 대칭 전환\r\n",
        "            cval = 255, # constant일때 여백 흰색\r\n",
        "            fill_mode='constant') #nearest constant\r\n",
        "    else:\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            rotation_range=20,\r\n",
        "            width_shift_range=0.1,\r\n",
        "            height_shift_range=0.1,\r\n",
        "            #rescale=1./255, predict시에는 이미지 스케일 작업없어서 제외\r\n",
        "            shear_range=0.2,\r\n",
        "            zoom_range=0.2, #확대/축소 비율\r\n",
        "            brightness_range= [0.1, 1.0], # 밝기 비율\r\n",
        "            channel_shift_range=80, # rgb 채널 랜덤 섞기(명암 어둡게 변함)\r\n",
        "            horizontal_flip=True,  #가로 대칭 전환\r\n",
        "            cval = 255, # constant일때 여백 흰색\r\n",
        "            fill_mode='constant') #nearest constant\r\n",
        "\r\n",
        "    img = load_img(path+\"/\"+file_name)  # PIL 이미지\r\n",
        "    x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\r\n",
        "    x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\r\n",
        "    print('x.shape:', x.shape)\r\n",
        "\r\n",
        "    #파일명별 폴더 생성\r\n",
        "    file_name = file_name.replace(\".jpg\",\"\")\r\n",
        "    new_path = new_dir + file_name\r\n",
        "    if not(os.path.isdir(new_path)): os.makedirs(os.path.join(new_path))\r\n",
        "\r\n",
        "    # 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서, save_to_dir저장\r\n",
        "    i = 0\r\n",
        "    for batch in datagen.flow(x, batch_size=1, save_to_dir=save_path+file_name, save_prefix=file_name, save_format='jpg'):\r\n",
        "        i += 1\r\n",
        "        if i > MAX_GEN_CNT: break \r\n",
        "\r\n",
        "# 이미지 변환 파일 생성\r\n",
        "MAX_GEN_CNT = 20\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "    save_img_by_img_gen(path, file_name, MAX_GEN_CNT, 'face_data/train/', '/content/face_data/train/', 'train')\r\n",
        "    print('i:',i+1 , ' ,name:', file_name + \" 변형 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HUNHOeEjwLZ"
      },
      "source": [
        "# 이미지 변환 파일 생성\r\n",
        "MAX_GEN_CNT = 10\r\n",
        "for i, file_name in enumerate(imgFileList):\r\n",
        "    save_img_by_img_gen(path, file_name, MAX_GEN_CNT, 'face_data/test/', '/content/face_data/test/', 'test')\r\n",
        "    print('i:',i+1 , ' ,name:', file_name + \" 변형 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHAwr_l_8GPv",
        "outputId": "32b05d37-3e5f-487e-9c91-4ac546ce283b"
      },
      "source": [
        "# example of loading the keras facenet model\r\n",
        "from keras.models import load_model\r\n",
        "# load the model\r\n",
        "facenet_model = load_model('facenet_keras.h5')\r\n",
        "# summarize input and output shape\r\n",
        "print(facenet_model.inputs)\r\n",
        "print(facenet_model.outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
            "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgCLdxxs8GSG",
        "outputId": "e35b2167-0e9a-46d9-92c4-622a279d7fe4"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.16.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLrgdv0L8GUY",
        "outputId": "db3d5816-9cc7-41a3-8ec6-4cf7fdf4d570"
      },
      "source": [
        "# confirm mtcnn was installed correctly\r\n",
        "import mtcnn\r\n",
        "# print version\r\n",
        "print(mtcnn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKdRFW23rWsh",
        "outputId": "5c739c09-70b2-4e64-8daf-17c755e47d6d"
      },
      "source": [
        "ls -alrt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 91180\n",
            "drwxr-xr-x 1 root root     4096 Dec 21 17:29 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 06:26 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 06:38 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root      720 Jan  6 06:38 adc.json\n",
            "-rw-r--r-- 1 root root   456511 Jan  6 06:54 faces-embeddings.npz\n",
            "-rw-r--r-- 1 root root   456809 Jan  6 07:04 faces-dataset.npz\n",
            "-rw-r--r-- 1 root root     8491 Jan  6 07:05 web_cam_capture_1.jpg\n",
            "-rw-r--r-- 1 root root 92397640 Jan  6 07:12 facenet_keras.h5\n",
            "drwxr-xr-x 3 root root     4096 Jan  6 07:13 \u001b[01;34morigin_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 07:13 \u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 4 root root     4096 Jan  6 07:13 \u001b[01;34mface_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UNLqXLw8GXV"
      },
      "source": [
        "# demonstrate face detection on 5 Celebrity Faces Dataset\r\n",
        "from os import listdir\r\n",
        "from PIL import Image\r\n",
        "from numpy import asarray\r\n",
        "from matplotlib import pyplot\r\n",
        "from mtcnn.mtcnn import MTCNN\r\n",
        " \r\n",
        "# extract a single face from a given photograph\r\n",
        "def extract_face(filename, required_size=(160, 160)):\r\n",
        "    # load image from file\r\n",
        "    image = Image.open(filename)\r\n",
        "    # convert to RGB, if needed\r\n",
        "    image = image.convert('RGB')\r\n",
        "    # convert to array\r\n",
        "    pixels = asarray(image)\r\n",
        "    # create the detector, using default weights\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect faces in the image\r\n",
        "    results = detector.detect_faces(pixels)\r\n",
        "    if len(results) == 0 :\r\n",
        "        print('------------------------------------------')\r\n",
        "        print('results:', results, ', filename:', filename)\r\n",
        "        print('------------------------------------------')\r\n",
        "        return []\r\n",
        "\r\n",
        "    # extract the bounding box from the first face\r\n",
        "    x1, y1, width, height = results[0]['box']\r\n",
        "    # bug fix\r\n",
        "    x1, y1 = abs(x1), abs(y1)\r\n",
        "    x2, y2 = x1 + width, y1 + height\r\n",
        "    # extract the face\r\n",
        "    face = pixels[y1:y2, x1:x2]\r\n",
        "    # resize pixels to the model size\r\n",
        "    image = Image.fromarray(face)\r\n",
        "    image = image.resize(required_size)\r\n",
        "    face_array = asarray(image)\r\n",
        "    return face_array\r\n",
        " \r\n",
        "# specify folder to plot\r\n",
        "folder = './face_data/test/B05_OOO/'\r\n",
        "i = 1\r\n",
        "# enumerate files\r\n",
        "for filename in listdir(folder):\r\n",
        "    if 'jpg' not in filename and 'jpeg' not in filename: continue\r\n",
        "    # path\r\n",
        "    path = folder + filename\r\n",
        "    # get face\r\n",
        "    face = extract_face(path)\r\n",
        "\r\n",
        "    if len(face) != 0 :\r\n",
        "        print(i, face.shape)\r\n",
        "        # plot\r\n",
        "        pyplot.subplot(2, 7, i)\r\n",
        "        pyplot.axis('off')\r\n",
        "        pyplot.imshow(face)\r\n",
        "        i += 1\r\n",
        "    else: print('extract_face err:', i)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbaCLXOG8GaG"
      },
      "source": [
        "# face detection for the 5 Celebrity Faces Dataset\r\n",
        "from os import listdir\r\n",
        "from os.path import isdir\r\n",
        "from PIL import Image\r\n",
        "from matplotlib import pyplot\r\n",
        "from numpy import savez_compressed\r\n",
        "from numpy import asarray\r\n",
        "from mtcnn.mtcnn import MTCNN\r\n",
        "\r\n",
        "# extract a single face from a given photograph\r\n",
        "def extract_face(filename, required_size=(160, 160)):\r\n",
        "    # load image from file\r\n",
        "    image = Image.open(filename)\r\n",
        "    # convert to RGB, if needed\r\n",
        "    image = image.convert('RGB')\r\n",
        "    # convert to array\r\n",
        "    pixels = asarray(image)\r\n",
        "    # create the detector, using default weights\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect faces in the image\r\n",
        "    results = detector.detect_faces(pixels)\r\n",
        "\r\n",
        "    if len(results) == 0 :\r\n",
        "        print('------------------------------------------')\r\n",
        "        print('results:', results, ', filename:', filename)\r\n",
        "        print('------------------------------------------')\r\n",
        "        return []\r\n",
        "\r\n",
        "    # extract the bounding box from the first face\r\n",
        "    x1, y1, width, height = results[0]['box']\r\n",
        "    # bug fix\r\n",
        "    x1, y1 = abs(x1), abs(y1)\r\n",
        "    x2, y2 = x1 + width, y1 + height\r\n",
        "    # extract the face\r\n",
        "    face = pixels[y1:y2, x1:x2]\r\n",
        "    # resize pixels to the model size\r\n",
        "    image = Image.fromarray(face)\r\n",
        "    image = image.resize(required_size)\r\n",
        "    face_array = asarray(image)\r\n",
        "    return face_array\r\n",
        "\r\n",
        "# load images and extract faces for all images in a directory\r\n",
        "def load_faces(directory):\r\n",
        "    faces = list()\r\n",
        "    # enumerate files\r\n",
        "    for filename in listdir(directory):\r\n",
        "        if 'jpg' not in filename and 'jpeg' not in filename: continue\r\n",
        "\r\n",
        "        # path\r\n",
        "        path = directory + filename\r\n",
        "        # get face\r\n",
        "        face = extract_face(path)\r\n",
        "        if len(face) != 0:\r\n",
        "            # store\r\n",
        "            faces.append(face)\r\n",
        "        else: print('extract_face err')\r\n",
        "    return faces\r\n",
        "\r\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\r\n",
        "def load_dataset(directory):\r\n",
        "    X, y = list(), list()\r\n",
        "    # enumerate folders, on per class\r\n",
        "    cnt = 0\r\n",
        "    for subdir in listdir(directory):\r\n",
        "        cnt += 1\r\n",
        "        # path\r\n",
        "        path = directory + subdir + '/'\r\n",
        "        # skip any files that might be in the dir\r\n",
        "        if not isdir(path):\r\n",
        "          continue\r\n",
        "        # load all faces in the subdirectory\r\n",
        "        faces = load_faces(path)\r\n",
        "        # create labels\r\n",
        "        labels = [subdir for _ in range(len(faces))]\r\n",
        "        # summarize progress\r\n",
        "        print('>cnt:', cnt, ' ,loaded %d examples for class: %s' % (len(faces), subdir), ' ,labels:', labels)\r\n",
        "        # store\r\n",
        "        X.extend(faces)\r\n",
        "        y.extend(labels)\r\n",
        "    return asarray(X), asarray(y)\r\n",
        "\r\n",
        "import time\r\n",
        "start = time.time() # 시작 시간 저장\r\n",
        "\r\n",
        "# load train dataset\r\n",
        "trainX, trainy = load_dataset('./face_data/train/')\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "print('trainy.shape:', trainy.shape)\r\n",
        "\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfFX6Dh6sE1R"
      },
      "source": [
        "# 작업 코드\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간\r\n",
        "\r\n",
        "# load test dataset\r\n",
        "testX, testy = load_dataset('./face_data/test/')\r\n",
        "print('testX.shape:', testX.shape)\r\n",
        "print('testy.shape:', testy.shape)\r\n",
        "print(testy)\r\n",
        "\r\n",
        "print(\"time :\", time.time() - start) # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSPrmQBbsNyT"
      },
      "source": [
        "# save arrays to one file in compressed format\r\n",
        "savez_compressed('faces-dataset.npz', trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-VKyomuD5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ce2a34-ac73-4135-ae4c-18038074897b"
      },
      "source": [
        "ls -alrt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 147252\n",
            "drwxr-xr-x 1 root root     4096 Dec 21 17:29 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 06:26 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 06:38 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root      720 Jan  6 06:38 adc.json\n",
            "-rw-r--r-- 1 root root   456511 Jan  6 06:54 faces-embeddings.npz\n",
            "-rw-r--r-- 1 root root     8491 Jan  6 07:05 web_cam_capture_1.jpg\n",
            "-rw-r--r-- 1 root root 92397640 Jan  6 07:12 facenet_keras.h5\n",
            "drwxr-xr-x 3 root root     4096 Jan  6 07:13 \u001b[01;34morigin_data\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Jan  6 07:13 \u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 4 root root     4096 Jan  6 07:13 \u001b[01;34mface_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 57874962 Jan  6 07:27 faces-dataset.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUuZNtAXuOZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737bec02-6e5a-45d8-9940-16eaba8d5c50"
      },
      "source": [
        "print('trainX:', trainX.shape)\r\n",
        "print('trainy:', trainy.shape)\r\n",
        "print('testX:', testX.shape)\r\n",
        "print('testy:', testy.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX: (630, 160, 160, 3)\n",
            "trainy: (630,)\n",
            "testX: (328, 160, 160, 3)\n",
            "testy: (328,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9zgGRNr7Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea50c04-8b32-4de9-b3ee-475864e0539a"
      },
      "source": [
        "# calculate a face embedding for each face in the dataset using facenet\r\n",
        "import numpy as np\r\n",
        "from numpy import load\r\n",
        "from numpy import expand_dims\r\n",
        "from numpy import asarray\r\n",
        "from numpy import savez_compressed\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "# #https://d-tail.tistory.com/31\r\n",
        "# ## 먼저 기존의 np.load를 np_load_old에 저장해둠.\r\n",
        "# np_load_old = np.load\r\n",
        "# ## 기존의 parameter을 바꿔줌\r\n",
        "# np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\r\n",
        "\r\n",
        "# get the face embedding for one face\r\n",
        "def get_embedding(model, face_pixels):\r\n",
        "    # scale pixel values\r\n",
        "    face_pixels = face_pixels.astype('float32')\r\n",
        "    # standardize pixel values across channels (global)\r\n",
        "    mean, std = face_pixels.mean(), face_pixels.std()\r\n",
        "    face_pixels = (face_pixels - mean) / std\r\n",
        "    # transform face into one sample\r\n",
        "    samples = expand_dims(face_pixels, axis=0)\r\n",
        "    # make prediction to get embedding\r\n",
        "    yhat = model.predict(samples)\r\n",
        "    return yhat[0]\r\n",
        "\r\n",
        "# load the face dataset\r\n",
        "data = load('faces-dataset.npz')\r\n",
        "#print('data:', data)\r\n",
        "#for item in data: print(data[item])\r\n",
        "\r\n",
        "print('trainX:', data['arr_0'].shape)\r\n",
        "print('trainy:', data['arr_1'].shape)\r\n",
        "print('testX:', data['arr_2'].shape)\r\n",
        "print('testy:', data['arr_3'].shape)\r\n",
        "\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX: (630, 160, 160, 3)\n",
            "trainy: (630,)\n",
            "testX: (328, 160, 160, 3)\n",
            "testy: (328,)\n",
            "Loaded:  (630, 160, 160, 3) (630,) (328, 160, 160, 3) (328,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU3R4Gogudob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3432bf17-5f89-4865-c52d-313af69796e2"
      },
      "source": [
        "# load the facenet model\r\n",
        "facenet_model = load_model('./facenet_keras.h5')\r\n",
        "print('Loaded Model')\r\n",
        "\r\n",
        "# convert each face in the train set to an embedding\r\n",
        "newTrainX = list()\r\n",
        "for face_pixels in trainX:\r\n",
        "    embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "    newTrainX.append(embedding)\r\n",
        "newTrainX = asarray(newTrainX)\r\n",
        "print(newTrainX.shape)\r\n",
        "\r\n",
        "# convert each face in the test set to an embedding\r\n",
        "newTestX = list()\r\n",
        "for idx, face_pixels in enumerate(testX):\r\n",
        "    if len(face_pixels)==0: \r\n",
        "        print('idx:', idx)\r\n",
        "        continue\r\n",
        "    embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "    newTestX.append(embedding)\r\n",
        "newTestX = asarray(newTestX)\r\n",
        "print(newTestX.shape)\r\n",
        "\r\n",
        "# save arrays to one file in compressed format\r\n",
        "savez_compressed('faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Model\n",
            "(630, 128)\n",
            "(328, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqjvUav-r7NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1245133d-9ce1-44cb-cba4-32dbc461eae1"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\r\n",
        "from numpy import load\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.svm import SVC\r\n",
        "# load dataset\r\n",
        "data = load('faces-embeddings.npz')\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\r\n",
        "\r\n",
        "# normalize input vectors\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "print('trainX.shape:',trainX.shape)\r\n",
        "print('trainX[0].shape:',trainX[0].shape)\r\n",
        "trainX = in_encoder.transform(trainX)\r\n",
        "testX = in_encoder.transform(testX)\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "print('testX.shape:', testX.shape)\r\n",
        "\r\n",
        "# label encode targets\r\n",
        "out_encoder = LabelEncoder()\r\n",
        "out_encoder.fit(trainy)\r\n",
        "trainy = out_encoder.transform(trainy)\r\n",
        "testy = out_encoder.transform(testy)\r\n",
        "print('trainy.shape:', trainy.shape)\r\n",
        "print('testy.shape:', testy.shape)\r\n",
        "\r\n",
        "print('testX:', testX)\r\n",
        "print('testy:', testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: train=630, test=328\n",
            "trainX.shape: (630, 128)\n",
            "trainX[0].shape: (128,)\n",
            "trainX.shape: (630, 128)\n",
            "testX.shape: (328, 128)\n",
            "trainy.shape: (630,)\n",
            "testy.shape: (328,)\n",
            "testX: [[ 0.06719897 -0.00746293 -0.07132015 ... -0.10519774  0.03399387\n",
            "  -0.04146887]\n",
            " [ 0.11998394 -0.06810085 -0.08123402 ... -0.09245402 -0.0454261\n",
            "  -0.05718428]\n",
            " [ 0.05698761  0.02405528 -0.10154805 ... -0.0466873   0.10299142\n",
            "  -0.02957636]\n",
            " ...\n",
            " [ 0.06540772 -0.08778912 -0.01173866 ... -0.18333246 -0.02484478\n",
            "  -0.04982429]\n",
            " [ 0.06045805 -0.11666107  0.0163904  ... -0.15685587  0.00355646\n",
            "  -0.0986824 ]\n",
            " [ 0.10205339 -0.09236851 -0.07657373 ... -0.17265351 -0.05783626\n",
            "  -0.05999085]]\n",
            "testy: [13 13 13 13 13 13 13 13 13 13 19 19 19 19 19 19 19 19 19 19 19 25 25 25\n",
            " 25 25 25 25 25 25 25 25 23 23 23 23 23 23 23 23 23 23 23 21 21 21 21 21\n",
            " 21 21 21 21 21 21  2  2  2  2  2  2  2  2  2  2  2 22 22 22 22 22 22 22\n",
            " 22 22 22 22 11 11 11 11 11 11 11 11 11 11 11  0  0  0  0  0  0  0  0  0\n",
            "  0  0 24 24 24 24 24 24 24 24 24 24 24  1  1  1  1  1  1  1  1  1  1  1\n",
            " 28 28 28 28 28 28 28 28 28 28 28 16 16 16 16 16 16 16 16 16 16 16  7  7\n",
            "  7  7  7  7  7  7  7  7  7  4  4  4  4  4  4  4  4  4  4  4 29 29 29 29\n",
            " 29 29 29 29 29 29 29 20 20 20 20 20 20 20 20 20 20 20 14 14 14 14 14 14\n",
            " 14 14 14 14 14 12 12 12 12 12 12 12 12 12 12 12 27 27 27 27 27 27 27 27\n",
            " 27 27 27 26 26 26 26 26 26 26 26 26 26 26  5  5  5  5  5  5  5  5  5  5\n",
            "  5 15 15 15 15 15 15 15 15 15 15 15 10 10 10 10 10 10 10 10 10 10 10  8\n",
            "  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  6  6  6\n",
            "  6  6  6  6  6  6  6  6  3  3  3  3  3  3  3  3  3  3 17 17 17 17 17 17\n",
            " 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEof2wzuyN1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcee410-06ed-4ba9-be85-42ce32ab819a"
      },
      "source": [
        "# fit model\r\n",
        "pred_model = SVC(kernel='linear', probability=True)\r\n",
        "pred_model.fit(trainX, trainy)\r\n",
        "\r\n",
        "# predict\r\n",
        "yhat_train = pred_model.predict(trainX)\r\n",
        "yhat_test = pred_model.predict(testX)\r\n",
        "\r\n",
        "# score\r\n",
        "score_train = accuracy_score(trainy, yhat_train)\r\n",
        "score_test = accuracy_score(testy, yhat_test)\r\n",
        "# summarize\r\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: train=100.000, test=100.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5anMjX66vgRC"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\r\n",
        "from random import choice\r\n",
        "from numpy import load\r\n",
        "from numpy import expand_dims\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.svm import SVC\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# load faces\r\n",
        "data = load('faces-dataset.npz')\r\n",
        "testX_faces = data['arr_2']\r\n",
        "\r\n",
        "# load face embeddings\r\n",
        "data = load('faces-embeddings.npz')\r\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\r\n",
        "print('trainX.shape:', trainX.shape)\r\n",
        "\r\n",
        "# normalize input vectors\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "trainX = in_encoder.transform(trainX)\r\n",
        "testX = in_encoder.transform(testX)\r\n",
        "\r\n",
        "# label encode targets\r\n",
        "out_encoder = LabelEncoder()\r\n",
        "out_encoder.fit(trainy)\r\n",
        "trainy = out_encoder.transform(trainy)\r\n",
        "testy = out_encoder.transform(testy)\r\n",
        "\r\n",
        "# fit model\r\n",
        "pred_model = SVC(kernel='linear', probability=True)\r\n",
        "pred_model.fit(trainX, trainy)\r\n",
        "\r\n",
        "# test model on a random example from the test dataset\r\n",
        "selection = choice([i for i in range(testX.shape[0])])\r\n",
        "random_face_pixels = testX_faces[selection]\r\n",
        "random_face_emb = testX[selection]\r\n",
        "random_face_class = testy[selection]\r\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\r\n",
        "\r\n",
        "# prediction for the face\r\n",
        "samples = expand_dims(random_face_emb, axis=0)\r\n",
        "yhat_class = pred_model.predict(samples)\r\n",
        "yhat_prob = pred_model.predict_proba(samples)\r\n",
        "\r\n",
        "# get name\r\n",
        "class_index = yhat_class[0]\r\n",
        "class_probability = yhat_prob[0,class_index] * 100\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\r\n",
        "print('Expected: %s' % random_face_name[0])\r\n",
        "\r\n",
        "# plot for fun\r\n",
        "pyplot.imshow(random_face_pixels)\r\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\r\n",
        "pyplot.title(title)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnyZgTpSBvL8"
      },
      "source": [
        "print(testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjbWzkSiA1h8"
      },
      "source": [
        "path=\"./web_cam_capture_1.jpg\"\r\n",
        "face_pixels = extract_face(path)\r\n",
        "print('face:', face_pixels.shape)\r\n",
        "\r\n",
        "embedding = get_embedding(facenet_model, face_pixels)\r\n",
        "print('embedding:', embedding.shape)\r\n",
        "\r\n",
        "in_encoder = Normalizer(norm='l2')\r\n",
        "#dataX = in_encoder.transform(np.array([embedding]))\r\n",
        "dataX = in_encoder.transform([embedding])\r\n",
        "print('dataX:', dataX.shape)\r\n",
        "\r\n",
        "# # test model on a random example from the test dataset\r\n",
        "# selection = choice([i for i in range(testX.shape[0])])\r\n",
        "# random_face_pixels = testX_faces[selection]\r\n",
        "# random_face_emb = testX[selection]\r\n",
        "# random_face_class = testy[selection]\r\n",
        "# random_face_name = out_encoder.inverse_transform([random_face_class])\r\n",
        "\r\n",
        "# prediction for the face\r\n",
        "#dataX = expand_dims(dataX, axis=0)\r\n",
        "#print('dataX:', dataX.shape)\r\n",
        "yhat_class = pred_model.predict(dataX)\r\n",
        "yhat_prob = pred_model.predict_proba(dataX)\r\n",
        "\r\n",
        "# get name\r\n",
        "class_index = yhat_class[0]\r\n",
        "class_probability = yhat_prob[0,class_index] * 100\r\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\r\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\r\n",
        "# print('Expected: %s' % random_face_name[0])\r\n",
        "\r\n",
        "# plot for fun\r\n",
        "pyplot.imshow(face_pixels)\r\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\r\n",
        "pyplot.title(title)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}